 1/1:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
from multiprocessing import Pool
%matplotlib inline
 1/2:
import warnings
warnings.filterwarnings("ignore")
 1/3: from mixed_quantum import qd_base_data as qd
 1/4: a, V0, m1, m2 = 2.5, 2, 0.17, 0.17
 1/5: data_25 = qd.qd_results(a, V0, m1, m2)
 1/6: data_25.e_levels
 1/7: a, V0, m1, m2 = 2.5, 1.5, 0.17, 0.17
 1/8: data_25 = qd.qd_results(a, V0, m1, m2)
 1/9: data_25.e_levels
1/10: a, V0, m1, m2 = 2.5, 1.15, 0.17, 0.17
1/11: data_25 = qd.qd_results(a, V0, m1, m2)
1/12: data_25.e_levels
1/13:
a, V0, m1, m2 = 3.9, 1.9, 0.17, 0.17
density = (np.pi/6, np.pi/6, np.pi/6)
1/14: data_39 = qd.qd_results(a, V0, m1, m2)
1/15: data_39.e_levels
1/16:
a, V0, m1, m2 = 3.9, 1.15, 0.17, 0.17
density = (np.pi/6, np.pi/6, np.pi/6)
1/17: data_39 = qd.qd_results(a, V0, m1, m2)
1/18: data_39.e_levels
1/19: data_to_plot = plot_data()
1/20: a = np.linspace(1, 15, 1000)
1/21:
# %load plot_data.py
"""
Class to plot data
"""
import numpy as np
import matplotlib.pyplot as plt


class plot_data:
    """Class to store data to later plot"""
    def __init__(self):
        """Initialize the variable with the data"""
        self.data = dict()

    def add_data(self, x_data, y_data, **data_info):
        """Add the data to the data dictionary
        data_info (tuple): title, x_label, y_label"""
        if not isinstance(x_data, np.ndarray
                          ) or not isinstance(y_data, np.ndarray):
            raise Exception("Data is not numpy array!!")

        self.data[data_info['label']] = [x_data, y_data, data_info]
        return print("Data Added Successfully")

    def single_plot(self, label, save=False, labelsize=14, size=(10, 8)):
        """Make a single plot for specific data"""
        x_val = self.data[label][0]
        y_val = self.data[label][1]
        if len(y_val.shape) > 1:
            for y_i in y_val:
                plt.plot(x_val, y_i)
        else:
            plt.plot(x_val, y_val)
            
        # plt.title(data_info, fontsize=labelsize)
        plt.xlabel(self.data[label][2]["xlabel"], fontsize=labelsize)
        plt.ylabel(self.data[label][2]["ylabel"], fontsize=labelsize)
        plt.tick_params(labelsize=labelsize-2)
        if save:
            plt.savefig(f"Figure_{label}.png", dpi=300,
                        transparent=True, bbox_inches='tight')
        plt.show()
1/22: data_to_plot = plot_data()
1/23: a = np.linspace(1, 15, 1000)
1/24:
a_variation = np.array([
    [qd.qd_results(a_i, 1,9, 0.17, 0.17, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1,9, 0.17, 0.17, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1,9, 0.17, 0.17, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1,9, 0.17, 0.17, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
1/25:
a_variation = np.array([
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
1/26: data_to_plot = plot_data()
1/27: a = np.linspace(1, 15, 1000)
1/28:
a_variation = np.array([
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
1/29:
V0 = np.linspace(0.5, 1.3, 1000)
m = np.linspace(0.05, 0.2, 1000)
1/30:
V0_variation = np.array([
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',0)).e_levels[0] for V0_i in V0],
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',1)).e_levels[0] for V0_i in V0],
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',2)).e_levels[0] for V0_i in V0],
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',0)).e_levels[1] for V0_i in V0]
])

m_variation = np.array([
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[0] for m1_i in m],
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',1)).e_levels[0] for m1_i in m],
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',2)).e_levels[0] for m1_i in m],
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[1] for m1_i in m]
])
1/31:
m2_variation = np.array([
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',0)).e_levels[0] for m2_i in m],
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',1)).e_levels[0] for m2_i in m],
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',2)).e_levels[0] for m2_i in m],
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',0)).e_levels[1] for m2_i in m]
])
1/32: a_dict = {"a_data": a, "E0": a_variation[0], "E1": a_variation[1], "E2": a_variation[2], "E3": a_variation[3]}
1/33:
a_dict = {"a_data": a, "E0": a_variation[0], "E1": a_variation[1], "E2": a_variation[2], "E3": a_variation[3]}
V0_dict = {"V0_data": V0, "E0": V0_variation[0], "E1": V0_variation[1], "E2": V0_variation[2], "E3": V0_variation[3]}
m_dict = {"m_data": m, "E0": m_variation[0], "E1": m_variation[1], "E2": m_variation[2], "E3": m_variation[3]}
1/34: a_lin_sweep = pd.DataFrame(a_dict)
1/35:
V0_lin_sweep = pd.DataFrame(V0_dict)
m_lin_sweep = pd.DataFrame(m_dict)
1/36: m2_dict = {"m2_data": m, "E0": m2_variation[0], "E1": m2_variation[1], "E2": m2_variation[2], "E3": m2_variation[3]}
1/37: m2_lin_sweep = pd.DataFrame(m2_dict)
1/38: a_lin_sweep.to_csv("a_lin_sweep.csv")
1/39:
V0_lin_sweep.to_csv("V0_lin_sweep.csv")
m_lin_sweep.to_csv("m_lin_sweep.csv")
m2_lin_sweep.to_csv("m2_lin_sweep.csv")
1/40:
data_to_plot.add_data(a, a_variation, **{'label': 'a_data', 'xlabel': 'a (nm)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(V0, V0_variation, **{'label': 'V0_data', 'xlabel': 'V$_0$ (eV)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(m, m_variation, **{'label': 'm1_data', 'xlabel': 'm$_1$ (*me)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(m, m2_variation, **{'label': 'm2_data', 'xlabel': 'm$_2$ (*me)', 'ylabel': 'E (eV)'})
1/41: data_to_plot.single_plot('a_data')
1/42: data_to_plot.single_plot('V0_data')
1/43: data_to_plot.single_plot('m1_data')
1/44: data_to_plot.single_plot('m2_data')
1/45:
a_variation = np.array([
    [qd.qd_results(a_i, 1.15, 0.17, 0.17, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.17, 0.17, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.17, 0.17, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.17, 0.17, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
1/46: data_to_plot = plot_data()
1/47: a = np.linspace(1, 15, 1000)
1/48:
a_variation = np.array([
    [qd.qd_results(a_i, 1.15, 0.17, 0.17, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.17, 0.17, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.17, 0.17, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.17, 0.17, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
1/49:
V0 = np.linspace(0.5, 1.3, 1000)
m = np.linspace(0.05, 0.2, 1000)
1/50:
V0_variation = np.array([
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',0)).e_levels[0] for V0_i in V0],
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',1)).e_levels[0] for V0_i in V0],
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',2)).e_levels[0] for V0_i in V0],
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',0)).e_levels[1] for V0_i in V0]
])

m_variation = np.array([
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[0] for m1_i in m],
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',1)).e_levels[0] for m1_i in m],
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',2)).e_levels[0] for m1_i in m],
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[1] for m1_i in m]
])
1/51:
m2_variation = np.array([
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',0)).e_levels[0] for m2_i in m],
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',1)).e_levels[0] for m2_i in m],
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',2)).e_levels[0] for m2_i in m],
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',0)).e_levels[1] for m2_i in m]
])
1/52: a_dict = {"a_data": a, "E0": a_variation[0], "E1": a_variation[1], "E2": a_variation[2], "E3": a_variation[3]}
1/53:
a_dict = {"a_data": a, "E0": a_variation[0], "E1": a_variation[1], "E2": a_variation[2], "E3": a_variation[3]}
V0_dict = {"V0_data": V0, "E0": V0_variation[0], "E1": V0_variation[1], "E2": V0_variation[2], "E3": V0_variation[3]}
m_dict = {"m_data": m, "E0": m_variation[0], "E1": m_variation[1], "E2": m_variation[2], "E3": m_variation[3]}
1/54: a_lin_sweep = pd.DataFrame(a_dict)
1/55:
V0_lin_sweep = pd.DataFrame(V0_dict)
m_lin_sweep = pd.DataFrame(m_dict)
1/56: m2_dict = {"m2_data": m, "E0": m2_variation[0], "E1": m2_variation[1], "E2": m2_variation[2], "E3": m2_variation[3]}
1/57: m2_lin_sweep = pd.DataFrame(m2_dict)
1/58: a_lin_sweep.to_csv("a_lin_sweep.csv")
1/59:
V0_lin_sweep.to_csv("V0_lin_sweep.csv")
m_lin_sweep.to_csv("m_lin_sweep.csv")
m2_lin_sweep.to_csv("m2_lin_sweep.csv")
1/60:
data_to_plot.add_data(a, a_variation, **{'label': 'a_data', 'xlabel': 'a (nm)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(V0, V0_variation, **{'label': 'V0_data', 'xlabel': 'V$_0$ (eV)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(m, m_variation, **{'label': 'm1_data', 'xlabel': 'm$_1$ (*me)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(m, m2_variation, **{'label': 'm2_data', 'xlabel': 'm$_2$ (*me)', 'ylabel': 'E (eV)'})
1/61: data_to_plot.single_plot('a_data')
1/62: data_to_plot.single_plot('V0_data')
1/63: data_to_plot.single_plot('m1_data')
1/64: data_to_plot.single_plot('m2_data')
 2/1:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
from multiprocessing import Pool
%matplotlib inline
 2/2:
import warnings
warnings.filterwarnings("ignore")
 2/3: from mixed_quantum import qd_base_data as qd
 2/4:
# %load plot_data.py
"""
Class to plot data
"""
import numpy as np
import matplotlib.pyplot as plt


class plot_data:
    """Class to store data to later plot"""
    def __init__(self):
        """Initialize the variable with the data"""
        self.data = dict()

    def add_data(self, x_data, y_data, **data_info):
        """Add the data to the data dictionary
        data_info (tuple): title, x_label, y_label"""
        if not isinstance(x_data, np.ndarray
                          ) or not isinstance(y_data, np.ndarray):
            raise Exception("Data is not numpy array!!")

        self.data[data_info['label']] = [x_data, y_data, data_info]
        return print("Data Added Successfully")

    def single_plot(self, label, save=False, labelsize=14, size=(10, 8)):
        """Make a single plot for specific data"""
        x_val = self.data[label][0]
        y_val = self.data[label][1]
        if len(y_val.shape) > 1:
            for y_i in y_val:
                plt.plot(x_val, y_i)
        else:
            plt.plot(x_val, y_val)
            
        # plt.title(data_info, fontsize=labelsize)
        plt.xlabel(self.data[label][2]["xlabel"], fontsize=labelsize)
        plt.ylabel(self.data[label][2]["ylabel"], fontsize=labelsize)
        plt.tick_params(labelsize=labelsize-2)
        if save:
            plt.savefig(f"Figure_{label}.png", dpi=300,
                        transparent=True, bbox_inches='tight')
        plt.show()
 2/5: data_to_plot = plot_data()
 2/6: a = np.linspace(1, 15, 1000)
 2/7:
a_variation = np.array([
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
 2/8:
V0 = np.linspace(0.5, 1.3, 1000)
m = np.linspace(0.05, 0.2, 1000)
 2/9: a_dict = {"a_data": a, "E0": a_variation[0], "E1": a_variation[1], "E2": a_variation[2], "E3": a_variation[3]}
2/10:
a_dict = {"a_data": a, "E0": a_variation[0], "E1": a_variation[1], "E2": a_variation[2], "E3": a_variation[3]}
V0_dict = {"V0_data": V0, "E0": V0_variation[0], "E1": V0_variation[1], "E2": V0_variation[2], "E3": V0_variation[3]}
m_dict = {"m_data": m, "E0": m_variation[0], "E1": m_variation[1], "E2": m_variation[2], "E3": m_variation[3]}
2/11:
V0 = np.linspace(0.5, 1.3, 1000)
m = np.linspace(0.05, 0.2, 1000)
2/12:
V0_variation = np.array([
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',0)).e_levels[0] for V0_i in V0],
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',1)).e_levels[0] for V0_i in V0],
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',2)).e_levels[0] for V0_i in V0],
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',0)).e_levels[1] for V0_i in V0]
])

m_variation = np.array([
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[0] for m1_i in m],
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',1)).e_levels[0] for m1_i in m],
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',2)).e_levels[0] for m1_i in m],
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[1] for m1_i in m]
])
2/13:
m2_variation = np.array([
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',0)).e_levels[0] for m2_i in m],
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',1)).e_levels[0] for m2_i in m],
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',2)).e_levels[0] for m2_i in m],
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',0)).e_levels[1] for m2_i in m]
])
2/14: a_dict = {"a_data": a, "E0": a_variation[0], "E1": a_variation[1], "E2": a_variation[2], "E3": a_variation[3]}
2/15:
a_dict = {"a_data": a, "E0": a_variation[0], "E1": a_variation[1], "E2": a_variation[2], "E3": a_variation[3]}
V0_dict = {"V0_data": V0, "E0": V0_variation[0], "E1": V0_variation[1], "E2": V0_variation[2], "E3": V0_variation[3]}
m_dict = {"m_data": m, "E0": m_variation[0], "E1": m_variation[1], "E2": m_variation[2], "E3": m_variation[3]}
2/16: a_lin_sweep = pd.DataFrame(a_dict)
2/17:
V0_lin_sweep = pd.DataFrame(V0_dict)
m_lin_sweep = pd.DataFrame(m_dict)
2/18: m2_dict = {"m2_data": m, "E0": m2_variation[0], "E1": m2_variation[1], "E2": m2_variation[2], "E3": m2_variation[3]}
2/19: m2_lin_sweep = pd.DataFrame(m2_dict)
2/20: a_lin_sweep.to_csv("a_lin_sweep.csv")
2/21:
V0_lin_sweep.to_csv("V0_lin_sweep.csv")
m_lin_sweep.to_csv("m_lin_sweep.csv")
m2_lin_sweep.to_csv("m2_lin_sweep.csv")
2/22:
data_to_plot.add_data(a, a_variation, **{'label': 'a_data', 'xlabel': 'a (nm)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(V0, V0_variation, **{'label': 'V0_data', 'xlabel': 'V$_0$ (eV)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(m, m_variation, **{'label': 'm1_data', 'xlabel': 'm$_1$ (*me)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(m, m2_variation, **{'label': 'm2_data', 'xlabel': 'm$_2$ (*me)', 'ylabel': 'E (eV)'})
2/23: data_to_plot.single_plot('a_data')
2/24: data_to_plot.single_plot('V0_data')
2/25: data_to_plot.single_plot('m1_data')
2/26: data_to_plot.single_plot('m2_data')
2/27: a, V0, m1, m2 = 1, 1.9, 0.17, 0.17
2/28: data_25 = qd.qd_results(a, V0, m1, m2)
2/29: data_25.e_levels
2/30: a, V0, m1, m2 = 1.1, 1.9, 0.17, 0.17
2/31: data_25 = qd.qd_results(a, V0, m1, m2)
2/32: data_25.e_levels
2/33: a, V0, m1, m2 = 1.1, 1.9, 0.25, 0.25
2/34: data_25 = qd.qd_results(a, V0, m1, m2)
2/35: data_25.e_levels
2/36: a, V0, m1, m2 = 1, 1.9, 0.25, 0.25
2/37: data_25 = qd.qd_results(a, V0, m1, m2)
2/38: data_25.e_levels
2/39: a, V0, m1, m2 = 0.9, 1.9, 0.25, 0.25
2/40: data_25 = qd.qd_results(a, V0, m1, m2)
2/41: data_25.e_levels
 4/1:
energy = np.linspace(0,1,500)
energies = data_25.e_levels.values
density = (np.pi/6, np.pi/6, np.pi/6)
 4/2:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
from multiprocessing import Pool
%matplotlib inline
 4/3:
import warnings
warnings.filterwarnings("ignore")
 4/4: from mixed_quantum import qd_base_data as qd
 4/5: a, V0, m1, m2 = 0.9, 1.9, 0.25, 0.25
 4/6: data_25 = qd.qd_results(a, V0, m1, m2)
 4/7: data_25.e_levels
 4/8:
print(f"""
{data_25.rad_matrix_element((0,0),(0,0))}
{data_25.rad_matrix_element((0,0),(1,0))}
{data_25.rad_matrix_element((0,0),(2,0))}
{data_25.rad_matrix_element((0,0),(0,1))}
{data_25.rad_matrix_element((1,0),(2,0))}
{data_25.rad_matrix_element((1,0),(0,1))}
{data_25.rad_matrix_element((2,0),(0,1))}
""")
 4/9:
print(f"""
Ep_z, Ep_left, Ep_right--
li = 0, lf = 0
{data_25.all_ang_matrix_elements(0,0)}\n
li = 0, lf = 1
{data_25.all_ang_matrix_elements(0,1)}\n
li = 0, lf = 2
{data_25.all_ang_matrix_elements(0,2)}\n
li = 1, lf = 0
{data_25.all_ang_matrix_elements(1,0)}\n
li = 1, lf = 2
{data_25.all_ang_matrix_elements(1,2)}\n
li = 2, lf = 0
{data_25.all_ang_matrix_elements(2,0)}\n
li = 2, lf = 1
{data_25.all_ang_matrix_elements(2,1)}\n
""")
4/10:
energy = np.linspace(0,1,500)
energies = data_25.e_levels.values
density = (np.pi/6, np.pi/6, np.pi/6)
4/11:
e_0_1 = abs(energies[0,0] - energies[0,1])
rad_elements = data_25.rad_matrix_element((0,0),(1,0))
_, ang_elements = data_25.all_ang_matrix_elements(0,1)
4/12: absorption_1 = qd.absorption_ij(energy, e_0_1, rad_elements*ang_elements[:,np.newaxis], qd_density=density)
4/13: plt.plot(energy, absorption_1[0], energy, absorption_1[1], energy, absorption_1[2])
4/14:
from mixed_quantum import qd_base_data as qd
from jupyterthemes import jtplot
4/15:
from mixed_quantum import qd_base_data as qd
from jupyterthemes import jtplot
 5/1:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
%matplotlib inline
 5/2:
import warnings
warnings.filterwarnings("ignore")
 5/3: from mixed_quantum import qd_base_data as qd
 5/4:
# %load plot_data.py
"""
Class to plot data
"""
import numpy as np
import matplotlib.pyplot as plt


class plot_data:
    """Class to store data to later plot"""
    def __init__(self):
        """Initialize the variable with the data"""
        self.data = dict()

    def add_data(self, x_data, y_data, **data_info):
        """Add the data to the data dictionary
        data_info (tuple): title, x_label, y_label"""
        if not isinstance(x_data, np.ndarray
                          ) or not isinstance(y_data, np.ndarray):
            raise Exception("Data is not numpy array!!")

        self.data[data_info['label']] = [x_data, y_data, data_info]
        return print("Data Added Successfully")

    def single_plot(self, label, save=False, labelsize=14, size=(10, 8)):
        """Make a single plot for specific data"""
        x_val = self.data[label][0]
        y_val = self.data[label][1]
        if len(y_val.shape) > 1:
            for y_i in y_val:
                plt.plot(x_val, y_i)
        else:
            plt.plot(x_val, y_val)
            
        # plt.title(data_info, fontsize=labelsize)
        plt.xlabel(self.data[label][2]["xlabel"], fontsize=labelsize)
        plt.ylabel(self.data[label][2]["ylabel"], fontsize=labelsize)
        plt.tick_params(labelsize=labelsize-2)
        if save:
            plt.savefig(f"Figure_{label}.png", dpi=300,
                        transparent=True, bbox_inches='tight')
        plt.show()
 5/5: data_to_plot = plot_data()
 5/6: a = np.linspace(0.5, 8, 1000)
 5/7:
a_variation = np.array([
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.17, 0.17, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.15, 0.17, 0.17, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
 5/8:
V0 = np.linspace(0.5, 1.3, 1000)
m = np.linspace(0.05, 0.2, 1000)
 5/9:
V0_variation = np.array([
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',0)).e_levels[0] for V0_i in V0],
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',1)).e_levels[0] for V0_i in V0],
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',2)).e_levels[0] for V0_i in V0],
    [qd.qd_results(5, V0_i, 0.17, 0.17, mode=('simple',0)).e_levels[1] for V0_i in V0]
])

m_variation = np.array([
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[0] for m1_i in m],
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',1)).e_levels[0] for m1_i in m],
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',2)).e_levels[0] for m1_i in m],
    [qd.qd_results(5, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[1] for m1_i in m]
])
5/10:
m2_variation = np.array([
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',0)).e_levels[0] for m2_i in m],
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',1)).e_levels[0] for m2_i in m],
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',2)).e_levels[0] for m2_i in m],
    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',0)).e_levels[1] for m2_i in m]
])
5/11: a_dict = {"a_data": a, "E0": a_variation[0], "E1": a_variation[1], "E2": a_variation[2], "E3": a_variation[3]}
5/12:
a_dict = {"a_data": a, "E0": a_variation[0], "E1": a_variation[1], "E2": a_variation[2], "E3": a_variation[3]}
V0_dict = {"V0_data": V0, "E0": V0_variation[0], "E1": V0_variation[1], "E2": V0_variation[2], "E3": V0_variation[3]}
m_dict = {"m_data": m, "E0": m_variation[0], "E1": m_variation[1], "E2": m_variation[2], "E3": m_variation[3]}
5/13: a_lin_sweep = pd.DataFrame(a_dict)
5/14:
V0_lin_sweep = pd.DataFrame(V0_dict)
m_lin_sweep = pd.DataFrame(m_dict)
5/15: m2_dict = {"m2_data": m, "E0": m2_variation[0], "E1": m2_variation[1], "E2": m2_variation[2], "E3": m2_variation[3]}
5/16: m2_lin_sweep = pd.DataFrame(m2_dict)
5/17: a_lin_sweep.to_csv("a_lin_sweep.csv")
5/18:
V0_lin_sweep.to_csv("V0_lin_sweep.csv")
m_lin_sweep.to_csv("m_lin_sweep.csv")
m2_lin_sweep.to_csv("m2_lin_sweep.csv")
5/19:
data_to_plot.add_data(a, a_variation, **{'label': 'a_data', 'xlabel': 'a (nm)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(V0, V0_variation, **{'label': 'V0_data', 'xlabel': 'V$_0$ (eV)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(m, m_variation, **{'label': 'm1_data', 'xlabel': 'm$_1$ (*me)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(m, m2_variation, **{'label': 'm2_data', 'xlabel': 'm$_2$ (*me)', 'ylabel': 'E (eV)'})
5/20: data_to_plot.single_plot('a_data')
 7/1:
a_variation_19 = np.array([
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
 7/2:
a_variation_155 = np.array([
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.55, 0.08, 0.08, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.55, 0.08, 0.08, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.55, 0.08, 0.08, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.55, 0.08, 0.08, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
 7/3: a = np.linspace(0.5, 8, 1000)
 7/4:
a_variation_19 = np.array([
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
 7/5:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
%matplotlib inline
 7/6:
import warnings
warnings.filterwarnings("ignore")
 7/7: from mixed_quantum import qd_base_data as qd
 7/8:
# %load plot_data.py
"""
Class to plot data
"""
import numpy as np
import matplotlib.pyplot as plt


class plot_data:
    """Class to store data to later plot"""
    def __init__(self):
        """Initialize the variable with the data"""
        self.data = dict()

    def add_data(self, x_data, y_data, **data_info):
        """Add the data to the data dictionary
        data_info (tuple): title, x_label, y_label"""
        if not isinstance(x_data, np.ndarray
                          ) or not isinstance(y_data, np.ndarray):
            raise Exception("Data is not numpy array!!")

        self.data[data_info['label']] = [x_data, y_data, data_info]
        return print("Data Added Successfully")

    def single_plot(self, label, save=False, labelsize=14, size=(10, 8)):
        """Make a single plot for specific data"""
        x_val = self.data[label][0]
        y_val = self.data[label][1]
        if len(y_val.shape) > 1:
            for y_i in y_val:
                plt.plot(x_val, y_i)
        else:
            plt.plot(x_val, y_val)
            
        # plt.title(data_info, fontsize=labelsize)
        plt.xlabel(self.data[label][2]["xlabel"], fontsize=labelsize)
        plt.ylabel(self.data[label][2]["ylabel"], fontsize=labelsize)
        plt.tick_params(labelsize=labelsize-2)
        if save:
            plt.savefig(f"Figure_{label}.png", dpi=300,
                        transparent=True, bbox_inches='tight')
        plt.show()
 7/9: data_to_plot = plot_data()
7/10: a = np.linspace(0.5, 8, 1000)
7/11:
a_variation_19 = np.array([
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
7/12:
a_variation_155 = np.array([
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.55, 0.08, 0.08, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.55, 0.08, 0.08, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.55, 0.08, 0.08, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.55, 0.08, 0.08, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
7/13:
a_variation_155 = np.array([
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.08, 0.08, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.08, 0.08, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.08, 0.08, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.15, 0.08, 0.08, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
7/14:
V0 = np.linspace(1, 2, 1000)
m = np.linspace(0.05, 0.3, 1000)
7/15:
V0_variation = np.array([
    [qd.qd_results(3.5, V0_i, 0.08, 0.08, mode=('simple',0)).e_levels[0] for V0_i in V0],
    [qd.qd_results(3.5, V0_i, 0.08, 0.08, mode=('simple',1)).e_levels[0] for V0_i in V0],
    [qd.qd_results(3.5, V0_i, 0.08, 0.08, mode=('simple',2)).e_levels[0] for V0_i in V0],
    [qd.qd_results(3.5, V0_i, 0.08, 0.08, mode=('simple',0)).e_levels[1] for V0_i in V0]
])

m_variation = np.array([
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',0)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',1)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',2)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',0)).e_levels[1] for m1_i in m]
])
7/16:
#m2_variation = np.array([
#    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',0)).e_levels[0] for m2_i in m],
#    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',1)).e_levels[0] for m2_i in m],
#    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',2)).e_levels[0] for m2_i in m],
#    [qd.qd_results(5, 1.15, 0.17, m2_i, mode=('simple',0)).e_levels[1] for m2_i in m]
#])
7/17:
a_dict_19 = {"a_data": a, "E0": a_variation_19[0], "E1": a_variation_19[1], "E2": a_variation_19[2], "E3": a_variation_19[3]}
a_dict_155 = {"a_data": a, "E0": a_variation_155[0], "E1": a_variation_155[1], "E2": a_variation_155[2], "E3": a_variation_155[3]}
V0_dict = {"V0_data": V0, "E0": V0_variation[0], "E1": V0_variation[1], "E2": V0_variation[2], "E3": V0_variation[3]}
m_dict = {"m_data": m, "E0": m_variation[0], "E1": m_variation[1], "E2": m_variation[2], "E3": m_variation[3]}
7/18:
a_lin_sweep_19 = pd.DataFrame(a_dict_19)
a_lin_sweep_155 = pd.DataFrame(a_dict_155)
V0_lin_sweep = pd.DataFrame(V0_dict)
m_lin_sweep = pd.DataFrame(m_dict)
7/19: #m2_dict = {"m2_data": m, "E0": m2_variation[0], "E1": m2_variation[1], "E2": m2_variation[2], "E3": m2_variation[3]}
7/20: #m2_lin_sweep = pd.DataFrame(m2_dict)
7/21:
a_lin_sweep_19.to_csv("a_lin_sweep_19.csv", index = False)
a_lin_sweep_155.to_csv("a_lin_sweep_155.csv", index = False)
V0_lin_sweep.to_csv("V0_lin_sweep.csv", index = False)
m_lin_sweep.to_csv("m_lin_sweep.csv", index = False)
#m2_lin_sweep.to_csv("m2_lin_sweep.csv")
7/22:
data_to_plot.add_data(a, a_variation_19, **{'label': 'a_data', 'xlabel': 'a (nm)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(a, a_variation_155, **{'label': 'a_data_155', 'xlabel': 'a (nm)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(V0, V0_variation, **{'label': 'V0_data', 'xlabel': 'V$_0$ (eV)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(m, m_variation, **{'label': 'm1_data', 'xlabel': 'm$_1$ (*me)', 'ylabel': 'E (eV)'})
#data_to_plot.add_data(m, m2_variation, **{'label': 'm2_data', 'xlabel': 'm$_2$ (*me)', 'ylabel': 'E (eV)'})
7/23: data_to_plot.single_plot('a_data')
7/24: data_to_plot.single_plot('a_data_155')
7/25: data_to_plot.single_plot('V0_data')
7/26: data_to_plot.single_plot('m1_data')
7/27:
a, V0, m1, m2 = 1.6, 1.15, 0.08, 0.08
density = (np.pi/6, np.pi/6, np.pi/6)
7/28: data_16_155 = qd.qd_results(a, V0, m1, m2)
7/29: data_16_155.e_levels
7/30:
a, V0, m1, m2 = 2.4, 1.55, 0.08, 0.08
density = (np.pi/6, np.pi/6, np.pi/6)
7/31: data_24_155 = qd.qd_results(a, V0, m1, m2)
7/32: data_24_155.e_levels
7/33:
print(f"""
{data_24_155.rad_matrix_element((0,0),(0,0))}
{data_24_155.rad_matrix_element((0,0),(1,0))}
""")
7/34:
a, V0, m1, m2 = 2.4, 1.15, 0.08, 0.08
density = (np.pi/6, np.pi/6, np.pi/6)
 8/1:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
%matplotlib inline
 8/2:
import warnings
warnings.filterwarnings("ignore")
 8/3: from mixed_quantum import qd_base_data as qd
 8/4:
# %load plot_data.py
"""
Class to plot data
"""
import numpy as np
import matplotlib.pyplot as plt


class plot_data:
    """Class to store data to later plot"""
    def __init__(self):
        """Initialize the variable with the data"""
        self.data = dict()

    def add_data(self, x_data, y_data, **data_info):
        """Add the data to the data dictionary
        data_info (tuple): title, x_label, y_label"""
        if not isinstance(x_data, np.ndarray
                          ) or not isinstance(y_data, np.ndarray):
            raise Exception("Data is not numpy array!!")

        self.data[data_info['label']] = [x_data, y_data, data_info]
        return print("Data Added Successfully")

    def single_plot(self, label, save=False, labelsize=14, size=(10, 8)):
        """Make a single plot for specific data"""
        x_val = self.data[label][0]
        y_val = self.data[label][1]
        if len(y_val.shape) > 1:
            for y_i in y_val:
                plt.plot(x_val, y_i)
        else:
            plt.plot(x_val, y_val)
            
        # plt.title(data_info, fontsize=labelsize)
        plt.xlabel(self.data[label][2]["xlabel"], fontsize=labelsize)
        plt.ylabel(self.data[label][2]["ylabel"], fontsize=labelsize)
        plt.tick_params(labelsize=labelsize-2)
        if save:
            plt.savefig(f"Figure_{label}.png", dpi=300,
                        transparent=True, bbox_inches='tight')
        plt.show()
 9/1:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
%matplotlib inline
 9/2:
import warnings
warnings.filterwarnings("ignore")
 9/3: from mixed_quantum import qd_base_data as qd
 9/4:
# %load plot_data.py
"""
Class to plot data
"""
import numpy as np
import matplotlib.pyplot as plt


class plot_data:
    """Class to store data to later plot"""
    def __init__(self):
        """Initialize the variable with the data"""
        self.data = dict()

    def add_data(self, x_data, y_data, **data_info):
        """Add the data to the data dictionary
        data_info (tuple): title, x_label, y_label"""
        if not isinstance(x_data, np.ndarray
                          ) or not isinstance(y_data, np.ndarray):
            raise Exception("Data is not numpy array!!")

        self.data[data_info['label']] = [x_data, y_data, data_info]
        return print("Data Added Successfully")

    def single_plot(self, label, save=False, labelsize=14, size=(10, 8)):
        """Make a single plot for specific data"""
        x_val = self.data[label][0]
        y_val = self.data[label][1]
        if len(y_val.shape) > 1:
            for y_i in y_val:
                plt.plot(x_val, y_i)
        else:
            plt.plot(x_val, y_val)
            
        # plt.title(data_info, fontsize=labelsize)
        plt.xlabel(self.data[label][2]["xlabel"], fontsize=labelsize)
        plt.ylabel(self.data[label][2]["ylabel"], fontsize=labelsize)
        plt.tick_params(labelsize=labelsize-2)
        if save:
            plt.savefig(f"Figure_{label}.png", dpi=300,
                        transparent=True, bbox_inches='tight')
        plt.show()
 9/5: data_to_plot = plot_data()
 9/6: a = np.linspace(0.5, 8, 1000)
 9/7: data_to_plot = plot_data()
 9/8: a = np.linspace(0.5, 8, 1000)
 9/9:
a_variation_19 = np.array([
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
9/10:
a_variation_115 = np.array([
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.08, 0.08, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.08, 0.08, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.08, 0.08, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.15, 0.08, 0.08, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
9/11:
V0 = np.linspace(1, 2, 1000)
m = np.linspace(0.05, 0.3, 1000)
9/12:
V0_variation = np.array([
    [qd.qd_results(3.5, V0_i, 0.08, 0.08, mode=('simple',0)).e_levels[0] for V0_i in V0],
    [qd.qd_results(3.5, V0_i, 0.08, 0.08, mode=('simple',1)).e_levels[0] for V0_i in V0],
    [qd.qd_results(3.5, V0_i, 0.08, 0.08, mode=('simple',2)).e_levels[0] for V0_i in V0],
    [qd.qd_results(3.5, V0_i, 0.08, 0.08, mode=('simple',0)).e_levels[1] for V0_i in V0]
])

m_variation_19 = np.array([
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',0)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',1)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',2)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',0)).e_levels[1] for m1_i in m]
])
m_variation_115 = np.array([
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',0)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',1)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',2)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',0)).e_levels[1] for m1_i in m]
])
9/13:
V0_variation = np.array([
    [qd.qd_results(3.5, V0_i, 0.08, 0.08, mode=('simple',0)).e_levels[0] for V0_i in V0],
    [qd.qd_results(3.5, V0_i, 0.08, 0.08, mode=('simple',1)).e_levels[0] for V0_i in V0],
    [qd.qd_results(3.5, V0_i, 0.08, 0.08, mode=('simple',2)).e_levels[0] for V0_i in V0],
    [qd.qd_results(3.5, V0_i, 0.08, 0.08, mode=('simple',0)).e_levels[1] for V0_i in V0]
])

m_variation_19 = np.array([
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',0)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',1)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',2)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.9, m1_i, m1_i, mode=('simple',0)).e_levels[1] for m1_i in m]
])
m_variation_115 = np.array([
    [qd.qd_results(3.5, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.15, m1_i, m1_i, mode=('simple',1)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.15, m1_i, m1_i, mode=('simple',2)).e_levels[0] for m1_i in m],
    [qd.qd_results(3.5, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[1] for m1_i in m]
])
9/14:
V0_variation = np.array([
    [qd.qd_results(4, V0_i, 0.08, 0.08, mode=('simple',0)).e_levels[0] for V0_i in V0],
    [qd.qd_results(4, V0_i, 0.08, 0.08, mode=('simple',1)).e_levels[0] for V0_i in V0],
    [qd.qd_results(4, V0_i, 0.08, 0.08, mode=('simple',2)).e_levels[0] for V0_i in V0],
    [qd.qd_results(4, V0_i, 0.08, 0.08, mode=('simple',0)).e_levels[1] for V0_i in V0]
])

m_variation_19 = np.array([
    [qd.qd_results(4, 1.9, m1_i, m1_i, mode=('simple',0)).e_levels[0] for m1_i in m],
    [qd.qd_results(4, 1.9, m1_i, m1_i, mode=('simple',1)).e_levels[0] for m1_i in m],
    [qd.qd_results(4, 1.9, m1_i, m1_i, mode=('simple',2)).e_levels[0] for m1_i in m],
    [qd.qd_results(4, 1.9, m1_i, m1_i, mode=('simple',0)).e_levels[1] for m1_i in m]
])

m_variation_115 = np.array([
    [qd.qd_results(4, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[0] for m1_i in m],
    [qd.qd_results(4, 1.15, m1_i, m1_i, mode=('simple',1)).e_levels[0] for m1_i in m],
    [qd.qd_results(4, 1.15, m1_i, m1_i, mode=('simple',2)).e_levels[0] for m1_i in m],
    [qd.qd_results(4, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[1] for m1_i in m]
])
9/15:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
%matplotlib inline
9/16:
import warnings
warnings.filterwarnings("ignore")
9/17: from mixed_quantum import qd_base_data as qd
9/18:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
%matplotlib inline
9/19:
import warnings
warnings.filterwarnings("ignore")
9/20: from mixed_quantum import qd_base_data as qd
10/1:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
%matplotlib inline
10/2:
import warnings
warnings.filterwarnings("ignore")
10/3: from mixed_quantum import qd_base_data as qd
10/4:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
%matplotlib inline
10/5:
import warnings
warnings.filterwarnings("ignore")
10/6: from mixed_quantum import qd_base_data as qd
10/7:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
%matplotlib inline
10/8:
import warnings
warnings.filterwarnings("ignore")
10/9: from mixed_quantum import qd_base_data as qd
10/10:
# %load plot_data.py
"""
Class to plot data
"""
import numpy as np
import matplotlib.pyplot as plt


class plot_data:
    """Class to store data to later plot"""
    def __init__(self):
        """Initialize the variable with the data"""
        self.data = dict()

    def add_data(self, x_data, y_data, **data_info):
        """Add the data to the data dictionary
        data_info (tuple): title, x_label, y_label"""
        if not isinstance(x_data, np.ndarray
                          ) or not isinstance(y_data, np.ndarray):
            raise Exception("Data is not numpy array!!")

        self.data[data_info['label']] = [x_data, y_data, data_info]
        return print("Data Added Successfully")

    def single_plot(self, label, save=False, labelsize=14, size=(10, 8)):
        """Make a single plot for specific data"""
        x_val = self.data[label][0]
        y_val = self.data[label][1]
        if len(y_val.shape) > 1:
            for y_i in y_val:
                plt.plot(x_val, y_i)
        else:
            plt.plot(x_val, y_val)
            
        # plt.title(data_info, fontsize=labelsize)
        plt.xlabel(self.data[label][2]["xlabel"], fontsize=labelsize)
        plt.ylabel(self.data[label][2]["ylabel"], fontsize=labelsize)
        plt.tick_params(labelsize=labelsize-2)
        if save:
            plt.savefig(f"Figure_{label}.png", dpi=300,
                        transparent=True, bbox_inches='tight')
        plt.show()
10/11: data_to_plot = plot_data()
10/12: a = np.linspace(0.5, 8, 1000)
10/13:
a_variation_19 = np.array([
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.9, 0.08, 0.08, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.9, 0.08, 0.08, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
10/14:
a_variation_115 = np.array([
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',0)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.08, 0.08, mode = ('simple',0)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',1)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.08, 0.08, mode = ('simple',1)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',2)).e_levels[0] if qd.qd_results(a_i, 1.15, 0.08, 0.08, mode = ('simple',2)).e_levels else np.nan for a_i in a],
    [qd.qd_results(a_i, 1.15, 0.08, 0.08, mode=('simple',0)).e_levels[1] if len(qd.qd_results(a_i, 1.15, 0.08, 0.08, mode = ('simple',0)).e_levels)>=2 else np.nan for a_i in a]
])
10/15:
V0 = np.linspace(1, 2, 1000)
m = np.linspace(0.05, 0.3, 1000)
10/16:
V0_variation = np.array([
    [qd.qd_results(4, V0_i, 0.08, 0.08, mode=('simple',0)).e_levels[0] for V0_i in V0],
    [qd.qd_results(4, V0_i, 0.08, 0.08, mode=('simple',1)).e_levels[0] for V0_i in V0],
    [qd.qd_results(4, V0_i, 0.08, 0.08, mode=('simple',2)).e_levels[0] for V0_i in V0],
    [qd.qd_results(4, V0_i, 0.08, 0.08, mode=('simple',0)).e_levels[1] for V0_i in V0]
])

m_variation_19 = np.array([
    [qd.qd_results(4, 1.9, m1_i, m1_i, mode=('simple',0)).e_levels[0] for m1_i in m],
    [qd.qd_results(4, 1.9, m1_i, m1_i, mode=('simple',1)).e_levels[0] for m1_i in m],
    [qd.qd_results(4, 1.9, m1_i, m1_i, mode=('simple',2)).e_levels[0] for m1_i in m],
    [qd.qd_results(4, 1.9, m1_i, m1_i, mode=('simple',0)).e_levels[1] for m1_i in m]
])

m_variation_115 = np.array([
    [qd.qd_results(4, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[0] for m1_i in m],
    [qd.qd_results(4, 1.15, m1_i, m1_i, mode=('simple',1)).e_levels[0] for m1_i in m],
    [qd.qd_results(4, 1.15, m1_i, m1_i, mode=('simple',2)).e_levels[0] for m1_i in m],
    [qd.qd_results(4, 1.15, m1_i, m1_i, mode=('simple',0)).e_levels[1] for m1_i in m]
])
10/17:
a_dict_19 = {"a_data": a, "E0": a_variation_19[0], "E1": a_variation_19[1], "E2": a_variation_19[2], "E3": a_variation_19[3]}
a_dict_115 = {"a_data": a, "E0": a_variation_115[0], "E1": a_variation_115[1], "E2": a_variation_115[2], "E3": a_variation_115[3]}
V0_dict = {"V0_data": V0, "E0": V0_variation[0], "E1": V0_variation[1], "E2": V0_variation[2], "E3": V0_variation[3]}
m_dict_19 = {"m_data": m, "E0": m_variation_19[0], "E1": m_variation_19[1], "E2": m_variation_19[2], "E3": m_variation_19[3]}
m_dict_115 = {"m_data": m, "E0": m_variation_115[0], "E1": m_variation_115[1], "E2": m_variation_115[2], "E3": m_variation_115[3]}
10/18:
a_lin_sweep_19 = pd.DataFrame(a_dict_19)
a_lin_sweep_115 = pd.DataFrame(a_dict_115)
V0_lin_sweep = pd.DataFrame(V0_dict)
m_lin_sweep_19 = pd.DataFrame(m_dict_19)
m_lin_sweep_115 = pd.DataFrame(m_dict_115)
10/19:
a_lin_sweep_19.to_csv("a_lin_sweep_19.csv", index = False, separator=" ")
a_lin_sweep_115.to_csv("a_lin_sweep_115.csv", index = False, separator=" ")
V0_lin_sweep.to_csv("V0_lin_sweep.csv", index = False, separator=" ")
m_lin_sweep_19.to_csv("m_lin_sweep_19.csv", index = False, separator=" ")
m_lin_sweep_115.to_csv("m_lin_sweep_115.csv", index = False, separator=" ")
#m2_lin_sweep.to_csv("m2_lin_sweep.csv")
10/20:
a_lin_sweep_19.to_csv("a_lin_sweep_19.csv", index = False, sep=" ")
a_lin_sweep_115.to_csv("a_lin_sweep_115.csv", index = False, sep=" ")
V0_lin_sweep.to_csv("V0_lin_sweep.csv", index = False, sep=" ")
m_lin_sweep_19.to_csv("m_lin_sweep_19.csv", index = False, sep=" ")
m_lin_sweep_115.to_csv("m_lin_sweep_115.csv", index = False, sep=" ")
#m2_lin_sweep.to_csv("m2_lin_sweep.csv")
10/21:
data_to_plot.add_data(a, a_variation_19, **{'label': 'a_data', 'xlabel': 'a (nm)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(a, a_variation_115, **{'label': 'a_data_115', 'xlabel': 'a (nm)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(V0, V0_variation, **{'label': 'V0_data', 'xlabel': 'V$_0$ (eV)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(m, m_variation_19, **{'label': 'm1_data_19', 'xlabel': 'm$_1$ (*me)', 'ylabel': 'E (eV)'})
data_to_plot.add_data(m, m_variation_115, **{'label': 'm1_data_115', 'xlabel': 'm$_1$ (*me)', 'ylabel': 'E (eV)'})
#data_to_plot.add_data(m, m2_variation, **{'label': 'm2_data', 'xlabel': 'm$_2$ (*me)', 'ylabel': 'E (eV)'})
10/22: data_to_plot.single_plot('a_data')
10/23: data_to_plot.single_plot('a_data_115')
10/24: data_to_plot.single_plot('V0_data')
10/25: data_to_plot.single_plot('m1_data_19')
10/26: data_to_plot.single_plot('m1_data_115')
10/27:
a = np.linspace(1.4, 8, 100)
V0 = np.linspace(1, 2, 100)
m = np.linspace(0.05, 0.3, 100)
10/28:
print("Calculating a - V0 relation....")
data = list()
a_v0_mesh, v0_a_mesh = np.meshgrid(a, V0)
for a_i, v_i in zip(a_v0_mesh, v0_a_mesh):
    data.append(list(map(
            lambda a_i, v_i: qd.qd_results(
                a_i, v_i, 0.08, 0.08, mode=('simple', 0)).e_levels[0],
            a_i, v_i
        )))
data_a_V0 = np.array(data)
print("DONE!....")


print("Calculating a - m realations...")
data = list()
a_m_mesh, m_a_mesh = np.meshgrid(a, m)
for a_i, m1_i in zip(a_m_mesh, m_a_mesh):
    data.append(list(map(
            lambda a_i, m_i: qd.qd_results(
                a_i, 1.9, m_i, m_i, mode=('simple', 0)).e_levels[0],
            a_i, m1_i
            )))
data_a_m1 = np.array(data)
print("DONE!....")

print("Calculating V0 - m relation...")
data = list()
v0_m_mesh, m_v0_mesh = np.meshgrid(V0, m)
for V0_i, m1_i in zip(v0_m_mesh, m_v0_mesh):
    data.append(list(map(
            lambda V0_i, m_i: qd.qd_results(
                3.5, V0_i, m_i, m_i, mode=('simple', 0)).e_levels[0],
            V0_i, m1_i
            )))
data_V0_m1 = np.array(data)
print("DONE!....")
10/29:
plt.figure(figsize=(7, 7))
plt.contourf(a_v0_mesh, v0_a_mesh, data_a_V0, levels = 50, cmap = plt.cm.rainbow)
plt.xlabel('a (um)', fontsize=17); plt.ylabel('V0 (eV)', fontsize=17);
plt.tick_params(labelsize=15)
plt.colorbar()
plt.ylabel("E$_0$")
plt.savefig("Test.png", dpi=300,
                transparent=True, bbox_inches='tight')
10/30:
plt.figure(figsize=(7, 7))
plt.contourf(a_m_mesh, m_a_mesh, data_a_m1, levels = 50, cmap = plt.cm.rainbow)
plt.xlabel('a (um)', fontsize=17); plt.ylabel('m1 (/me)', fontsize=17);
plt.tick_params(labelsize=15)
10/31:
plt.figure(figsize=(7, 7))
plt.contourf(v0_m_mesh, m_v0_mesh, data_V0_m1, levels = 50, cmap = plt.cm.rainbow)
plt.xlabel('a (um)', fontsize=17); plt.ylabel('V0 (eV)', fontsize=17);
plt.tick_params(labelsize=15)
10/32:
a_v0_dict = {"a": a_v0_mesh.flatten(), "V0": v0_a_mesh.flatten(), "data": data_a_V0.flatten()}
a_m_dict = {"a": a_m_mesh.flatten(), "m": m_a_mesh.flatten(), "data": data_a_m1.flatten()}
v0_m_dict = {"V0": v0_m_mesh.flatten(), "m": m_v0_mesh.flatten(), "data": data_V0_m1.flatten()}
10/33:
a_v0_df = pd.DataFrame(a_v0_dict)
a_m_df = pd.DataFrame(a_m_dict)
v0_m_df = pd.DataFrame(v0_m_dict)
10/34:
a_v0_df.to_csv("a_V0_sweep.csv", index=False)
a_m_df.to_csv("a_m_sweep.csv", index=False)
v0_m_df.to_csv("V0_m_sweep.csv", index=False)
10/35:
print("Calculating a - V0 relation....")
data = list()
a_v0_mesh, v0_a_mesh = np.meshgrid(a, V0)
for a_i, v_i in zip(a_v0_mesh, v0_a_mesh):
    data.append(list(map(
            lambda a_i, v_i: qd.qd_results(
                a_i, v_i, 0.08, 0.08, mode=('simple', 0)).e_levels[0],
            a_i, v_i
        )))
data_a_V0 = np.array(data)
print("DONE!....")


print("Calculating a - m realations for V0 1.9 eV...")
data = list()
a_m_mesh, m_a_mesh = np.meshgrid(a, m)
for a_i, m1_i in zip(a_m_mesh, m_a_mesh):
    data.append(list(map(
            lambda a_i, m_i: qd.qd_results(
                a_i, 1.9, m_i, m_i, mode=('simple', 0)).e_levels[0],
            a_i, m1_i
            )))
data_a_m1_19 = np.array(data)
print("DONE!....")

print("Calculating a - m realations for V0 1.15 eV...")
data = list()
a_m_mesh, m_a_mesh = np.meshgrid(a, m)
for a_i, m1_i in zip(a_m_mesh, m_a_mesh):
    data.append(list(map(
            lambda a_i, m_i: qd.qd_results(
                a_i, 1.15, m_i, m_i, mode=('simple', 0)).e_levels[0],
            a_i, m1_i
            )))
data_a_m1_115 = np.array(data)
print("DONE!....")

print("Calculating V0 - m relation...")
data = list()
v0_m_mesh, m_v0_mesh = np.meshgrid(V0, m)
for V0_i, m1_i in zip(v0_m_mesh, m_v0_mesh):
    data.append(list(map(
            lambda V0_i, m_i: qd.qd_results(
                3.5, V0_i, m_i, m_i, mode=('simple', 0)).e_levels[0],
            V0_i, m1_i
            )))
data_V0_m1 = np.array(data)
print("DONE!....")
10/36:
plt.figure(figsize=(7, 7))
plt.contourf(a_v0_mesh, v0_a_mesh, data_a_V0, levels = 50, cmap = plt.cm.rainbow)
plt.xlabel('a (um)', fontsize=17); plt.ylabel('V0 (eV)', fontsize=17);
plt.tick_params(labelsize=15)
plt.colorbar()
plt.ylabel("E$_0$")
plt.savefig("Test.png", dpi=300,
                transparent=True, bbox_inches='tight')
10/37:
plt.figure(figsize=(7, 7))
plt.contourf(a_m_mesh, m_a_mesh, data_a_m1_19, levels = 50, cmap = plt.cm.rainbow)
plt.xlabel('a (um)', fontsize=17); plt.ylabel('m1 (/me)', fontsize=17);
plt.tick_params(labelsize=15)
10/38:
plt.figure(figsize=(7, 7))
plt.contourf(a_m_mesh, m_a_mesh, data_a_m1_115, levels = 50, cmap = plt.cm.rainbow)
plt.xlabel('a (um)', fontsize=17); plt.ylabel('m1 (/me)', fontsize=17);
plt.tick_params(labelsize=15)
10/39:
plt.figure(figsize=(7, 7))
plt.contourf(v0_m_mesh, m_v0_mesh, data_V0_m1, levels = 50, cmap = plt.cm.rainbow)
plt.xlabel('a (um)', fontsize=17); plt.ylabel('V0 (eV)', fontsize=17);
plt.tick_params(labelsize=15)
10/40:
a_v0_dict = {"a": a_v0_mesh.flatten(), "V0": v0_a_mesh.flatten(), "data": data_a_V0.flatten()}
a_m_dict_19 = {"a": a_m_mesh_19.flatten(), "m": m_a_mesh.flatten(), "data": data_a_m1.flatten()}
a_m_dict_115 = {"a": a_m_mesh_115.flatten(), "m": m_a_mesh.flatten(), "data": data_a_m1.flatten()}
v0_m_dict = {"V0": v0_m_mesh.flatten(), "m": m_v0_mesh.flatten(), "data": data_V0_m1.flatten()}
10/41:
a_v0_dict = {"a": a_v0_mesh.flatten(), "V0": v0_a_mesh.flatten(), "data": data_a_V0.flatten()}
a_m_dict_19 = {"a": a_m_mesh.flatten(), "m": m_a_mesh_19.flatten(), "data": data_a_m1.flatten()}
a_m_dict_115 = {"a": a_m_mesh.flatten(), "m": m_a_mesh115.flatten(), "data": data_a_m1.flatten()}
v0_m_dict = {"V0": v0_m_mesh.flatten(), "m": m_v0_mesh.flatten(), "data": data_V0_m1.flatten()}
10/42:
a_v0_dict = {"a": a_v0_mesh.flatten(), "V0": v0_a_mesh.flatten(), "data": data_a_V0.flatten()}
a_m_dict_19 = {"a": a_m_mesh.flatten(), "m": m_a_mesh.flatten(), "data": data_a_m1_19.flatten()}
a_m_dict_115 = {"a": a_m_mesh.flatten(), "m": m_a_mesh.flatten(), "data": data_a_m1_115.flatten()}
v0_m_dict = {"V0": v0_m_mesh.flatten(), "m": m_v0_mesh.flatten(), "data": data_V0_m1.flatten()}
10/43:
a_v0_df = pd.DataFrame(a_v0_dict)
a_m_df_19 = pd.DataFrame(a_m_dict_19)
a_m_df_115 = pd.DataFrame(a_m_dict_115)
v0_m_df = pd.DataFrame(v0_m_dict)
10/44:
a_v0_df.to_csv("a_V0_sweep.csv", index=False, sep=" ")
a_m_df_19.to_csv("a_m_sweep.csv", index=False, sep=" ")
a_m_df_115.to_csv("a_m_sweep.csv", index=False, sep=" ")
v0_m_df.to_csv("V0_m_sweep.csv", index=False, sep=" ")
10/45:
a_v0_df.to_csv("a_V0_sweep.csv", index=False, sep=" ")
a_m_df_19.to_csv("a_m_sweep_19.csv", index=False, sep=" ")
a_m_df_115.to_csv("a_m_sweep_115.csv", index=False, sep=" ")
v0_m_df.to_csv("V0_m_sweep.csv", index=False, sep=" ")
14/1: pip install jupyterthemes
15/1: import fib
15/2: fib?
15/3: fib.fib?
15/4: %load_ext cythonmagic
15/5:
%%cython
def fib(int n):
    cdef int i
    cdef double a=0.0, b=1.0
    for i in range(n):
        a, b = a + b, a
    return a
16/1: %load_ext cythonmagic
17/1: %load_ext cythonmagic
17/2: %load_ext Cython
17/3:
def fib(int i):
    cdef int i
17/4:
def fib(int i):
    cdef int i
17/5:
%%cython
def fib(int i):
    cdef int i
    cdef long a=0, b=1
    for i in range(n):
        a, b = a + b, a
    return a
17/6:
%%cython
def fib(int n):
    cdef int i
    cdef long a=0, b=1
    for i in range(n):
        a, b = a + b, a
    return a
17/7: fib(90)
20/1: %run -p nbody.py 500000
20/2: %run -p nbody.py 500000
22/1: import pyximport; pyximport.install()
22/2: import particle
23/1: import pyximport; pyximport.install()
23/2: import python_particle
23/3: import cython_particle
23/4: python_particle.Particle?
23/5: cython_particle.Particle?
23/6: py_particle = python_particle.Particle(1.0, 2.0, 3.0)
23/7: cy_particle = cython_particle.Particle(1.0, 2.0, 3.0)
23/8: py_particle.get_momentum()
23/9: cy_particle.get_momentum()
23/10: py_particle.mass
23/11: cy_particle.mass
23/12: import cython_particle
23/13: cy_particle = cython_particle.Particle(1.0, 2.0, 3.0)
23/14: cy_particle.mass
23/15: import cython_particle
23/16: cy_particle = cython_particle.Particle(1.0, 2.0, 3.0)
23/17: cy_particle.mass
24/1: import pyximport; pyximport.install()
24/2: import cython_particle
24/3: cy_particle = cython_particle.Particle(1.0, 2.0, 3.0)
24/4: cy_particle.mass
25/1: import h5py
25/2: f = h5py.file('zaasd', 'r')
25/3: f = h5py.File('zaasd', 'r')
25/4: list(f.keys())
25/5: dset = f['collection']
25/6: list(dset.keys())
25/7: dset['geometry_0']
25/8: list(dset['geometry_0'].keys())
25/9: dset['geometry_0']['region_0]
25/10: dset['geometry_0']['region_0']
25/11: dset['geometry_0']['region_0'].keys
25/12: dset['geometry_0']['region_0'].keys()
25/13: dset['geometry_0']['region_0']['elements_0']
26/1: import webbrowser
26/2: webbrowser.open("https://apostas.placard.pt/sports/basketball/highlights")
26/3: import urllib2
26/4: import urllib
26/5: urllib.urlopen("https://apostas.placard.pt/sports/basketball/highlights")
27/1: import urlli.request as urllib2
27/2: import urllib.request as urllib2
27/3: urllib2.open("https://apostas.placard.pt/sports/basketball/highlights")
27/4: urllib2.urlopen("https://apostas.placard.pt/sports/basketball/highlights")
27/5: from bs4 import *
27/6: c = urllib2.urlopen("https://apostas.placard.pt/sports/basketball/highlights")
27/7: c.read()
27/8: soup = BeautifulSoup(c.read())
28/1: from bs4 import BeautifulSoup
28/2: import urlib.request
28/3: import urllib.request
28/4: url = "https://apostas.placard.pt/sports/basketball/highlights"
28/5: soup = BeatifulSoup(urllib.request.urlopen(url), 'html.parser')
28/6: soup = BeautifulSoup(urllib.request.urlopen(url), 'html.parser')
28/7: print(soup)
28/8: url = “https://www.tipico.de/de/live-wetten/"
28/9: url = "https://www.tipico.de/de/live-wetten/"
28/10: soup = BeautifulSoup(urllib.request.urlopen(url), 'html.parser')
28/11: url = "https://apostas.placard.pt/sports/basketball/highlights"
28/12: soup = BeautifulSoup(urllib.request.urlopen(url), 'html.parser')
28/13: print(soup)
28/14: url = "https://www.tipico.de/de/"
28/15: soup = BeautifulSoup(urllib.request.urlopen(url), 'html.parser')
28/16: url = "https://sports.tipico.de/de"
28/17: soup = BeautifulSoup(urllib.request.urlopen(url), 'html.parser')
28/18: soup = BeautifulSoup(urllib.request.urlopen(url), 'json.parser')
28/19: url = "https://apostas.placard.pt/sports/basketball/highlights"
28/20: soup = BeautifulSoup(urllib.request.urlopen(url), 'json.parser')
28/21: soup = BeautifulSoup(urllib.request.urlopen(url), 'html.parser')
28/22: print(soup)
29/1: ls
29/2: cd Documents/Python/PhD/Article\ Results
29/3: ls
29/4: cat m_lin_sweep_115.csv
29/5: import pandas
29/6: import pandas as pd
29/7: pd.read_csv("m_lin_sweep_115.csv")
29/8: asdasd = pd.read_csv("m_lin_sweep_115.csv")
33/1: import numpy as np
33/2: ?np.mgrid
33/3: a = np.mgrid[:3,:3,:3][0]
33/4: a
33/5: np.fft.fftn(a)
33/6: np.fft.fftn(a, axes=(1,2))
33/7: afft = np.fft.fftn(a)
33/8: afft
33/9: np.fft.ifft(afft)
33/10: import scipy.fft
33/11: scipy.fft.fftn(a)
33/12: scipy.fft.ifftn(scipy.fft.fftn(a))
33/13: np.fft.ifft(np.fft.fft(a))
33/14: np.fft.ifftn(np.fft.fftn(a))
33/15: res = np.fft.fftn(a)
33/16: res
33/17: np.fft.ifftn(res)
34/1: import numpy
34/2: import numpy as np
34/3: ?linspcae
34/4: ?linspace
34/5: ?np.linspace
35/1: import numpy as np
35/2: ?np.arange
35/3: np.arange(0.5, 0.5+7*1)
35/4: np.linspace(0.5, 6.5, 7)
35/5: x = np.arange(0.5, 0.5*7+1)
35/6: y = np.arange(0.5, 0.5*5+1)
35/7: XX, YY = np.meshgrid(x, y)
35/8: XX
35/9: x = np.arange(0.5, 0.5*7+1)
35/10: x
35/11: x = np.arange(0.5, 0.5+7*1)
35/12: x
35/13: y = np.arange(0.5, 0.5+5*1)
35/14: XX, YY = np.meshgrid(x, y)
35/15: XX
35/16: XX ** 2
35/17: XX ** 2 + YY ** 2
35/18: XX ** 2 + YY ** 2 < 15
35/19: XX ** 2 + YY ** 2 <= 15
35/20: a = np.zeros(7, 7)
35/21: a = np.zeros((7,7))
35/22: a
35/23: a[2,4] = 1
35/24: a
35/25: a.T
35/26: a = np.zeros((7,7))
35/27: a[2,:] = 1
35/28: a
35/29: a[2,3:5] = 1
35/30: a
35/31: a[2,3:5] = 2
35/32: a
40/1: from numpy import mgrid
40/2: mgrid[0:5][0:5]
40/3: mgrid[0:5,0:5]
40/4: mgrid[0:5,0:5][1]
40/5: mgrid[0:5,0:5]
40/6: mgrid[0:5:5j,0:5:5j]
40/7: import matplotlib.pyplot as plt
40/8: x, y = mgrid[0:5:5j,0:5:5j]
40/9: x
40/10: y
40/11: plt.pcolormesh(y)
40/12: plt.show()
40/13: plt.show()
40/14: plt.pcolormesh(y)
40/15: plt.show()
40/16: x
40/17: mask = y > -0.5*x +7
40/18: maks
40/19: mask
40/20: mask = y > -0.5*x +4
40/21: mask = y > -0.5*x +4
40/22: mask
40/23: y[y > -0.5*x +4]
40/24: y[y > -0.5*x +4] = 1
40/25: y
40/26: masl
40/27: maks
40/28: mask
40/29: plt.pcolormesh(mask)
40/30: plt.show()
40/31: x, y = mgrid[0:5:100j,0:5:100j]
40/32: mask = y > -0.5*x + 5
40/33: plt.pcolormesh(mask)
40/34: plt.show()
40/35: plt.show()
40/36: plt.pcolormesh(mask)
40/37: plt.show()
40/38: x
40/39: x, y = mgrid[0:5:10j,0:5:10j]
40/40: x
40/41: mask_x = x > 2
40/42: mask_x_2 = x > 2
40/43: mask_x && mask_x_2
40/44: mask_x +  mask_x_2
40/45: bool = mask_x + mask_x_2
40/46: boolean = mask_x + mask_x_2
40/47: boolean
40/48: boolean.astype(int)
40/49: mask_x = x > 2
40/50: mask_x_2 = x > 3
40/51: np.logical_xor(mask_x, mask_x_2)
40/52: import numpy as np
40/53: np.logical_xor(mask_x, mask_x_2)
40/54: np.logical_or(mask_x, mask_x_2)
40/55: np.logical_and(mask_x, mask_x_2)
40/56: np.logical_xor(mask_x, mask_x_2)
40/57: np.logical_xor(mask_x, mask_x_2) & np.logical_or(mask_x, mask_x_2)
40/58: mask
40/59: mask_x
40/60: mask_x & mask_x_2
40/61: mask_x & ~mask_x_2
40/62: (mask_x & ~mask_x_2).astype(int)
41/1: import matplotlib.pyplot as plt
41/2: import numpy as np
41/3: x = np.linspace(0, 10, 1000)
41/4: y = x**2
41/5: plt.plot(x, y)
41/6: plt.show()
41/7: plt.plot(x, y)
41/8: plt.show()
41/9: import matplotlib
41/10: matplotlib.use("WXAgg")
42/1: import matplotlib
42/2: matplotlib.__version__
42/3: matplotlib.use("WXAgg")
42/4: plt.figure(figsize=(400,240))
42/5: import matplotlib.pyplot as plt
42/6: plt.figure(figsize=(400,240))
42/7: plt.plot(x, y)
42/8: x = np.linspace(0, 10, 1000)
42/9: import numpy as np
42/10: x = np.linspace(0, 10, 1000)
42/11: y = x**2
42/12: plt.plot(x, y)
42/13: plt.show()
42/14: plt.figure(figsize=(100,50))
42/15: plt.plot(x, y)
42/16: plt.show()
42/17: %matplotlib inline
42/18: plt.figure(figsize=(20,10))
42/19: plt.plot(x, y)
42/20: plt.show()
42/21: plt.show()
43/1: import matplotlib.pyplot as plt
43/2: import numpy as np
43/3: x = np.linspace(0, 10, 1000)
43/4: y = x**2
43/5: plt.figure(figsize=(20,10))
43/6: plt.plot(x, y)
43/7: plt.show()
43/8: plt.figure(figsize=(2,1))
43/9: plt.plot(x, y)
43/10: plt.show()
43/11: plt.figure(figsize=(4,4))
43/12: plt.plot(x, y)
43/13: plt.show()
43/14: plt.figure(figsize=(4,3))
43/15: plt.plot(x, y)
43/16: plt.show()
44/1: import matplotlib.pyplot as plt
44/2: plt.rcParams["figure.figsize"]
44/3: plt.rcParams["figure.font"]
44/4: plt.rcParams["figure.fontsize"]
44/5: plt.rcParams["figure.font.size"]
44/6: plt.rcParams["figure.font"]
44/7: plt.rcParams["font"]
44/8: plt.rcParams["font.size"]
44/9: plt.rcParams["figure.figsize"] = (4,3)
44/10: plt.rcParams["font.size"] = 10
45/1: import numpy as np
45/2: import matplotlib.pyplot as plt
45/3: x = np.linspace(0, 10, 1000)
45/4: y = x**2
45/5: plt.plot(x, y)
45/6: plt.show()
46/1: import matplotlib
46/2: from matplotlib import rc
46/3: matplotlib.rcParams["font.size"] = 10
46/4: matplotlib.rcParams["figure.figsize"] = (4,3)
47/1: import numpy as np
47/2: import matplotlib.pyplot as plt
47/3: x = np.linspace(0, 10, 1000)
47/4: y = x**2
47/5: plt.plot(x, y)
47/6: plt.show()
47/7: import matplotlib
47/8: print matplotlib.matplotlib_fname()
47/9: print(matplotlib.matplotlib_fname())
48/1: import matplotlib.pyplot as plt
48/2: import numpy as np
48/3: x = np.linspace(0, 10, 1000)
48/4: y = x**2
48/5: plt.plot(x, y)
48/6: plt.show()
48/7: plt.rcParams["figure.figsize"]
49/1: import matplotlib
49/2: print(matplotlib.matplotlib_fname())
49/3: import matplotlib.pyplot as plt
49/4: import numpy as np
49/5: plt.rcParams["figure.figsize"]
49/6: plt.rcParams["font.size"]
49/7: plt.rcParams["backend"]
50/1: import matplotlib.pyplot as plt
51/1: import matplotlib.pyplot as plt
51/2: plt.rcParams["font.size"]
52/1: import matplotlib
52/2: matplotlib.rcParams["figure.figsize"]
52/3: print(matplotlib.matplotlib_fname())
52/4: matplotlib.rcParamsDefault
52/5: matplotlib.rcParams["font.size"]
53/1: matplotlib.rcParams["font.size"]
55/1: matplotlib.pyplot.plt
56/1: import matplotlib.pyplot as plt
56/2: plt.rcParams["figure.figsize"]
56/3: plt.rcParamsDefault
56/4: plt.rcParams["font.size"]
57/1: %matplotlib jupyter
57/2: %matplotlib qt
57/3: import matplotlib.pyplot as plt
57/4: plt.rcParams["font.size"]
57/5: plt.rcParams["figure.figsize"]
57/6: x = np.linspace(0, 10, 1000)
57/7: import numpy as np
57/8: x = np.linspace(0, 10, 1000)
57/9: y = x**2
57/10: plt.plot(x, y)
58/1: import matplotlib.pyplot as plt
58/2: import numpy as np
58/3: x = np.linspace(0, 10, 100)
58/4: x
58/5: y = x ** 2
58/6: y
58/7: plt.plot(x, y)
58/8: plt.show()
58/9: x = np.linspace(-10, 10, 10000000)
58/10: y = x ** 2
58/11: plt.plot(x, y)
58/12: plt.show()
58/13: x = np.linspace(-10, 10, 10000000, dtype='float')
58/14: y = x ** 2
58/15: x = np.linspace(-10, 10, 10000000)
58/16: y = x ** 2
58/17: x = np.linspace(-10, 10, 1000000000, dtype='double')
59/1: import numpy as np
59/2: x = np.linspace(-10, 10, 100000000, dtype='float')
59/3: y = x ** 2
59/4: x = np.linspace(-10, 10, 100000000)
59/5: y = x ** 2
59/6: x = np.linspace(-10, 10, 1000000000)
60/1: import numpy as np
60/2: x = np.linspace(-10, 10, 500000000)
60/3: y = x ** 2
61/1: import numpy as np
61/2: x = np.linspace(-10, 10, 1000000000, dtype = np.float32)
62/1: x = np.linspace(-10, 10, 1000000000, dtype = np.int32)
62/2: import numpy as np
62/3: x = np.linspace(-10, 10, 1000000000, dtype = np.int32)
63/1: x = np.linspace(-10, 10, 1000000000, dtype = uint32)
63/2: import numpy as np
63/3: x = np.linspace(-10, 10, 1000000000, dtype = uint32)
63/4: x = np.linspace(-10, 10, 1000000000, dtype = "uint32")
64/1: import numpy as np
64/2: x = np.linspace(-10, 10, 1000000000, dtype = "uint16")
65/1: import numpy as np
65/2: x = np.linspace(-10, 10, 1000000000, dtype = "uint4")
66/1: import numpy as np
66/2: x = np.linspace(-10, 10, 100000000, dtype = "uint4")
66/3: x = np.linspace(-10, 10, 100000000, dtype = "ui4")
66/4: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("ui4"))
66/5: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("uint4"))
66/6: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("i4"))
66/7: x
66/8: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("uint32"))
66/9: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("uint64"))
66/10: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("uint32"))
66/11: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("uint64"))
66/12: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("uint32"))
66/13: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("uint16"))
66/14: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("uint8"))
66/15: x
66/16: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("int8"))
66/17: x
66/18: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("f8"))
66/19: x
66/20: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("f64"))
66/21: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("double"))
66/22: x
66/23: x.dtype
66/24: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("float"))
66/25: x
66/26: x.dtype
66/27: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("f32"))
66/28: x = np.linspace(-10, 10, 100000000, dtype = np.dtype("float32"))
66/29: x
67/1: import numpy as np
67/2: x = np.linspace(-10, 10, 1000, dtype = np.dtype("short"))
67/3: x
67/4: x = np.linspace(-10, 10, 1000, dtype = np.dtype("long"))
67/5: x
67/6: x.dtype
67/7: x = np.linspace(-10, 10, 1000, dtype = np.dtype("long double"))
67/8: x = np.linspace(-10, 10, 1000, dtype = np.dtype("long float"))
67/9: x = np.arange(0, 100000, 1, dtype = np.dtype("long float"))
67/10: x = np.arange(0, 100000, 1, dtype = np.dtype("ushort"))
67/11: x
67/12: x = np.arange(0, 100, 1, dtype = np.dtype("ushort"))
67/13: x
67/14: x = np.arange(0, 100, 1, dtype = np.dtype("uint"))
67/15: x
67/16: x = np.arange(0, 1000, 1, dtype = np.uint)
67/17: x
67/18: x = np.arange(0, 100000, 1, dtype = np.uint)
67/19: x
67/20: x = np.arange(0, 100000, 1, dtype = np.uint32)
67/21: x
67/22: 2**32
67/23: 2**16
67/24: x.itemsize
67/25: x.itemsize * x.size
67/26: y = np.arange(0, 100000, 1, dtype = np.uint64)
67/27: y.itemsize * y.size
67/28: y = np.arange(0, 100000, 1, dtype = np.longfloat)
67/29: y.itemsize * y.size
68/1: import numpy as np
68/2: import numpy.lib.stride_tricks.sliding_window_view as window_view
68/3: import np.lib.stride_tricks.sliding_window_view as window_view
68/4: np.__version__
69/1: import numpy as np
69/2: np.__version__
70/1: import numpy as np
70/2: np.array([1, 2, 3, 4])
70/3: np.array([1, 2, 3, 4]).repeat(3, axis=0)
70/4: np.array([1, 2, 3, 4]).repeat(3, axis=1)
70/5: np.array([1, 2, 3, 4]).repeat(3, axis=0)
70/6: from scipy.sparse import dia_matrix
70/7: a = np.array([-1 0 1])
70/8: a = np.array([-1,0,1])
70/9: a = np.array([-1,0,1], np.zeros(3))
70/10: np.zeros(3)
70/11: a = np.array(([-1,0,1], np.zeros(3)))
70/12: a
70/13: a = np.array(([-1,0,1] np.zeros(3)))
70/14: a = np.concatenate(([-1, 0, 1], np.zeros(3)))
70/15: a
70/16: dia_matrix((a, [-1, 0, 1]), shape=(6,6)).to_array()
70/17: dia_matrix((a, [-1, 0, 1]), shape=(5,5)).to_array()
70/18: data = np.array([-np.eye(6), np.zeros(6,6), np.eye(6)])
70/19: data = np.array([-np.eye(6), np.zeros((6,6)), np.eye(6)])
70/20: data
70/21: dia_matrix((data, [-1, 0, 1]), shape(6,6)).to_array()
70/22: dia_matrix((data, [-1, 0, 1]), shape=(6,6)).to_array()
70/23: n = 10
70/24: ex = np.ones(10)
70/25: ex
70/26: data = np.array([-np.ones(6), np.zeros(6), np.ones(6)])
70/27: data
70/28: dia_matrix((data, [-1, 0, 1]), shape=(6,6)).toarray()
70/29: dia_matrix((data, [-1, 0, 1]), shape=(6,6))
70/30: dia_matrix((data, [-1, 0, 1]), shape=(6,6), dtype=np.int8)
70/31: dia_matrix((data, [-1, 0, 1]), shape=(6,6), dtype=np.int8).toarray()
71/1: import scipy
71/2: scipy.__version__
72/1: from scipy import sparse
72/2: sparse.eye(3, dtype = int8)
72/3: sparse.eye(3, dtype = npint8)
72/4: sparse.eye(3, dtype = np.int8)
72/5: import numpy as np
72/6: sparse.eye(3, dtype = np.int8)
72/7: a = sparse.eye(3, dtype = np.int8)
72/8: a.toarray()
72/9: a[0,0]
72/10: a.toarray()[0]
72/11: a.toarray()[0,0]
72/12: a.toarray()[0,0] = 2
72/13: a
72/14: a.toarray()
72/15: a.getH
72/16: a.toarray()
72/17: a.arcsin.toarray()
72/18: a.arcsin().toarray()
72/19: a.arcsin
72/20: a.toarray()
72/21: b = a.arcsin
72/22: b.toarray()
72/23: b
72/24: b.toarray()
72/25: a.tocsr()
72/26: a[0,0]
72/27: a[0,0] = 0
72/28: a
72/29: b = a.tocsr()
72/30: b
72/31: b.toarray()
72/32: b[0]
72/33: b[0] = 0
72/34: b
72/35: b[0] = [0,0,0]
72/36: b.to_array()
72/37: b.toarray()
72/38: a + b
72/39: c = a+b
72/40: c.toarray()
72/41: a*b
72/42: c = a*b
72/43: c.toarray()
72/44: a = csr_matrix([[1, 2, 0],[0,0,1],[1,0,0]])
72/45: a = sparse.csr_matrix([[1, 2, 0],[0,0,1],[1,0,0]])
72/46: a
72/47: b = sparse.rand(3,3, format="csr")
72/48: b
72/49: c = a*b
72/50: c.toarray()
72/51: b.toarray()
72/52: b = sparse.rand(3,3, density=0.25, format="csr")
72/53: b.toarray()
72/54: c = a*b
72/55: b.toarray()
72/56: c.toarray()
72/57: a.toarray()
76/1: import numpy as np
76/2: np.arange(0,20,1).reshape
76/3: np.arange(0,20,1)
76/4: np.arange(0,20,1).reshape(-1)
76/5: np.arange(0,20,1).reshape(10,2)
76/6: a 0 np.arange(0,20,1).reshape(10,2)
76/7: a 2 np.arange(0,20,1).reshape(10,2)
76/8: a = np.arange(0,20,1).reshape(10,2)
76/9: a
76/10: a.reshape(-1)
76/11: a.reshape(-1, 'F')
77/1:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
%matplotlib inline
77/2: from mixed_quantum import qd_base_data as qd
77/3:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
%matplotlib inline
77/4: from mixed_quantum import qd_base_data as qd
77/5: from mixed_quantum import qd_base_data as qd
77/6: from mixed_quantum import qd_base_data as qd
77/7: from mixed_quantum import qd_base_data as qd
77/8: from mixed_quantum import qd_base_data as qd
77/9: from mixed_quantum import qd_base_data as qd
77/10: from mixed_quantum import qd_base_data as qd
77/11: from mixed_quantum import qd_base_data as qd
77/12:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
%matplotlib inline
77/13: from mixed_quantum import qd_base_data as qd
77/14: from mixed_quantum import qd_base_data as qd
77/15: from mixed_quantum import qd_base_data as qd
77/16: from mixed_quantum import qd_base_data as qd
77/17:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import special
%matplotlib inline
77/18:
import warnings
warnings.filterwarnings("ignore")
77/19: from mixed_quantum import qd_base_data as qd
77/20: a, V0, m1, m2 = 1.6, 1.9, 0.08, 0.08
77/21: data_16 = qd.qd_results(a, V0, m1, m2)
77/22: data_16.e_levels
77/23:
print(f"""
{data_16.rad_matrix_element((0,0),(0,0))}
{data_16.rad_matrix_element((0,0),(1,0))}
""")
#{data_25.rad_matrix_element((0,0),(2,0))}
#{data_25.rad_matrix_element((0,0),(0,1))}
#{data_25.rad_matrix_element((1,0),(2,0))}
#{data_25.rad_matrix_element((1,0),(0,1))}
#{data_25.rad_matrix_element((2,0),(0,1))}
#""")
77/24:
print(f"""
Ep_z, Ep_left, Ep_right--
li = 0, lf = 0
{data_16.all_ang_matrix_elements(0,0)}\n
li = 0, lf = 1
{data_16.all_ang_matrix_elements(0,1)}\n
li = 0, lf = 2
{data_16.all_ang_matrix_elements(0,2)}\n
li = 1, lf = 0
{data_16.all_ang_matrix_elements(1,0)}\n
li = 1, lf = 2
{data_16.all_ang_matrix_elements(1,2)}\n
li = 2, lf = 0
{data_16.all_ang_matrix_elements(2,0)}\n
li = 2, lf = 1
{data_16.all_ang_matrix_elements(2,1)}\n
""")
77/25:
energy = np.linspace(0,1.5,500)
energies = data_16.e_levels.values
density = (np.pi/6, np.pi/6, np.pi/6)
77/26:
e_0_1 = abs(energies[0,0] - energies[0,1])
rad_elements = data_16.rad_matrix_element((0,0),(1,0))
_, ang_elements = data_16.all_ang_matrix_elements(0,1)
absorption_1 = qd.absorption_ij(energy, e_0_1, rad_elements*ang_elements[:,np.newaxis], qd_density=density)
77/27: plt.plot(energy, absorption_1[0], energy, absorption_1[1], energy, absorption_1[2])
77/28:
e_0_1 = abs(energies[0,0] - energies[0,1])
rad_elements = data_16.rad_matrix_element((0,0),(1,0))
_, ang_elements = data_16.all_ang_matrix_elements(0,1)
absorption_1 = qd.absorption_ij(energy, e_0_1, rad_elements*ang_elements[:,np.newaxis], qd_density=density)
absorption_2 = qd.absorption_ij(energy, e_0_1, rad_elements*ang_elements[:,np.newaxis], gauss_dispersion = 0.05, qd_density=density)
77/29: plt.plot(energy, absorption_1[0], energy, absorption_1[1], energy, absorption_1[2], energy, absorption_2[0], energy, absorption_[1])
77/30: plt.plot(energy, absorption_1[0], energy, absorption_1[1], energy, absorption_1[2], energy, absorption_2[0], energy, absorption_2[1])
77/31:
data_16_dict_z = {"Energy": energy, "abs1": absorption_1[0], "abs2": absorption_2[0]}
data_16_dict_left = {"Energy": energy, "abs1": absorption_1[1], "abs2": absorption_2[1]}
pd.DataFrame(data_16_dict_z).to_csv("Absorption_z_16nm_19.csv", index=False, sep=" ")
pd.DataFrame(data_16_dict_left).to_csv("Absorption_left_16nm_19.csv", index=False, sep=" ")
78/1: import numpy as np
80/1: import numpy as np
81/1: import pandas as pd
81/2: data = pd.read_csv("efield_n83_des.dat")
81/3: data
81/4: import numpy as np
81/5: results = data.values
81/6: results
81/7: results.shape
81/8: results[:,5].shape
81/9: 209999/2
81/10: data = pd.read_csv("efield_n83_des.dat", header = False)
81/11: data = pd.read_csv("efield_n83_des.dat", header = None)
81/12: data
82/1: import numpy as np
82/2: import pandas as pd
82/3: imp_data = pd.read_csv("efield_n83_des.dat", header=None)
82/4: data = imp_data.values
82/5: data
82/6: data.shape
82/7: data[:,5].reshape(10500,10500)
82/8: data[5,5]
82/9: data.[5,:].reshape(:,2)
82/10: data[5,:].reshape(:,2)
82/11: data[5,:].reshape(10500,2)
82/12: data[:,5].reshape(10500,2)
82/13: data[:,5].reshape(100500,2)
82/14: data[:,5].reshape(150000,2)
82/15: data[:,5].reshape(105000,2)
82/16: data[:,5].reshape(105000,2)[2,2]
82/17: data[:,5].reshape(105000,2)[2,1]
82/18: data[:,5].reshape(105000,2)[2,2]
82/19: data[:,5].reshape(105000,2)[2,1]
82/20: data
82/21: imp_data
82/22: imp_data.groupby["5"]
82/23: imp_data.groupby[5]
82/24: imp_data.groupby(["5"])
82/25: imp_data.groupby([5])
82/26: imp_data.groupby([5]).mean()
82/27: grouped = imp_data.groupby([5])
82/28: grouped
82/29: grouped.first()
83/1: from .pso import particle_swarm
83/2: from pso.pso import particle_swarm
83/3: from pso import particle_swarm
84/1: from pso.pso import particle_swarm
84/2:
from pso.pso import particle_swarm
import numpy as np
import matplotli.pyplot as plt
84/3:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
84/4:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)
84/5:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function with vectorize"""
    return
84/6:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function with vectorize"""
    return x**3 + 2*y**2 + (x*y)
84/7:
x = np.linspace(0, 10, 200)
y = np.linspace(0, 10, 200)
84/8:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return x**3 + 2*y**2 + (x*y)
84/9:
XX, YY = np.meshgrid(x, y)
plt.contourf(XX, YY, gaussian_test(XX, YY))
84/10:
XX, YY = np.meshgrid(x, y)
plt.contourf(XX, YY, gaussian_test(XX, YY), colors='k')
84/11:
XX, YY = np.meshgrid(x, y)
plt.contourf(XX, YY, gaussian_test(XX, YY), cmap='jet')
84/12:
XX, YY = np.meshgrid(x, y)
plt.contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
84/13:
XX, YY = np.meshgrid(x, y)
plt.contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', locator=ticker.LogLocator())
84/14:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import ticker
84/15:
XX, YY = np.meshgrid(x, y)
plt.contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', locator=ticker.LogLocator())
84/16:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
84/17:
XX, YY = np.meshgrid(x, y)
plt.contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
84/18:
x = np.linspace(0, 5, 200)
y = np.linspace(0, 5, 200)
84/19:
XX, YY = np.meshgrid(x, y)
plt.contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
84/20:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
84/21:
XX, YY = np.meshgrid(x, y)
plt.contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
84/22:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3)
ax[0,0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
ax[0,1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow')
ax[0,2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow')
84/23:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10,3))
ax[0,0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
ax[0,1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow')
ax[0,2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow')
84/24:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10,3))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow')
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow')
84/25:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow')
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow')
84/26:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 10, 200)
y1 = np.linspace(0, 10, 200)
84/27:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow')
ax[2].contourf(XX, YY, vectorize_test(XX1, YY1), cmap='rainbow')
84/28:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 10, 200)
y1 = np.linspace(0, 10, 200)
84/29:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow')
ax[2].contourf(XX, YY, vectorize_test(XX1, YY1), cmap='rainbow')
84/30:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', title="Gaussian")
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow')
ax[2].contourf(XX, YY, vectorize_test(XX1, YY1), cmap='rainbow')
84/31:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow')
ax[2].contourf(XX, YY, vectorize_test(XX1, YY1), cmap='rainbow')
84/32:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow')
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow')
84/33:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x*y)
84/34:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 10, 200)
y1 = np.linspace(0, 10, 200)
84/35:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow')
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow')
84/36:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x*y) - (x-3)**2*(y-2)**2
84/37:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 10, 200)
y1 = np.linspace(0, 10, 200)
84/38:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow')
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow')
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow')
84/39:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow')
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow')
84/40:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow', levels=50)
84/41:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x*y) - (x-3)**3*(y-2)**3
84/42:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 10, 200)
y1 = np.linspace(0, 10, 200)
84/43:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow', levels=50)
84/44:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x*y)**2 - (x-3)**3*(y-2)**3
84/45:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 10, 200)
y1 = np.linspace(0, 10, 200)
84/46:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow', levels=50)
84/47:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x*y) - (x-3)**3*(y-2)**3
84/48:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 10, 200)
y1 = np.linspace(0, 10, 200)
84/49:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow', levels=50)
84/50:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x*y) - (x-3)**3*(y-2)**3
84/51:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 10, 200)
y1 = np.linspace(0, 10, 200)
84/52:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow', levels=50)
84/53:
param_dict = {"x":[0,10];"y":[0,10]}
particle_swarm(gaussian_test, param_dict, maximize=False)
84/54:
param_dict = {"x":[0,10], "y":[0,10]}
particle_swarm(gaussian_test, param_dict, maximize=False)
84/55:
param_dict = {"x":[0,10], "y":[0,10]}
particle_swarm(card_sin_test, param_dict, maximize=False)
84/56:
param_dict = {"x":[-5, 5], "y":[-5, 5]}
particle_swarm(card_sin_test, param_dict, maximize=False)
84/57:
param_dict = {"x":[-10, 10], "y":[-10, 10]}
particle_swarm(card_sin_test, param_dict, maximize=False)
84/58:
param_dict = {"x":[-10, 10], "y":[-10, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True)
84/59:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True)
84/60:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.8, 2, 2))
84/61:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.8, 10, 10))
84/62:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.99, 10, 10))
84/63:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.99, 10, 10), n_particles=30)
84/64:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.1, 10, 10), n_particles=30)
84/65:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.1, 10, 10), n_particles=30, n_iter=100)
84/66:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.78, 1, 1), n_particles=30, n_iter=100)
84/67:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.78, 1, 1))
84/68:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.78, 1, 1))
84/69:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.78, 1, 1))
84/70:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.78, 1, 1))
84/71:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(vectorize_test, param_dict, maximize=True, swarm_properties=(0.78, 1, 1))
84/72:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(vectorize_test, param_dict, maximize=True, swarm_properties=(0.78, 1, 1))
84/73:
param_dict = {"x":[-1,10], "y":[-1, 10]}
particle_swarm(vectorize_test, param_dict, maximize=True, swarm_properties=(0.78, 1, 1))
84/74:
param_dict = {"x":[0.1,10], "y":[0.1, 10]}
particle_swarm(vectorize_test, param_dict, maximize=True, swarm_properties=(0.78, 1, 1))
84/75:
param_dict = {"x":[-1,10], "y":[-1, 10]}
particle_swarm(gaussian_test, param_dict, maximize=True, swarm_properties=(0.78, 1, 1))
84/76:
param_dict = {"x":[-1,10], "y":[-1, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
84/77:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
84/78:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
84/79:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
84/80:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
84/81:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
84/82:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x*y) - (x-3)**3*(y-2)**3
84/83:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 10, 200)
y1 = np.linspace(0, 10, 200)
84/84:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow', levels=50)
84/85:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
84/86:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
84/87:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
85/1:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
85/2:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x*y) - (x-3)**3*(y-2)**3
85/3:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 10, 200)
y1 = np.linspace(0, 10, 200)
85/4:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow', levels=50)
85/5:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
85/6:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
85/7:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
85/8:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
85/9:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
85/10:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
85/11:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
85/12:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
85/13:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False, swarm_properties=(0.78, 1, 1))
85/14:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True)
85/15:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True)
85/16:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=True)
85/17:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=True)
85/18:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=True)
85/19:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=True)
85/20:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=True)
print(best)
85/21:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=True)
print(best)
85/22:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=True)
print(best)
85/23:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=True)
print(best)
85/24:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=True)
print(best)
85/25:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=True)
print(best)
85/26:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False)
print(best)
85/27:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False)
print(best)
85/28:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False)
print(best)
85/29:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False)
print(best)
85/30:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=False)
print(best)
85/31:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=True)
print(best)
85/32:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=True)
print(best)
85/33:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_pos, best_pos_part, best_iter = particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.9,1,1))
print(best)
85/34:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.9,1,1))
85/35:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.9,1,1))
85/36:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.9,1,1))
85/37:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.9,1,1))
85/38:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.9,1,1))
85/39:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True, swarm_properties=(0.9,1,1))
85/40:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True)
85/41:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True)
85/42:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=True)
85/43:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=False)
85/44:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=False)
85/45:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=False)
85/46:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(card_sin_test, param_dict, maximize=False)
85/47:
param_dict = {"x":[0,10], "y":[0, 10]}
particle_swarm(gaussian_test, param_dict, maximize=False)
85/48:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False)
85/49:
param_dict = {"x":[0,10], "y":[0, 10]}
vect_func = np.vectorize(vectorize_test)
85/50:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False)
print(best, best_loc)
85/51:
param_dict = {"x":[0,10], "y":[0, 10]}
vect_func = np.vectorize(vectorize_test
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False)
85/52:
param_dict = {"x":[0,10], "y":[0, 10]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False)
85/53:
param_dict = {"x":[0,10], "y":[0, 10]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
85/54:
param_dict = {"x":[0,10], "y":[0, 10]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print(best, best_loc)
85/55:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 1, 200)
y1 = np.linspace(0, 1, 200)
85/56:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow', levels=50)
85/57:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 2, 200)
y1 = np.linspace(0, 2, 200)
85/58:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow', levels=50)
85/59:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 3, 200)
y1 = np.linspace(0, 3, 200)
85/60:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow', levels=50)
85/61:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print(best, best_loc)
85/62:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=True)
print(best, best_loc)
85/63:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=True)
print(best, best_loc)
85/64:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=True)
print(best, best_loc)
85/65:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=True)
print(best, best_loc)
85/66:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=True)
print(best, best_loc)
85/67:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=True)
print(best, best_loc)
85/68:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print(best, best_loc)
85/69:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print(best, best_loc)
85/70:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print(best, best_loc)
85/71:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print(best, best_loc)
85/72:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print(best, best_loc)
85/73:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print(best, best_loc)
85/74:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print(best, best_loc, best_iter)
85/75:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print(best, best_loc, best_iter, sep="\n")
85/76:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print(best, best_loc, best_iter, sep="\n")
85/77:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print(best, best_loc, best_iter, sep="\n")
85/78:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=True)
print(best, best_loc, best_iter, sep="\n")
85/79:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=True)
print(best, best_loc, best_iter, sep="\n")
85/80:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=True)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/81:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=True)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/82:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=True)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/83:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/84:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/85:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/86:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return x*y
85/87:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 3, 200)
y1 = np.linspace(0, 3, 200)
85/88:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow', levels=50)
85/89:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return x*y - x**2*y
85/90:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
x1 = np.linspace(0, 3, 200)
y1 = np.linspace(0, 3, 200)
85/91:
XX, YY = np.meshgrid(x, y)
XX1, YY1 = np.meshgrid(x1, y1)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX1, YY1, vectorize_test(XX1, YY1), cmap='rainbow', levels=50)
85/92:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/93:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/94:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return x * (y - 3)
85/95:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/96:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/97:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 4) * (y - 3)
85/98:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/99:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/100:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 2) * (y - 3)
85/101:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/102:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/103:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 2) * (y - 2)
85/104:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/105:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/106:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False)
print(best, best_loc)
85/107:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/108:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=True)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/109:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/110:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/111:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/112:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/113:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/114:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.sin(y)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
85/115:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/116:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/117:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False)
print(best, best_loc)
85/118: param_dict = {}
85/119:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/120:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x-1)*np.sin(y-1)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
85/121:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/122:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/123:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(3*x)*np.sin(4*x)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
85/124:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/125:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/126:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(0.1*x)*np.sin(0.2*x)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
85/127:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/128:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/129:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(0.5*x)*np.sin(0.5*x)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
85/130:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/131:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/132:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return 10*np.sin(1.1*x)*np.sin(1.1*x)/(x*y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
85/133:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/134:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/135:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
85/136:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/137:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/138:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)*np.sin(y)*np.cos(x)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
85/139:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/140:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/141:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)*np.sin(y)*np.cos(0.1*x)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
85/142:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/143:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/144:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def card_sin_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)*np.sin(y)*np.cos(0.9*x)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
85/145:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/146:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, card_sin_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/147:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def trig_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)*np.sin(y)*np.cos(0.9*x)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
85/148:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/149:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
85/150:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False)
print(best, best_loc)
85/151:
param_dict = {"x":[0,3], "y":[0,3]}
best, best_loc, best_particle, best_iter = particle_swarm(trig_test, param_dict)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
85/152:
param_dict = {"x":[0,3], "y":[0,3]}
best, best_loc, best_particle, best_iter = particle_swarm(trig_test, param_dict)
print("Best Value", best, "Best pos", best_loc, sep="\n")
85/153:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
85/154:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
85/155:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def trig_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)*np.sin(y)*np.cos(0.9*x)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
85/156:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
85/157:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
86/1:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
86/2:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def trig_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)*np.sin(y)*np.cos(0.9*x)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
86/3:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
86/4:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
86/5:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
86/6:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def trig_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)*np.sin(y)*np.cos(0.9*x)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
86/7:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
86/8:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
86/9:
param_dict = {"x":[0,3], "y":[0,3]}
best, best_loc, best_particle, best_iter = particle_swarm(trig_test, param_dict)
print("Best Value", best, "Best pos", best_loc, sep="\n")
86/10:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print("Best Value", best, "Best pos", best_loc, best_iter, sep="\n")
86/11:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False)
print("Best Value", best, "Best pos", best_loc, sep="\n")
87/1:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
87/2:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def trig_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)*np.sin(y)*np.cos(0.9*x)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
87/3:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
87/4:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
87/5:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False, plot=False)
print(best, best_loc)
88/1:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
88/2:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def trig_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)*np.sin(y)*np.cos(0.9*x)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
88/3:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
88/4:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
88/5:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False, plot=False)
print(best, best_loc)
88/6:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False, plot=False)
print(best, best_loc)
plt.plot(best_loc)
88/7:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False, plot=False)
print(best, best_loc)
plt.plot(best_iter)
88/8:
param_dict = {"x":[0,3], "y":[0,3]}
best, best_loc, best_particle, best_iter = particle_swarm(trig_test, param_dict, plot=False)
print("Best Value", best, "Best pos", best_loc, sep="\n")
88/9:
param_dict = {"x":[0,3], "y":[0,3]}
best, best_loc, best_particle, best_iter = particle_swarm(trig_test, param_dict, plot=False)
print("Best Value", best, "Best pos", best_loc, sep="\n")
plt.plot(best_iter)
88/10:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False, plot=False)
print("Best Value", best, "Best pos", best_loc, sep="\n")
plt.plot(best_iter)
88/11:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def trig_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)*np.sin(y)*np.cos(0.9*x)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
88/12:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
ax[0].colorbar
88/13:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
ax[0].colorbar()
88/14:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax0)
88/15:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax1 = ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax2 = ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax0, ax1, ax2)
88/16:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax1 = ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax2 = ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax0)
fig.colorbar(ax1)
fig.colorbar(ax2)
88/17:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,10))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax1 = ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax2 = ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax0)
fig.colorbar(ax1)
fig.colorbar(ax2)
88/18:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(25,5))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax1 = ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax2 = ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax0)
fig.colorbar(ax1)
fig.colorbar(ax2)
88/19:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(25,5))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax0)
ax1 = ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax1)
ax2 = ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax2)
88/20:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(25,5))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax[0].colorbar(ax0)
ax1 = ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax1)
ax2 = ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax2)
88/21:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(25,5))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax1 = ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax2 = ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax0, ax = ax0)
fig.colorbar(ax1)
fig.colorbar(ax2)
88/22:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(25,5))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax1 = ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax2 = ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax0, ax = ax[0])
fig.colorbar(ax1)
fig.colorbar(ax2)
88/23:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(25,5))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax1 = ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax2 = ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax0, ax = ax[0])
fig.colorbar(ax1, ax = ax[1])
fig.colorbar(ax2, ax = ax[2])
88/24:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20,5))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax1 = ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax2 = ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax0, ax = ax[0])
fig.colorbar(ax1, ax = ax[1])
fig.colorbar(ax2, ax = ax[2])
88/25:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False, plot=False)
print(best, best_loc)
plt.plot(best_iter)
88/26:
param_dict = {"x":[0,3], "y":[0,3]}
best, best_loc, best_particle, best_iter = particle_swarm(trig_test, param_dict, plot=False)
print("Best Value", best, "Best pos", best_loc, sep="\n")
plt.plot(best_iter)
88/27:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False, plot=False)
print("Best Value", best, "Best pos", best_loc, sep="\n")
plt.plot(best_iter)
88/28:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
from jupyterthemes import jtplot

jtplot.style()
88/29:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def trig_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)*np.sin(y)*np.cos(0.9*x)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
88/30:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
88/31:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20,5))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax1 = ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax2 = ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax0, ax = ax[0])
fig.colorbar(ax1, ax = ax[1])
fig.colorbar(ax2, ax = ax[2])
88/32:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False, plot=False)
print(best, best_loc)
plt.plot(best_iter)
88/33:
param_dict = {"x":[0,3], "y":[0,3]}
best, best_loc, best_particle, best_iter = particle_swarm(trig_test, param_dict, plot=False)
print("Best Value", best, "Best pos", best_loc, sep="\n")
plt.plot(best_iter)
88/34:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False, plot=False)
print("Best Value", best, "Best pos", best_loc, sep="\n")
plt.plot(best_iter)
88/35:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
88/36:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def trig_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)*np.sin(y)*np.cos(0.9*x)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
88/37:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
88/38:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20,5))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax1 = ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax2 = ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax0, ax = ax[0])
fig.colorbar(ax1, ax = ax[1])
fig.colorbar(ax2, ax = ax[2])
88/39:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False, plot=False)
print(best, best_loc)
plt.plot(best_iter)
89/1:
from pso.pso import particle_swarm
import numpy as np
import matplotlib.pyplot as plt
89/2:
def gaussian_test(x, y):
    """Test function to minimize"""
    return -np.exp(-x**2)*np.exp(-y**2)

def trig_test(x, y):
    """Test function to maximize"""
    return np.sin(x)*np.cos(y)*np.sin(y)*np.cos(0.9*x)

def vectorize_test(x, y):
    """Test function for np.vectorize"""
    return (x - 3) * (y - 2)
89/3:
x = np.linspace(0, 3, 200)
y = np.linspace(0, 3, 200)
89/4:
XX, YY = np.meshgrid(x, y)
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20,5))
ax0 = ax[0].contourf(XX, YY, gaussian_test(XX, YY), cmap='rainbow', levels=50)
ax1 = ax[1].contourf(XX, YY, trig_test(XX, YY), cmap='rainbow', levels=50)
ax2 = ax[2].contourf(XX, YY, vectorize_test(XX, YY), cmap='rainbow', levels=50)
fig.colorbar(ax0, ax = ax[0])
fig.colorbar(ax1, ax = ax[1])
fig.colorbar(ax2, ax = ax[2])
89/5:
param_dict = {"x":[0,10], "y":[0, 10]}
best, best_loc, best_particle, best_iter = particle_swarm(gaussian_test, param_dict, maximize=False, plot=False)
print(best, best_loc)
plt.plot(best_iter)
89/6:
param_dict = {"x":[0,3], "y":[0,3]}
best, best_loc, best_particle, best_iter = particle_swarm(trig_test, param_dict, plot=False)
print("Best Value", best, "Best pos", best_loc, sep="\n")
plt.plot(best_iter)
89/7:
param_dict = {"x":[0,3], "y":[0, 3]}
vect_func = np.vectorize(vectorize_test)
best, best_loc, best_particle, best_iter = particle_swarm(vect_func, param_dict, maximize=False, plot=False)
print("Best Value", best, "Best pos", best_loc, sep="\n")
plt.plot(best_iter)
91/1: import numpy as np
91/2: np.linspace?
91/3: np.linspace(0, 100, 1e6)
91/4: np.linspace(0, 100, 1*10**6)
91/5: np.linspace(0, 100, 10)
91/6: np.linspace(0, 100, 10, dtype="f4")
91/7: a = np.linspace(0, 100, 10)
91/8: a.dtype
91/9: np.linspace(0, 100, 10, dtype="f2")
91/10: np.linspace(0, 100, 10, dtype="f16")
91/11: np.linspace(0, 100, 10, dtype="f8")
92/1: from fdtd import update_fields
92/2: import numpy as np
92/3: np.zeros(10)
92/4: e = np.zeros(10)
92/5: b = np.zeros(10)
92/6: m = np.ones(10)
92/7: m
92/8: update_fields(e, h, m, 100)
92/9: update_fields(e, b, m, 100)
92/10: a[-1]
92/11: e[-1:]
92/12: e[:-2]
92/13: e[:-1]
92/14: e[:-1] = 1
92/15: e[-1] = 2
92/16: e
92/17: e[-1] = 0
92/18: e
92/19: e[:-1] = 2
92/20: e
92/21: e = 0
92/22: e
93/1: from fdtd import update_fields
93/2: import numpy as np
93/3: e = np.zeros(10)
93/4: h = np.zeros(10)
93/5: m = np.ones(10)
93/6: update_fields(e, b, m, 100)
93/7: update_fields(e, h, m, 100)
94/1: from fdtd import update_fields
94/2: import numpy as np
94/3: e = np.zeros(10)
94/4: h = np.zeros(10)
94/5: m = np.ones(10)
94/6: update_fields(e, h, m, 100)
94/7: update_fields(e, h, 1, 100)
94/8: update_fields(e, h, 1, 10000)
96/1: from band_model import qd_base_data as qbd
96/2: from band_model import qd_base_data as qbd
97/1: %prun python modules/scattering_matrix.py
97/2: %prunmodules/scattering_matrix.py
97/3: %prun modules/scattering_matrix.py
97/4: %run -p modules/scattering_matrix.py
97/5: %run -p modules/scattering_matrix.py
97/6: %run -p modules/scattering_matrix.py
97/7: %run -p modules/scattering_matrix.py
97/8: %run -p modules/scattering_matrix.py
97/9: %run -p modules/scattering_matrix.py
97/10: %run -p modules/scattering_matrix.py
97/11: %run -p modules/scattering_matrix.py
98/1: %run -p modules/scattering_matrix.py
98/2: %run -p modules/scattering_matrix.py
98/3: %run -p modules/scattering_matrix.py
98/4: %run -p modules/scattering_matrix.py
98/5: %run -p modules/scattering_matrix.py
98/6: %run -p modules/scattering_matrix.py
98/7: %run -p modules/scattering_matrix.py
98/8: %run -p modules/scattering_matrix.py
98/9: %run -p modules/scattering_matrix.py
98/10: %run -p modules/scattering_matrix.py
98/11: %run -p modules/scattering_matrix.py
98/12: %run -p modules/scattering_matrix.py
98/13: %run -p modules/scattering_matrix.py
98/14: %run -p modules/scattering_matrix.py
98/15: %run -p modules/scattering_matrix.py
98/16: %run -p modules/scattering_matrix.py
98/17: %run -p modules/scattering_matrix.py
98/18: %run -p modules/scattering_matrix.py
98/19: %run -p modules/scattering_matrix.py
98/20: %run -p modules/scattering_matrix.py
98/21: %run -p modules/scattering_matrix.py
101/1: from band_model import qd_base_data as qbd
101/2: qd = qbd.qd_results(2, 1, 0.08, 0.08, "BC")
101/3: qd.e_levels
101/4: qd = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
101/5: qd = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
101/6: qd.e_levels
101/7: qd.band
101/8: qd.norm_A
101/9: qd.norm_B
101/10: qd.norm_kin
101/11: qd.norm_k_in
101/12: qd.k_in
101/13: qd.k_out
101/14: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
101/15: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
101/16: qd_wavefunction.e_levels
101/17:
#angular momentum value
l = 0
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#Grid for exportation purposes
Phi, R = np.meshgrid(phi,r)

Phi = Phi.flatten()[R.flatten() < 3.5]
Psi = psi.flatten()[R.flatten() < 3.5]
R = R.flatten()[R.flatten() < 3.5]

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
data_to_export = {"Phi": Phi.flatten(), "R": R.flatten(), "Wavefunction": Psi.flatten()}
pd.DataFrame(data_to_export).to_csv(f"wavefunction_l{l}_n{k}.csv", index = False, sep=" ")
101/18:
#angular momentum value
l = 0
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#Grid for exportation purposes
Phi, R = np.meshgrid(phi,r)

Phi = Phi.flatten()[R.flatten() < 3.5]
Psi = psi.flatten()[R.flatten() < 3.5]
R = R.flatten()[R.flatten() < 3.5]

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
data_to_export = {"Phi": Phi.flatten(), "R": R.flatten(), "Wavefunction": Psi.flatten()}
pd.DataFrame(data_to_export).to_csv(f"wavefunction_l{l}_n{k}.csv", index = False, sep=" ")
101/19:
from band_model import qd_base_data as qbd
import numpy as np
101/20:
#angular momentum value
l = 0
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#Grid for exportation purposes
Phi, R = np.meshgrid(phi,r)

Phi = Phi.flatten()[R.flatten() < 3.5]
Psi = psi.flatten()[R.flatten() < 3.5]
R = R.flatten()[R.flatten() < 3.5]

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
data_to_export = {"Phi": Phi.flatten(), "R": R.flatten(), "Wavefunction": Psi.flatten()}
pd.DataFrame(data_to_export).to_csv(f"wavefunction_l{l}_n{k}.csv", index = False, sep=" ")
101/21:
from band_model import qd_base_data as qbd
from scipy import special
import numpy as np
101/22:
#angular momentum value
l = 0
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#Grid for exportation purposes
Phi, R = np.meshgrid(phi,r)

Phi = Phi.flatten()[R.flatten() < 3.5]
Psi = psi.flatten()[R.flatten() < 3.5]
R = R.flatten()[R.flatten() < 3.5]

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
data_to_export = {"Phi": Phi.flatten(), "R": R.flatten(), "Wavefunction": Psi.flatten()}
pd.DataFrame(data_to_export).to_csv(f"wavefunction_l{l}_n{k}.csv", index = False, sep=" ")
101/23:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import numpy as np
101/24:
#angular momentum value
l = 0
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#Grid for exportation purposes
Phi, R = np.meshgrid(phi,r)

Phi = Phi.flatten()[R.flatten() < 3.5]
Psi = psi.flatten()[R.flatten() < 3.5]
R = R.flatten()[R.flatten() < 3.5]

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
data_to_export = {"Phi": Phi.flatten(), "R": R.flatten(), "Wavefunction": Psi.flatten()}
pd.DataFrame(data_to_export).to_csv(f"wavefunction_l{l}_n{k}.csv", index = False, sep=" ")
101/25:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
%matplotlib inline
101/26:
#angular momentum value
l = 0
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#Grid for exportation purposes
Phi, R = np.meshgrid(phi,r)

Phi = Phi.flatten()[R.flatten() < 3.5]
Psi = psi.flatten()[R.flatten() < 3.5]
R = R.flatten()[R.flatten() < 3.5]

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
data_to_export = {"Phi": Phi.flatten(), "R": R.flatten(), "Wavefunction": Psi.flatten()}
pd.DataFrame(data_to_export).to_csv(f"wavefunction_l{l}_n{k}.csv", index = False, sep=" ")
101/27:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
%matplotlib inline
101/28:
#angular momentum value
l = 0
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#Grid for exportation purposes
Phi, R = np.meshgrid(phi,r)

Phi = Phi.flatten()[R.flatten() < 3.5]
Psi = psi.flatten()[R.flatten() < 3.5]
R = R.flatten()[R.flatten() < 3.5]

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
data_to_export = {"Phi": Phi.flatten(), "R": R.flatten(), "Wavefunction": Psi.flatten()}
pd.DataFrame(data_to_export).to_csv(f"wavefunction_l{l}_n{k}.csv", index = False, sep=" ")
101/29:
#angular momentum value
l = 0
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
101/30:
#angular momentum value
l = 1
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
101/31:
#angular momentum value
l = 1
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
101/32:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
101/33:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(0, 4, 100)
y = np.linspace(0, 4, 100)
z = np.linspace(0, 4, 100)
qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
101/34:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
101/35: importlib.reload(band_models)
101/36: importlib.reload(band_model)
101/37: importlib.reload(qbd)
101/38:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(0, 4, 100)
y = np.linspace(0, 4, 100)
z = np.linspace(0, 4, 100)
qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
101/39: importlib.reload(qbd)
101/40:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(0, 4, 100)
y = np.linspace(0, 4, 100)
z = np.linspace(0, 4, 100)
qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
103/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
103/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
103/3: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
103/4: qd_wavefunction.e_levels
103/5:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
103/6:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(0, 4, 100)
y = np.linspace(0, 4, 100)
z = np.linspace(0, 4, 100)
qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
103/7:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(0, 4, 100)
y = np.linspace(0, 4, 100)
z = np.linspace(0, 4, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
103/8:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(0, 4, 100)
y = np.linspace(0, 4, 100)
z = np.linspace(0, 4, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
103/9: print(XX[:,0,:].shape)
103/10: plt.contourf(XX[:,0,:], YY[:,0,:],norm_wavefunction[:,0,:])
103/11: print(norm_wavefunction[:, 0, :])
103/12: plt.contourf(XX[:,0,:].flatten(), YY[:,0,:].flatten(),norm_wavefunction[:,0,:].flatten())
103/13: plt.contourf(XX[:,0,:], YY[:,0,:],norm_wavefunction[:,0,:]
103/14: plt.contourf(XX[:,0,:], YY[:,0,:],norm_wavefunction[:,0,:])
103/15: print(norm_wavefunction[:, 0, :])
103/16: plt.contourf(XX[:,0,:], YY[:,0,:],norm_wavefunction[:,0,:], cmap=cm.jet)
103/17: pprint(norm_wavefunction[:, 0, :])
103/18: print(norm_wavefunction[:, 0, :])
103/19: print(norm_wavefunction[0, 0, :])
103/20: print(norm_wavefunction[:, 0, :])
103/21:
plt.contourf(XX[:,0,:], YY[:,0,:],norm_wavefunction[:,0,:], cmap=cm.jet)
plt.show()
103/22:
plt.contour(XX[:,0,:], YY[:,0,:],norm_wavefunction[:,0,:], cmap=cm.jet)
plt.show()
103/23: print(XX[:, 0, :])
103/24: print(YY[:, 0, :])
103/25:
plt.contour(XX[0, :, :], YY[0, :, :],norm_wavefunction[:,0,:], cmap=cm.jet)
plt.show()
103/26:
plt.contour(XX[0, :, :], YY[:, 0, :],norm_wavefunction[:,0,:], cmap=cm.jet)
plt.show()
103/27: print(XX[:, 0, :])
103/28: print(XX[:, 1, :])
103/29: print(XX[:, 2, :])
103/30: print(XX[0, 2, :])
103/31: print(XX[0, 2, 0])
103/32: print(XX[:, 2, 0])
103/33: XX
103/34: XX[0]
103/35:
plt.contour(XX[0], YY[0],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/36: YY[0]
103/37: YY[:, 0, :]
103/38:
plt.contour(XX[0], YY[:, 0, :],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/39:
YY[:, 0, :]
XX
103/40: YY[:, :, 0]
103/41: YY[:]
103/42: YY
103/43: ZZ
103/44: ZZ[0]
103/45:
plt.contour(XX[0], ZZ[0],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/46:
plt.contourf(XX[0], ZZ[0],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/47:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
103/48: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
103/49: qd_wavefunction.e_levels
103/50:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
103/51:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(0, 4, 100)
y = np.linspace(0, 4, 100)
z = np.linspace(0, 4, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
103/52:
plt.contourf(XX[0], ZZ[0],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/53:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(0, 4, 100)
y = np.linspace(0, 4, 100)
z = np.linspace(0, 4, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
103/54:
plt.contourf(XX[0], ZZ[0],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/55:
# l/m/n values
l = 0
m = 0
n = 1

x = np.linspace(0, 4, 100)
y = np.linspace(0, 4, 100)
z = np.linspace(0, 4, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
103/56:
plt.contourf(XX[0], ZZ[0],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/57:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(0, 4, 100)
y = np.linspace(0, 4, 100)
z = np.linspace(0, 4, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
103/58:
plt.contourf(XX[0], ZZ[0],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/59:
plt.contourf(XX[0], ZZ[1],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/60:
plt.contourf(XX[0], ZZ[50],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/61:
plt.contourf(XX[50], ZZ[50],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/62:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(0, 4, 100)
y = np.linspace(0, 4, 100)
z = np.linspace(0, 4, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
103/63:
plt.contourf(XX[50], ZZ[50],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/64:
plt.contourf(XX[:, 0, :], ZZ[50],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/65:
plt.contourf(XX[0], ZZ[50],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/66:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(0, 4, 50)
y = np.linspace(0, 4, 50)
z = np.linspace(0, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
103/67:
plt.contourf(XX[0], ZZ[50],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/68:
plt.contourf(XX[0], ZZ[0],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/69:
# l/m/n values
l = 1
m = 1
n = 0

x = np.linspace(0, 4, 50)
y = np.linspace(0, 4, 50)
z = np.linspace(0, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
103/70:
plt.contourf(XX[0], ZZ[0],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/71:
# l/m/n values
l = 2
m = 1
n = 0

x = np.linspace(0, 4, 50)
y = np.linspace(0, 4, 50)
z = np.linspace(0, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
103/72:
plt.contourf(XX[0], ZZ[0],norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/73:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(0, 4, 50)
y = np.linspace(0, 4, 50)
z = np.linspace(0, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
103/74:
plt.contourf(XX[0], ZZ[0],norm_wavefunction[0], cmap=cm.jet)
plt.show()
104/1: import numpy as np
104/2: from scipy import special
103/75: YY[0]
103/76: XX[0]
103/77: XX[1, :, :]
103/78: XX[:, :, 0]
103/79: XX[:, 0, :]
103/80: XX[:, 2, :]
103/81: XX[0]
103/82: YY[:, 0, :]
103/83: YY[:, :, 0]
103/84: YY[0]
103/85: YY[0, :, :]
103/86: YY[:, 0, :]
103/87: YY[:, :, 0]
103/88: XX[:, :, 0]
103/89:
plt.contourf(XX[:, :, 0], YY[:, :, 0], norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/90:
plt.contourf(XX[:, :, 0], YY[:, :, 0], norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/91:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
103/92:
plt.contourf(XX[:, :, 0], YY[:, :, 0], norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/93:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
103/94:
plt.contourf(XX[:, :, 0], YY[:, :, 0], norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/95:
fig, ax = plt.subplots(figsize=(3,3))
ax.contourf(XX[:, :, 0], YY[:, :, 0], norm_wavefunction[:, :, 0], cmap=cm.jet)
ax.show()
103/96:
fig, ax = plt.subplots(figsize=(3,3))
ax.contourf(XX[:, :, 0], YY[:, :, 0], norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/97:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 0], YY[:, :, 0], norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/98: YY[:, :, 0]
103/99:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
103/100:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 0], YY[:, :, 0], norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/101:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[0], ZZ[0], norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/102:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 0], YY[:, :, 0], norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/103:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], YY[:, :, 50], norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/104:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], YY[:, :, 25], norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/105:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 49], YY[:, :, 49], norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/106:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 49], YY[:, :, 49], norm_wavefunction[:, :, 49], cmap=cm.jet)
plt.show()
103/107:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], YY[:, :, 25], norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
103/108:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 0], YY[:, :, 0], norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/109:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 10], YY[:, :, 10], norm_wavefunction[:, :, 10], cmap=cm.jet)
plt.show()
103/110:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,np.log(psi), cmap=cm.jet)
103/111:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[0], YY[0], norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/112:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[0], ZZ[0], norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/113:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[25], ZZ[25], norm_wavefunction[25], cmap=cm.jet)
plt.show()
103/114:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(YY[25], ZZ[25], norm_wavefunction[25], cmap=cm.jet)
plt.show()
103/115:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(YY[:, :, 25], ZZ[25], norm_wavefunction[25], cmap=cm.jet)
plt.show()
103/116:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(YY[:, :, 24], ZZ[24], norm_wavefunction[24], cmap=cm.jet)
plt.show()
103/117:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(YY[:, 24, :], ZZ[24], norm_wavefunction[24], cmap=cm.jet)
plt.show()
103/118:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[24], ZZ[24], norm_wavefunction[24], cmap=cm.jet)
plt.show()
103/119:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 0], YY[:, :, 0], norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/120:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], YY[:, :, 25], norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
103/121:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
103/122:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], YY[:, :, 25], np.log(norm_wavefunction[:, :, 25]), cmap=cm.jet)
plt.show()
103/123:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], YY[:, :, 25], norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
103/124:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,np.pi/2,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
103/125:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
103/126:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[25], ZZ[25], norm_wavefunction[25], cmap=cm.jet)
plt.show()
103/127:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[25], ZZ[0], norm_wavefunction[25], cmap=cm.jet)
plt.show()
103/128:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[25], ZZ[0], norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/129:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[25], ZZ[25], norm_wavefunction[15], cmap=cm.jet)
plt.show()
103/130: Z[25]
103/131: ZZ[25]
103/132: ZZ[0]
103/133: ZZ[:, 0, :]
103/134: ZZ[:, :, 0]
103/135: ZZ[:, :, 25]
103/136: ZZ[25]
103/137: ZZ[:, 0]
103/138: ZZ[:, :, 0]
103/139: ZZ[0]
103/140: XX[0]
103/141:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(ZZ[0], XX[0], norm_wavefunction[15], cmap=cm.jet)
plt.show()
103/142:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(ZZ[0], XX[0], norm_wavefunction[0], cmap=cm.jet)
plt.show()
103/143:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(ZZ[25], XX[25], norm_wavefunction[25], cmap=cm.jet)
plt.show()
103/144: ZZ[:]
103/145: ZZ[0,0,0]
103/146: ZZ[0,0,1]
103/147: ZZ[0,1,0]
103/148: ZZ[0, : , 0]
103/149: ZZ[0, : , :]
103/150: ZZ[:, : , 0]
103/151:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 0], ZZ[:, :, 0] norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/152:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 0], ZZ[:, :, 0], norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/153: XX[:, :, 0]
103/154: ZZ[:, : , 0]
103/155: ZZ[:, : , 0]
103/156: ZZ[:, 1 , 0]
103/157: ZZ[:, 2 , 0]
103/158: ZZ[:, 3 , 0]
103/159: ZZ[2, : , 0]
103/160: ZZ[0]
103/161: ZZ[0].T
103/162:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 0], ZZ[0].T, norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
103/163: ZZ
104/3: a = np.linspace(0, 10, 10)
104/4: b = np.linspace(0, 10, 10)
104/5: c = np.linspace(0, 10, 10)
104/6: AA, BB, CC = np.meshgrid(a, b, c)
104/7: AA
104/8: BB
104/9: CC
104/10: AA[0, 0, 0]
104/11: AA[0, 0, 1]
104/12: AA[0, 0, 2]
104/13: AA[0, 1, 2]
104/14: AA[0, 0, 0]
104/15: AA[1, 0, 0]
104/16: AA[1, 1, 0]
104/17: AA[2, 1, 0]
104/18: AA[2, 1, 1]
104/19: AA[2, 2, 1]
104/20: BB[0, 0, 0]
104/21: BB[0, 0, 1]
104/22: BB[1, 0, 0]
104/23: CC[0, 0, 1]
104/24: CC[1, 0, 0]
105/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
105/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
105/3: qd_wavefunction.e_levels
105/4:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
105/5:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
105/6:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 0], ZZ[0].T, norm_wavefunction[:, :, 0], cmap=cm.jet)
plt.show()
105/7:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 0], ZZ[0].T, np.absolute(norm_wavefunction[:, :, 0])**2, cmap=cm.jet)
plt.show()
105/8:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.absolute(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
106/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
106/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
106/3: qd_wavefunction.e_levels
106/4:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
106/5:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
106/6:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.absolute(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
106/7: norm_wavefunction
106/8: importlib.reload(qbd)
106/9: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
106/10: qd_wavefunction.e_levels
106/11:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
106/12:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
106/13:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
106/14:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.absolute(norm_wavefunction[:, 25, :])**2, cmap=cm.jet)
plt.show()
106/15:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, 25, :], cmap=cm.jet)
plt.show()
106/16:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
107/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
107/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
107/3: qd_wavefunction.e_levels
107/4:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
107/5:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
107/6:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
107/7: importlib.reload(qbd)
107/8: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
107/9: qd_wavefunction.e_levels
107/10:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
107/11:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
107/12:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
107/13: importlib.reload(qbd)
107/14: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
107/15: qd_wavefunction.e_levels
107/16:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
107/17:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
107/18:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
107/19:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
107/20:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
107/21: importlib.reload(qbd)
107/22: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
107/23: qd_wavefunction.e_levels
107/24:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
107/25:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
107/26:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
107/27: importlib.reload(qbd)
107/28: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
107/29: qd_wavefunction.e_levels
107/30:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
107/31:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
107/32:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
107/33:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
107/34:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
107/35:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
107/36:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
107/37:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
107/38:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.absolute(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
108/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
108/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
108/3: qd_wavefunction.e_levels
108/4:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
108/5:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
z = np.linspace(-4, 4, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
108/6:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.absolute(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
108/7:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
108/8: qd_wavefunction.norm_envolute(4, 10, "S", 0, 0, 0, 1, 1)
108/9: XX, YY, ZZ, envolute = qd_wavefunction.norm_envolute(4, 10, "S", 0, 0, 0, 1, 1)
108/10: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(4, 10, "S", 0, 0, 0, 1, 1)
108/11:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, envolute[:, :, 25], cmap=cm.jet)
plt.show()
108/12: print(XX_env.shape)
108/13: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(0.2, 5, "S", 0, 0, 0, 1, 1)
108/14: print(XX_env.shape)
108/15: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 0, 1, 1)
108/16: print(XX_env.shape)
108/17: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 0, 1, 1)
108/18: print(XX_env.shape)
108/19: importlib.reload(qbd)
108/20:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, envolute[:, :, 25], cmap=cm.jet)
plt.show()
108/21: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 0, 1, 1)
108/22: print(XX_env.shape)
109/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
109/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
109/3: qd_wavefunction.e_levels
109/4: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 0, 1, 1)
109/5: print(XX_env.shape)
109/6: importlib.reload(qbd)
109/7: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
109/8: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 0, 1, 1)
109/9: importlib.reload(qbd)
109/10: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
109/11: qd_wavefunction.e_levels
109/12:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
109/13: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 0, 1, 1)
109/14: print(XX_env.shape)
109/15:
half_size = 5
lat_size = 0.25

np.arange(-half_size, half_size, half_size/lat_size)
109/16:
half_size = 5
lat_size = 0.25

np.arange(-half_size, half_size, lat_size)
109/17: importlib.reload(qbd)
109/18: importlib.reload(qbd)
109/19: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
109/20: qd_wavefunction.e_levels
109/21: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 0, 1, 1)
109/22: print(XX_env.shape)
109/23:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, envolute[:, :, 25], cmap=cm.jet)
plt.show()
109/24: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 2, 0, 1, 1)
109/25: print(XX_env.shape)
109/26:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, envolute[:, :, 25], cmap=cm.jet)
plt.show()
109/27: envolute
109/28: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 1, 0, 1, 1)
109/29: print(XX_env.shape)
109/30:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, envolute[:, :, 25], cmap=cm.jet)
plt.show()
109/31: envolute
109/32: importlib.reload(qbd)
109/33: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
109/34: qd_wavefunction.e_levels
109/35: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 1, 0, 1, 1)
109/36: print(XX_env.shape)
109/37:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, envolute[:, :, 25], cmap=cm.jet)
plt.show()
109/38: envolute
109/39: importlib.reload(qbd)
109/40: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
109/41: qd_wavefunction.e_levels
109/42: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 1, 0, 1, 1)
109/43: importlib.reload(qbd)
109/44: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 1, 0, 1, 1)
110/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
110/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
110/3: qd_wavefunction.e_levels
110/4: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 1, 0, 1, 1)
110/5: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 1, 0, 1, 1)
110/6: importlib.reload(qbd)
110/7: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
110/8: qd_wavefunction.e_levels
110/9: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 1, 0, 1, 1)
110/10:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
110/11: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 1, 0, 1, 1)
110/12:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
print(norm_wavefunction)
110/13: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 1, 0, 0, 1, 1)
110/14:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, envolute[:, :, 25], cmap=cm.jet)
plt.show()
110/15:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.log(envolute[:, :, 25]), cmap=cm.jet)
plt.show()
111/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
111/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
111/3: qd_wavefunction.e_levels
111/4:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
111/5:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
111/6:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
111/7:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.absolute(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
111/8: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 2, 0, 0, 1, 1)
111/9: print(XX_env.shape)
111/10:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.log(envolute[:, :, 25]), cmap=cm.jet)
plt.show()
111/11:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, envolute[:, :, 25], cmap=cm.jet)
plt.show()
111/12:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.absolute(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
111/13: envolute
111/14:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.absolute(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
111/15:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
111/16:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.absolute(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
111/17: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 0, 1, 1)
111/18: print(XX_env.shape)
111/19:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.absolute(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
111/20:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.log(np.absolute(envolute[:, :, 0])**2), cmap=cm.jet)
plt.show()
111/21:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
111/22: np.sum(np.abs(envolute))
111/23: np.sum(np.abs(envolute))*0.2
111/24: np.sum(np.abs(envolute)**2)*0.2
111/25: np.sum(np.abs(norm_wavefunction)**2)
111/26: print(x)
111/27: print(x[1:]-x[:-1])
111/28: np.sum(np.abs(norm_wavefunction)**2)*0.20408163
111/29: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
111/30: np.sum(np.abs(envolute)**2)*(0.2)**3
112/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
112/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
112/3: qd_wavefunction.e_levels
112/4:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
112/5:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
112/6: np.sum(norm_wavefunction)*(0.20408163)**3
112/7:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.absolute(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
112/8:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
112/9: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 0, 1, 1)
112/10: print(XX_env.shape)
112/11:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
112/12: np.sum(envolute)*(0.2)**3
112/13: np.sum(np.absolute(envolute)**2)*(0.2)**3
112/14: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "T", 0, 0, 0, 1, 1)
112/15: print(XX_env.shape)
112/16:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
112/17: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "X", 0, 0, 0, 1, 1)
112/18: print(XX_env.shape)
112/19:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
112/20: np.sum(np.absolute(envolute)**2)*(0.2)**3
112/21: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 0, 1, 1)
112/22: print(XX_env.shape)
112/23:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
112/24: np.sum(np.absolute(envolute)**2)*(0.2)**3
112/25: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "Y", 0, 0, 0, 1, 1)
112/26: print(XX_env.shape)
112/27:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
112/28: np.sum(np.absolute(envolute)**2)*(0.2)**3
112/29: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "Z", 0, 0, 0, 1, 1)
112/30: print(XX_env.shape)
112/31:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
112/32: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
113/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
113/3: qd_wavefunction.e_levels
113/4: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "Z", 0, 0, 0, 1, 1)
113/5: print(XX_env.shape)
113/6:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/7: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/8: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 0, 1, 1)
113/9: print(XX_env.shape)
113/10:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/11: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/12: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "X", 0, 0, 0, 1, 1)
113/13: print(XX_env.shape)
113/14:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/15: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/16: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "Y", 0, 0, 0, 1, 1)
113/17: print(XX_env.shape)
113/18:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/19: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/20: 0.28+0.719
113/21: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 0, 1, 1)
113/22: print(XX_env.shape)
113/23:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/24: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/25: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "Z", 0, 0, 0, 1, 1)
113/26: print(XX_env.shape)
113/27:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/28: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/29: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "Z", 0, 0, 0, 1.42, 1)
113/30: print(XX_env.shape)
113/31:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/32: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/33: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 0, 1.42, 1)
113/34: print(XX_env.shape)
113/35:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/36: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/37:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.log(np.abs(envolute[:, :, 0])**2), cmap=cm.jet)
plt.show()
113/38:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/39: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 1, 0, 0, 1.42, 1)
113/40: print(XX_env.shape)
113/41:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/42:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
113/43: np.sum(np.absolute(envolute)*(0.2)**3
113/44: np.sum(np.absolute(envolute))*(0.2)**3
113/45: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/46: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "Z", 1, 0, 0, 1.42, 1)
113/47: print(XX_env.shape)
113/48:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
113/49: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/50: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 1, 0, 0, 1.42, 1)
113/51: print(XX_env.shape)
113/52:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
113/53: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/54: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "X", 1, 0, 0, 1.42, 1)
113/55: print(XX_env.shape)
113/56:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
113/57: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/58: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "Y", 1, 0, 0, 1.42, 1)
113/59: print(XX_env.shape)
113/60:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
113/61: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/62: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "Y", 0, 0, 1, 1.42, 1)
113/63: print(XX_env.shape)
113/64:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
113/65: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "X", 0, 0, 1, 1.42, 1)
113/66: print(XX_env.shape)
113/67:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
113/68: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 0, 0, 1, 1.42, 1)
113/69: print(XX_env.shape)
113/70:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
113/71: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/72: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "Z", 0, 0, 1, 1.42, 1)
113/73: print(XX_env.shape)
113/74:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
113/75: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/76: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "Z", 1, 0, 0, 1.42, 1)
113/77: print(XX_env.shape)
113/78:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
113/79: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/80: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "s", 1, 0, 0, 1.42, 1)
113/81: print(XX_env.shape)
113/82: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 1, 0, 0, 1.42, 1)
113/83: print(XX_env.shape)
113/84:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
113/85: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/86:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
113/87: importlib.reload(qbd)
113/88: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
113/89: qd_wavefunction.e_levels
113/90: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(5, 0.2, "S", 1, 0, 0, 1.42, 1)
113/91: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.15, "S", 1, 0, 0, 1.42, 1)
113/92:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
113/93: np.sum(np.absolute(envolute)**2)*(0.2)**3
113/94: np.sum(np.absolute(envolute)**2)*(0.15)**3
113/95: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(7, 0.15, "S", 1, 0, 0, 1.42, 1)
113/96:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
113/97: np.sum(np.absolute(envolute)**2)*(0.15)**3
113/98:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 50])**2, cmap=cm.jet)
plt.show()
113/99: np.sum(np.absolute(envolute)**2)*(0.15)**3
113/100: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(7, 0.15, "Z", 1, 0, 0, 1.42, 1)
113/101:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 50])**2, cmap=cm.jet)
plt.show()
113/102: np.sum(np.absolute(envolute)**2)*(0.15)**3
113/103: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(7, 0.15, "Z", 2, 0, 0, 1.42, 1)
113/104:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 50])**2, cmap=cm.jet)
plt.show()
113/105: np.sum(np.absolute(envolute)**2)*(0.15)**3
113/106: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(7, 0.15, "S", 2, 0, 0, 1.42, 1)
113/107:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 50])**2, cmap=cm.jet)
plt.show()
113/108: np.sum(np.absolute(envolute)**2)*(0.15)**3
113/109: np.pi/7
113/110: importlib.reload(qbd)
113/111: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
113/112: qd_wavefunction.e_levels
113/113: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(7, 0.15, "S", 2, 0, 0, 1.42, 1)
113/114: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.15, "S", 2, 0, 0, 1.42, 1)
113/115: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.15, "S", 0, 0, 0, 1.42, 1)
113/116: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.5, "S", 0, 0, 0, 1.42, 1)
113/117:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 50])**2, cmap=cm.jet)
plt.show()
113/118:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/119: np.sum(np.absolute(envolute)**2)*(0.15)**3
113/120: importlib.reload(qbd)
113/121: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
113/122: qd_wavefunction.e_levels
113/123: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.5, "S", 0, 0, 0, 1.42, 1)
113/124: importlib.reload(qbd)
113/125: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
113/126: qd_wavefunction.e_levels
113/127: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.5, "S", 0, 0, 0, 1.42, 1)
113/128: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.1, "S", 0, 0, 0, 1.42, 1)
113/129:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/130: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.05, "S", 0, 0, 0, 1.42, 1)
113/131:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/132: np.sum(np.absolute(envolute)**2)*(0.15)**3
113/133: np.sum(np.absolute(envolute)**2)*(0.05)**3
113/134: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.05, "Z", 0, 0, 0, 1.42, 1)
113/135:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/136: np.sum(np.absolute(envolute)**2)*(0.05)**3
113/137: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.05, "Z", 1, 0, 0, 1.42, 1)
113/138:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/139: np.sum(np.absolute(envolute)**2)*(0.05)**3
113/140: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.05, "S", 1, 0, 0, 1.42, 1)
113/141:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/142: np.sum(np.absolute(envolute)**2)*(0.05)**3
113/143: importlib.reload(qbd)
113/144: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
113/145: qd_wavefunction.e_levels
113/146: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.05, "S", 1, 0, 0, 1.42, 1)
113/147:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/148: np.sum(np.absolute(envolute)**2)*(0.05)**3
113/149: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.15, "S", 1, 0, 0, 1.42, 1)
113/150:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
113/151:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
114/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
114/2: importlib.reload(qbd)
114/3: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
114/4: qd_wavefunction.e_levels
114/5: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.15, "S", 1, 0, 0, 1.42, 1)
114/6:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
114/7: np.sum(np.absolute(envolute)**2)*(0.05)**3
114/8: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
114/9: qd_wavefunction.e_levels
114/10: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.15, "S", 1, 0, 0, 1.42, 1)
114/11:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
114/12: np.sum(np.absolute(envolute)**2)*(0.05)**3
114/13: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.15, "Z", 1, 0, 0, 1.42, 1)
114/14:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
114/15: np.sum(np.absolute(envolute)**2)*(0.05)**3
114/16: np.sum(np.absolute(envolute)**2)*(0.15)**3
114/17: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.15, "S", 1, 0, 0, 1.42, 1)
114/18:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
114/19: np.sum(np.absolute(envolute)**2)*(0.15)**3
115/1: importlib.reload(qbd)
115/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
115/3: qd_wavefunction.e_levels
115/4: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.15, "S", 1, 0, 0, 1.42, 1)
115/5:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
115/6:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
115/7: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
115/8: qd_wavefunction.e_levels
115/9: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.15, "S", 1, 0, 0, 1.42, 1)
115/10:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
115/11: np.sum(np.absolute(envolute)**2)*(0.15)**3
116/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
116/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
116/3: qd_wavefunction.e_levels
116/4: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.15, "S", 1, 0, 0, 1.42, 1)
117/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
117/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
117/3: qd_wavefunction.e_levels
117/4: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(3, 0.15, "S", 1, 0, 0, 1.42, 1)
117/5:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[0].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
117/6: np.sum(np.absolute(envolute)**2)*(0.15)**3
117/7:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
117/8: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(30, 0.15, "S", 1, 0, 0, 1.42, 1)
117/9:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
117/10: np.sum(np.absolute(envolute)**2)*(0.15)**3
117/11: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(30, 0.15, "Z", 1, 0, 0, 1.42, 1)
117/12:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
117/13: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(10, 0.15, "S", 0, 0, 0, 1.42, 1)
117/14:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
117/15: np.sum(np.absolute(envolute)**2)*(0.15)**3
117/16: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(10, 0.15, "Z", 0, 0, 0, 1.42, 1)
117/17:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
117/18: np.sum(np.absolute(envolute)**2)*(0.15)**3
118/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
118/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
118/3: qd_wavefunction.e_levels
118/4: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(10, 0.15, "Z", 0, 0, 0, 1.42, 1)
118/5:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
119/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
119/2:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
119/3: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
119/4: qd_wavefunction.e_levels
119/5: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(10, 0.15, "Z", 0, 0, 0, 1.42, 1)
119/6:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
119/7: np.sum(np.absolute(envolute)**2)*(0.15)**3
119/8: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(10, 0.15, "S", 0, 0, 0, 1.42, 1)
119/9:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
119/10: np.sum(np.absolute(envolute)**2)*(0.15)**3
119/11: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(10, 0.15, "S", 1, 0, 0, 1.42, 1)
119/12:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
119/13: np.sum(np.absolute(envolute)**2)*(0.15)**3
119/14: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(10, 0.15, "z", 1, 0, 0, 1.42, 1)
119/15: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(10, 0.15, "Z", 1, 0, 0, 1.42, 1)
119/16:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
119/17: np.sum(np.absolute(envolute)**2)*(0.15)**3
120/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
120/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
120/3: qd_wavefunction.e_levels
120/4: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(30, 1.5, "Z", 1, 0, 0, 1.42, 1)
120/5: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(20, 1.5, "Z", 1, 0, 0, 1.42, 1)
120/6:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
120/7: np.sum(np.absolute(envolute)**2)*(0.15)**3
120/8: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(20, 1.5, "S", 1, 0, 0, 1.42, 1)
120/9:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
120/10: np.sum(np.absolute(envolute)**2)*(0.15)**3
120/11: np.sum(np.absolute(envolute)**2)*(1.5)**3
120/12: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(20, 1.5, "Z", 1, 0, 0, 1.42, 1)
120/13:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
120/14: np.sum(np.absolute(envolute)**2)*(1.5)**3
121/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
121/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
121/3: qd_wavefunction.e_levels
121/4: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(20, 1.5, "S", 1, 0, 0, 1.42, 1)
121/5: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(20, 1.5, "Z", 1, 0, 0, 1.42, 1)
122/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
122/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
122/3: qd_wavefunction.e_levels
122/4: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(20, 1.5, "Z", 1, 0, 0, 1.42, 1)
122/5: XX_env, YY_env, ZZ_env, envolute = qd_wavefunction.norm_envolute(20, 1.5, "S", 1, 0, 0, 1.42, 1)
123/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
123/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
123/3: qd_wavefunction.e_levels
123/4: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(20, 1.5, "S", 1, 0, 0, 1.42, 1)
123/5: print(t_matrix)
123/6: print(t_matrix[10])
123/7: print(t_matrix[20])
123/8: importlib.reload(qbd)
123/9: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(20, 1.5, "S", 1, 0, 0, 1.42, 1)
124/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
124/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
124/3: qd_wavefunction.e_levels
124/4: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(20, 1.5, "S", 1, 0, 0, 1.42, 1)
124/5: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(20, 1.5, "S", 1, 0, 0, 1.42, 1)
124/6: importlib.reload(qbd)
124/7: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(20, 1.5, "S", 1, 0, 0, 1.42, 1)
124/8: print(t_matrix[20])
124/9:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
124/10: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
124/11: qd_wavefunction.e_levels
124/12: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(20, 1.5, "S", 1, 0, 0, 1.42, 1)
125/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
125/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
125/3: qd_wavefunction.e_levels
125/4: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(20, 1.5, "S", 1, 0, 0, 1.42, 1)
125/5: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(20, 1.5, "S", 1, 0, 0, 1.42, 1)
125/6:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 10], ZZ_env[10].T, np.abs(envolute[:, :, 10])**2, cmap=cm.jet)
plt.show()
125/7:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
125/8: np.sum(np.absolute(envolute)**2)*(1.5)**3
125/9: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(20, 1.5, "Z", 1, 0, 0, 1.42, 1)
125/10:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
125/11: np.sum(np.absolute(envolute)**2)*(1.5)**3
125/12: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "Z", 1, 0, 0, 1.42, 1)
125/13:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
125/14: np.sum(np.absolute(envolute)**2)*(1.5)**3
125/15: np.sum(np.absolute(envolute)**2)*(0.2)**3
125/16: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "S", 1, 0, 0, 1.42, 1)
125/17:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
125/18: np.sum(np.absolute(envolute)**2)*(0.2)**3
128/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
128/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
128/3: qd_wavefunction.e_levels
128/4: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "S", 1, 0, 0, 1.42, 1)
128/5:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
128/6: np.sum(np.absolute(envolute)**2)*(0.2)**3
128/7: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "Z", 1, 0, 0, 1.42, 1)
128/8:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
128/9:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
128/10: np.sum(np.absolute(envolute)**2)*(0.2)**3
128/11: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "Z", 1, 0, 0, 1.42, 1)
128/12:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
128/13: np.sum(np.absolute(envolute)**2)*(0.2)**3
128/14: np.sum(np.absolute(envolute)**2)*(0.1)**3
128/15: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "S", 1, 0, 0, 1.42, 1)
128/16:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
128/17: np.sum(np.absolute(envolute)**2)*(0.1)**3
128/18: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "S", 2, 0, 0, 1.42, 1)
128/19:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
128/20: np.sum(np.absolute(envolute)**2)*(0.1)**3
128/21: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "z", 2, 0, 0, 1.42, 1)
128/22: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "Z", 2, 0, 0, 1.42, 1)
128/23:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
128/24: np.sum(np.absolute(envolute)**2)*(0.1)**3
129/1: import my_sqrt
129/2: import basic_func
130/1: import my_sqrt
131/1: import build/lib.linux-x86_64-3.8/py_sqrt.cpython-38-x86_64-linux-gnu.so
131/2: import py_sqrt
131/3: import my_sqrt
131/4: import usr_sqrt
131/5: import build/lib.linux-x86_64-3.8/py_sqrt
131/6: import build/lib/py_sqrt
132/1: import py_sqrt
132/2: py_sqrt.calculate_sqrt(100)
133/1: import py_sqrt
133/2: py.sqrt.calculate_sqrt(10)
133/3: py_sqrt.calculate_sqrt(10)
133/4: import math
133/5: math.sqrt(10)
134/1: import build/lib.linux-x86_64-3.8/py_sqrt.cpython-38-x86_64-linux-gnu.so
134/2: import build/lib.linux-x86_64-3.8/py_sqrt
134/3: import build/py_sqrt
135/1: import build.lib.linux-x86_64-3.8.py_sqrt
135/2: import build.py_sqrt
135/3: import py_sqrt
137/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
137/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
137/3: qd_wavefunction.e_levels
137/4:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/5:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
137/6:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
137/7: np.sum(norm_wavefunction)*(0.20408163)**3
137/8: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/9:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
137/10: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/11:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, norm_wavefunction[:, :, 25], cmap=cm.jet)
plt.show()
137/12:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
137/13:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.log(np.abs(norm_wavefunction[:, :, 25])**2), cmap=cm.jet)
plt.show()
137/14:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-10, 10, 50)
y = np.linspace(-10, 10, 50)
z = np.linspace(-10, 10, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
137/15: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/16:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.log(np.abs(norm_wavefunction[:, :, 25])**2), cmap=cm.jet)
plt.show()
137/17:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.log(np.abs(norm_wavefunction[:, :, 25])**2), cmap=cm.jet)
plt.colorbar()
plt.show()
137/18:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.log(np.abs(norm_wavefunction[:, :, 25])**2), cmap=cm.jet)
plt.colorbar(ax=ax)
plt.show()
137/19:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.log(np.abs(norm_wavefunction[:, :, 25])**2), cmap=cm.jet)
plt.colorbar(cax=ax)
plt.show()
137/20:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.log(np.abs(norm_wavefunction[:, :, 25])**2), cmap=cm.jet)
cax = plt.axes()
plt.colorbar(cax=cax)
plt.show()
137/21:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.log(np.abs(norm_wavefunction[:, :, 25])**2), cmap=cm.jet)
plt.colorbar()
plt.show()
137/22:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.log(np.abs(norm_wavefunction[:, :, 25])**2), cmap=cm.jet)
plt.colorbar(np.log(np.abs(norm_wavefunction[:, :, 25])**2))
plt.show()
137/23:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.log(np.abs(norm_wavefunction[:, :, 25])**2), cmap=cm.jet)
plt.colorbar(ax)
plt.show()
137/24:
fig, ax = plt.subplots(figsize=(6, 6))
img = ax.contourf(XX[:, :, 25], ZZ[25].T, np.log(np.abs(norm_wavefunction[:, :, 25])**2), cmap=cm.jet)
plt.colorbar(img)
plt.show()
137/25:
fig, ax = plt.subplots(figsize=(6, 6))
img = ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.colorbar(img)
plt.show()
137/26: x
137/27: x[1:]-x[:-1]
137/28: np.sum(np.abs(norm_wavefunction)**2)*(0.40816327)**3
137/29:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
137/30: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
137/31:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-10, 10, 50)
y = np.linspace(-10, 10, 50)
z = np.linspace(-10, 10, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
137/32: x[1:]-x[:-1]
137/33: np.sum(np.abs(norm_wavefunction)**2)*(0.40816327)**3
137/34:
fig, ax = plt.subplots(figsize=(6, 6))
img = ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.colorbar(img)
plt.show()
137/35:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
137/36: x[1:]-x[:-1]
137/37: np.sum(np.abs(norm_wavefunction)**2)*(0.40816327)**3
137/38:
fig, ax = plt.subplots(figsize=(6, 6))
img = ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.colorbar(img)
plt.show()
137/39:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
print(x[1:]-x[:-1][0])
137/40:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
print(x[1:]-x[:-1])
137/41: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/42:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
print(x[1:]-x[:-1])
137/43: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/44:
fig, ax = plt.subplots(figsize=(6, 6))
img = ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.colorbar(img)
plt.show()
137/45:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
print(x[1:]-x[:-1])
137/46: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/47:
fig, ax = plt.subplots(figsize=(6, 6))
img = ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.colorbar(img)
plt.show()
137/48:
# l/m/n values
l = 1
m = -1
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
print(x[1:]-x[:-1])
137/49: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/50:
fig, ax = plt.subplots(figsize=(6, 6))
img = ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.colorbar(img)
plt.show()
137/51:
# l/m/n values
l = 1
m = 1
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
print(x[1:]-x[:-1])
137/52: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/53:
fig, ax = plt.subplots(figsize=(6, 6))
img = ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.colorbar(img)
plt.show()
137/54:
# l/m/n values
l = 1
m = 1
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(norm_wavefunction)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
print(x[1:]-x[:-1])
137/55:
# l/m/n values
l = 1
m = 1
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(XX.shape, YY.shape, ZZ.shape, norm_wavefunction.shape)
print(x[1:]-x[:-1])
137/56:
# l/m/n values
l = 1
m = 1
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
137/57:
np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
np.abs(1+1j)
137/58:
np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
print(np.abs(1+1j))
137/59:
np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
print(np.absolute(1+1j))
137/60:
np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
print(np.absolute(1.2+1j))
137/61:
np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
print(np.absolute(1.2+1j)**2)
137/62:
np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
print(np.absolute(1+1j)**2)
137/63:
np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
print(np.abs(1+1j)**2)
137/64: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/65:
# l/m/n values
l = 2
m = 1
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
137/66: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/67:
fig, ax = plt.subplots(figsize=(6, 6))
img = ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.colorbar(img)
plt.show()
137/68:
# l/m/n values
l = 3
m = 1
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
137/69: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/70:
fig, ax = plt.subplots(figsize=(6, 6))
img = ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.colorbar(img)
plt.show()
137/71: np.abs(norm_wavefunction)**2
137/72:
# l/m/n values
l = 1
m = 1
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
137/73: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/74:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
137/75: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/76:
fig, ax = plt.subplots(figsize=(6, 6))
img = ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.colorbar(img)
plt.show()
137/77: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "Z", 2, 0, 0, 1.42, 1)
137/78: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "Z", 1, 0, 0, 1.42, 1)
137/79:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
137/80: np.sum(np.absolute(envolute)**2)*(0.1)**3
137/81: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "S", 1, 0, 0, 1.42, 1)
137/82:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
137/83: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "S", 1, 0, 0, 1.42, 1)
137/84:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
137/85: np.sum(np.absolute(envolute)**2)*(0.1)**3
137/86: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "Z", 1, 0, 0, 1.42, 1)
137/87:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 0], ZZ_env[10].T, np.abs(envolute[:, :, 0])**2, cmap=cm.jet)
plt.show()
137/88: np.sum(np.absolute(envolute)**2)*(0.1)**3
137/89:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
137/90: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "S", 1, 0, 0, 1.42, 1)
137/91:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
137/92: np.sum(np.absolute(envolute)**2)*(0.1)**3
137/93:
theta = np.linspace(0, 2*np.pi, 50)
phi = np.linspace(0, np.pi, 50)
harmonics = special.sph_harm(1, 0, theta, phi)
137/94: harmonics.shape
137/95:
theta = np.linspace(0, 10, 50)
phi = np.linspace(0, np.pi, 50)
harmonics = special.sph_harm(1, 0, theta, phi)
137/96:
theta = np.linspace(0, 10, 50)
phi = np.linspace(0, np.pi, 50)
THETA, PHI = np.meshgrid(theta, phi)
harmonics = special.sph_harm(1, 0, THETA, PHI)
137/97: harmonics.shape
137/98:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
137/99: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/100: np.abs(norm_wavefunction)**2[:,:,-1]
137/101: np.abs(norm_wavefunction)**2
137/102: (np.abs(norm_wavefunction)**2)[:,:, 1]
137/103: (np.abs(norm_wavefunction)**2)[:,:,-1]
137/104: np.sum((np.abs(norm_wavefunction)**2)[:,:,-1])
137/105: np.sum((np.abs(norm_wavefunction)**2)[:,-1,:])
137/106: np.sum((np.abs(norm_wavefunction)**2)[-1,:,:])
137/107:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
137/108: np.sum(np.abs(norm_wavefunction)**2)*(0.20408163)**3
137/109: np.sum(np.abs(norm_wavefunction)**2)*(0.101)**3
137/110:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-50, 50, 100)
y = np.linspace(-50, 50, 100)
z = np.linspace(-50, 50, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
137/111: np.sum(np.abs(norm_wavefunction)**2)*(1.01)**3
137/112: np.sum((np.abs(norm_wavefunction)**2)[-1,:,:])
137/113:
fig, ax = plt.subplots(figsize=(6, 6))
img = ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.colorbar(img)
plt.show()
137/114: np.sum((np.abs(norm_wavefunction)**2)[[0:30 70:99],[0:30 70:99], [0:30 70:99]])
137/115: np.sum((np.abs(norm_wavefunction)**2)[0:30,0:30,0:30])
137/116: np.sum((np.abs(norm_wavefunction)**2)[0:30,0:30,0:30])*(1.01)**#
137/117: np.sum((np.abs(norm_wavefunction)**2)[0:30,0:30,0:30])*(1.01)**3
137/118: np.sum((np.abs(norm_wavefunction)**2)[0:40,0:40,0:40])*(1.01)**3
137/119:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
np.sum(f_r**2)

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/120:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(np.sum(f_r**2)*(r[1:]-r[:-1])[0])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/121:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(f_r, r)
print(np.sum(f_r**2)*(r[1:]-r[:-1])[0])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/122:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(f_r, r)
print(np.sum(f_r**2)*(0.015)

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/123:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(f_r, r)
print(np.sum(f_r**2)*(0.015))

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/124:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(np.sum(f_r**2)*(0.015))

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/125:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(np.sum(f_r))

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/126:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(np.sum(f_r)*(0.15))

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/127:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(np.sum(f_r)*(0.015))

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/128:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(r)
print(np.sum(f_r)*(0.015))

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/129:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(np.sum(f_r)*(0.015)**3)

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/130:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(np.sum(f_r*r**2)*(0.015))

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/131:
#angular momentum value
l = 1
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(np.sum(f_r*r**2)*(0.015))

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/132:
#angular momentum value
l = 1
#index of the energy level
k = 0
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(np.sum(f_r*r**2)*(0.015))

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/133:
#angular momentum value
l = 0
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])
print(np.sum(f_r*r**2)*(0.015))

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/134:
#angular momentum value
l = 0
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
137/135:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
137/136: qd_wavefunction.e_levels
137/137:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-50, 50, 100)
y = np.linspace(-50, 50, 100)
z = np.linspace(-50, 50, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
137/138: np.sum(np.abs(norm_wavefunction)**2)*(1.01)**3
137/139: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
137/140: qd_wavefunction.e_levels
137/141:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-50, 50, 100)
y = np.linspace(-50, 50, 100)
z = np.linspace(-50, 50, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
137/142: np.sum(np.abs(norm_wavefunction)**2)*(1.01)**3
137/143: norm_wavefunction
137/144:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
137/145: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
137/146: qd_wavefunction.e_levels
137/147:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-50, 50, 100)
y = np.linspace(-50, 50, 100)
z = np.linspace(-50, 50, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
137/148: norm_wavefunction
137/149: np.sum(np.abs(norm_wavefunction)**2)*(1.01)**3
137/150:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-5, 5, 10)
y = np.linspace(-5, 5, 10)
z = np.linspace(-5, 5, 10)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
137/151: np.sum(np.abs(norm_wavefunction)**2)*(1.11)**3
138/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
138/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
138/3: qd_wavefunction.e_levels
138/4:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-5, 5, 10)
y = np.linspace(-5, 5, 10)
z = np.linspace(-5, 5, 10)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
138/5: np.sum(np.abs(norm_wavefunction)**2)*(1.11)**3
138/6:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-10, 10, 10)
y = np.linspace(-10, 5, 10)
z = np.linspace(-10, 5, 10)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
138/7:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-10, 10, 10)
y = np.linspace(-10, 10, 10)
z = np.linspace(-10, 10, 10)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
138/8: np.sum(np.abs(norm_wavefunction)**2)*(1.11)**3
138/9:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-10, 10, 100)
y = np.linspace(-10, 10, 100)
z = np.linspace(-10, 10, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
138/10: np.sum(np.abs(norm_wavefunction)**2)*(0.2020202)**3
139/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
139/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
139/3: qd_wavefunction.e_levels
139/4:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-10, 10, 100)
y = np.linspace(-10, 10, 100)
z = np.linspace(-10, 10, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
139/5: np.sum(np.abs(norm_wavefunction)**2)*(0.2020202)**3
139/6: np.sum(np.abs(norm_wavefunction)**2(XX**2+YY**2+ZZ**2))*(0.2020202)**3
139/7: np.sum(np.abs(norm_wavefunction)**2*(XX**2+YY**2+ZZ**2))*(0.2020202)**3
139/8: np.sum(np.abs(norm_wavefunction)**2)*(0.2020202)**3
139/9: np.sum(np.abs(norm_wavefunction[XX**2+YY**2+ZZ**2>4])**2)*(0.2020202)**3
139/10: np.sum(np.abs(norm_wavefunction[50, :, :])**2)*(0.2020202)
139/11: np.sum(np.abs(norm_wavefunction)**2)*(0.2020202)**3
140/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
140/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
140/3: qd_wavefunction.e_levels
140/4:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-10, 10, 100)
y = np.linspace(-10, 10, 100)
z = np.linspace(-10, 10, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
140/5: np.sum(np.abs(norm_wavefunction)**2)*(0.2020202)**3
141/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
141/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
141/3: qd_wavefunction.e_levels
141/4:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-10, 10, 100)
y = np.linspace(-10, 10, 100)
z = np.linspace(-10, 10, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
141/5: np.sum(np.abs(norm_wavefunction)**2)*(0.2020202)**3
141/6:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-10, 10, 100)
y = np.linspace(-10, 10, 100)
z = np.linspace(-10, 10, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
141/7: np.sum(np.abs(norm_wavefunction)**2)*(0.2020202)**3
141/8: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "S", 1, 0, 0, 1.42, 1)
141/9:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
141/10: np.sum(np.absolute(envolute)**2)*(0.1)**3
141/11: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "Z", 1, 0, 0, 1.42, 1)
141/12:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
141/13: np.sum(np.absolute(envolute)**2)*(0.1)**3
141/14: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "S", 2, 0, 0, 1.42, 1)
141/15:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, :, 25])**2, cmap=cm.jet)
plt.show()
141/16: np.sum(np.absolute(envolute)**2)*(0.1)**3
141/17: qd_wavefunction.e_levels
141/18:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
141/19:
# l/m/n values
l = 2
m = 1
n = 0

x = np.linspace(-10, 10, 100)
y = np.linspace(-10, 10, 100)
z = np.linspace(-10, 10, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
141/20:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
141/21:
# l/m/n values
l = 0
m = 1
n = 0

x = np.linspace(-10, 10, 100)
y = np.linspace(-10, 10, 100)
z = np.linspace(-10, 10, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
141/22:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
141/23:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(-10, 10, 100)
y = np.linspace(-10, 10, 100)
z = np.linspace(-10, 10, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
141/24:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
141/25:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-10, 10, 100)
y = np.linspace(-10, 10, 100)
z = np.linspace(-10, 10, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
141/26:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
142/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
142/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
142/3: qd_wavefunction.e_levels
142/4:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-10, 10, 100)
y = np.linspace(-10, 10, 100)
z = np.linspace(-10, 10, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
142/5:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
142/6: np.sum(np.abs(norm_wavefunction)**2)*(0.2020202)**3
143/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
143/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "BC")
143/3: qd_wavefunction.e_levels
143/4:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-10, 10, 100)
y = np.linspace(-10, 10, 100)
z = np.linspace(-10, 10, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
143/5:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 25], ZZ[25].T, np.abs(norm_wavefunction[:, :, 25])**2, cmap=cm.jet)
plt.show()
143/6: np.sum(np.abs(norm_wavefunction)**2)*(0.2020202)**3
143/7:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, :, 50])**2, cmap=cm.jet)
plt.show()
143/8:
# l/m/n values
l = 1
m = 0
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
143/9:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, :, 50])**2, cmap=cm.jet)
plt.show()
143/10:
# l/m/n values
l = 2
m = 0
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
143/11:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, :, 50])**2, cmap=cm.jet)
plt.show()
143/12:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
143/13:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, :, 50])**2, cmap=cm.jet)
plt.show()
143/14:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
143/15:
# l/m/n values
l = 0
m = 0
n = 1

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
143/16:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, :, 50])**2, cmap=cm.jet)
plt.show()
143/17:
# l/m/n values
l = 1
m = 1
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
143/18:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, :, 50])**2, cmap=cm.jet)
plt.show()
143/19: np.sum(np.abs(norm_wavefunction)**2)*(0.2020202)**3
143/20: np.sum(np.abs(norm_wavefunction)**2)*(0.101)**3
143/21:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, 50, :])**2, cmap=cm.jet)
plt.show()
143/22:
# l/m/n values
l = 2
m = 1
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print(x[1:]-x[:-1])
143/23:
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, 50, :])**2, cmap=cm.jet)
plt.show()
143/24: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "S", 2, 0, 0, 1.42, 1)
143/25:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 25], ZZ_env[25].T, np.abs(envolute[:, 25])**2, cmap=cm.jet)
plt.show()
143/26:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
143/27: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "S", 2, 1, 0, 1.42, 1)
143/28:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
143/29: np.sum(np.absolute(envolute)**2)*(0.1)**3
143/30: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "X", 2, 1, 0, 1.42, 1)
143/31:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
143/32: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "Z", 2, 1, 0, 1.42, 1)
143/33:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
143/34: np.sum(np.absolute(envolute)**2)*(0.1)**3
143/35: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
143/36: qd_wavefunction.e_levels
143/37:
# l/m/n values
l = 2
m = 1
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, 50, :])**2, cmap=cm.jet)
plt.show()
143/38:
# l/m/n values
l = 2
m = 1
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, 50, :])**2, cmap=cm.jet)
plt.show()
143/39:
# l/m/n values
l = 2
m = 1
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, 50, :])**2, cmap=cm.jet)
plt.show()
143/40: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "Z", 2, 1, 0, 1.42, 1)
143/41:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
143/42: np.sum(np.absolute(envolute)**2)*(0.1)**3
143/43: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "S", 2, 1, 0, 1.42, 1)
143/44:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
143/45: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "X", 2, 1, 0, 1.42, 1)
143/46:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
143/47: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "Y", 2, 1, 0, 1.42, 1)
143/48:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
143/49: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
143/50: qd_wavefunction.e_levels
143/51:
#angular momentum value
l = 0
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
143/52:
#angular momentum value
l = 2
#index of the energy level
k = 1
#z angular momentum
m = 0

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
143/53:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 1

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
143/54:
# l/m/n values
l = 2
m = 1
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, 50, :])**2, cmap=cm.jet)
plt.show()
143/55: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "S", 2, 1, 0, 1.42, 1)
144/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
144/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
144/3: qd_wavefunction.e_levels
144/4:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 1

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
144/5:
# l/m/n values
l = 2
m = 1
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, 50, :])**2, cmap=cm.jet)
plt.show()
144/6: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "S", 2, 1, 0, 1.42, 1)
145/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
145/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
145/3: qd_wavefunction.e_levels
145/4:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 1

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
145/5:
# l/m/n values
l = 2
m = 1
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, 50, :])**2, cmap=cm.jet)
plt.show()
145/6: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "S", 2, 1, 0, 1.42, 1)
145/7:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
145/8:
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S t_matrix_S= qd_wavefunction.norm_envolute(5, 0.1, "S", 2, 1, 0, 1.42, 1)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(5, 0.1, "Y", 2, 1, 0, 1.42, 1)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(5, 0.1, "X", 2, 1, 0, 1.42, 1)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(5, 0.1, "Z", 2, 1, 0, 1.42, 1)
envolutes = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes:
    norm_factor += np.sum(np.abs(envolute)**2)*(0.1)**2
145/9:
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S= qd_wavefunction.norm_envolute(5, 0.1, "S", 2, 1, 0, 1.42, 1)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(5, 0.1, "Y", 2, 1, 0, 1.42, 1)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(5, 0.1, "X", 2, 1, 0, 1.42, 1)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(5, 0.1, "Z", 2, 1, 0, 1.42, 1)
envolutes = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes:
    norm_factor += np.sum(np.abs(envolute)**2)*(0.1)**2
145/10:
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S= qd_wavefunction.norm_envolute(5, 0.1, "S", 2, 1, 0, 1.42, 1)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(5, 0.1, "Y", 2, 1, 0, 1.42, 1)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(5, 0.1, "X", 2, 1, 0, 1.42, 1)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(5, 0.1, "Z", 2, 1, 0, 1.42, 1)
envolutes = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes:
    norm_factor += np.sum(np.abs(envolute)**2)*(0.1)**2
print(norm_factor)
145/11:
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S= qd_wavefunction.norm_envolute(5, 0.1, "S", 2, 1, 0, 1.42, 1)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(5, 0.1, "Y", 2, 1, 0, 1.42, 1)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(5, 0.1, "X", 2, 1, 0, 1.42, 1)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(5, 0.1, "Z", 2, 1, 0, 1.42, 1)
envolutes = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes:
    norm_factor += np.sum(np.abs(envolute)**2)*(0.1)**3
print(norm_factor)
145/12:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(0.1)**3
print("CB Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(0.1)**3
print(norm_factor)
145/13:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(0.1)**3
print("CB Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(0.1)**3
print("LH Normalization\n", norm_factor)
145/14:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("LH Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("HH Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "SO")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("SO Normalization\n", norm_factor)
145/15:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("LH Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("HH Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "SO")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("SO Normalization\n", norm_factor)
145/16:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("LH Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("HH Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "SO")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("SO Normalization\n", norm_factor)
145/17:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(6, 6), n_cols=2, n_rows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
plt.show()
145/18:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(6, 6), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
plt.show()
145/19:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(10, 10), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
plt.show()
145/20:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/21:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/22:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/23:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/24:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "SO")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/25:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/26:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/27:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/28:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
145/29:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/30:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/31:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/32:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "SO")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/33:
# Setup parameters
sim_size = 10
lat_size = 0.1
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
145/34:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/35:
# Setup parameters
sim_size = 5
lat_size = 0.05
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
145/36:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX[:, :, 50], ZZ[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/37:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, 50], ZZ_env_S[50].T, np.abs(envolute_S[:, 50, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, 50], ZZ_env_Y[50].T, np.abs(envolute_Y[:, 50, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, 50], ZZ_env_X[50].T, np.abs(envolute_X[:, 50, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, 50], ZZ_env_Z[50].T, np.abs(envolute_Z[:, 50, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/38:
# Setup parameters
sim_size = 5
lat_size = 0.05
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
center = sim_size/lat_size
145/39:
# Setup parameters
sim_size = 5
lat_size = 0.05
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
center = sim_size/lat_size
print(center)
145/40:
# Setup parameters
sim_size = 5
lat_size = 0.05
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
145/41:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/42:
# Setup parameters
sim_size = 5
lat_size = 0.08
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
145/43:
# Setup parameters
sim_size = 5
lat_size = 0.08
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
145/44:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/45:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/46:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/47:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "SO")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/48:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
145/49:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/50:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/51:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/52:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "SO")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/53:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
center = 50
145/54:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/55:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/56:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/57:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "SO")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/58:
# Setup parameters
sim_size = 10
lat_size = 0.2
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
center = 50
145/59:
# Setup parameters
sim_size = 10
lat_size = 0.2
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
145/60:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/61:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/62:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/63:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "SO")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/64:
# Setup parameters
sim_size = 30
lat_size = 0.35
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
145/65:
# Setup parameters
sim_size = 30
lat_size = 0.5
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
145/66:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/67:
# Setup parameters
sim_size = 25
lat_size = 0.3
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
145/68:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/69:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/70:
# Setup parameters
sim_size = 15
lat_size = 0.2
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
145/71:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/72:
# Setup parameters
sim_size = 20
lat_size = 0.3
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
145/73:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/74:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/75:
# Setup parameters
sim_size = 10
lat_size = 0.15
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
145/76:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/77:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/78:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/79:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "SO")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/80:
# Setup parameters
sim_size = 10
lat_size = 0.15
l = 2
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
145/81:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/82:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/83:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/84:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "SO")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
145/85:
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
145/86:
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, :, center])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
145/87:
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[center])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
145/88: XX_env_S[:, :, 1]
145/89: ZZ_env_S[:, :, 1]
145/90: ZZ_env_S[1]
145/91: XX_env_S[:, :, 1]
145/92: ZZ_env_S[:, :, 1]
145/93: ZZ_env_S[1]
145/94: ZZ_env_S[1].T
145/95: envolute_S[1]
145/96:
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
145/97:
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, :, center])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
145/98:
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, :, 1])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
145/99:
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[1])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
145/100:
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[-1])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
145/101:
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
145/102:
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(exp_df)
145/103:
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
145/104: exp_df
145/105: exp_df.to_csv("results.csv", index=False)
146/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
146/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
146/3: qd_wavefunction.e_levels
146/4:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 1

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
146/5:
# l/m/n values
l = 2
m = 1
n = 0

x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
z = np.linspace(-5, 5, 100)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, 50, :])**2, cmap=cm.jet)
plt.show()
# Export Results
exp_data = {"X": XX.flatten(), "Y": YY.flatten(), "Z": ZZ.flatten(), "env": (np.abs(norm_wavefunction)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"wavefunction_{l}_{m}_{n}.csv", index=False)
146/6:
# l/m/n values
l = 0
m = 0
n = 0

x = np.linspace(-5, 5, 50)
y = np.linspace(-5, 5, 50)
z = np.linspace(-5, 5, 50)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, 50], ZZ[50].T, np.abs(norm_wavefunction[:, 50, :])**2, cmap=cm.jet)
plt.show()
# Export Results
exp_data = {"X": XX.flatten(), "Y": YY.flatten(), "Z": ZZ.flatten(), "env": (np.abs(norm_wavefunction)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"wavefunction_{l}_{m}_{n}.csv", index=False)
146/7:
# l/m/n values
l = 0
m = 0
n = 0
n_points = 50
x = np.linspace(-5, 5, n_points)
y = np.linspace(-5, 5, n_points)
z = np.linspace(-5, 5, n_points)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, int(n_points/2)], ZZ[int(n_points/2)].T, np.abs(norm_wavefunction[:, int(n_points/2), :])**2, cmap=cm.jet)
plt.show()
# Export Results
exp_data = {"X": XX.flatten(), "Y": YY.flatten(), "Z": ZZ.flatten(), "env": (np.abs(norm_wavefunction)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"wavefunction_{l}_{m}_{n}.csv", index=False)
146/8:
# l/m/n values
l = 0
m = 0
n = 0
n_points = 50
x = np.linspace(-5, 5, n_points)
y = np.linspace(-5, 5, n_points)
z = np.linspace(-5, 5, n_points)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, int(n_points/2)], ZZ[int(n_points/2)].T, np.abs(norm_wavefunction[:, int(n_points/2), :])**2, cmap=cm.jet)
plt.show()
# Export Results
exp_data = {"X": XX.flatten(), "Y": YY.flatten(), "Z": ZZ.flatten(), "env": (np.abs(norm_wavefunction)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"wavefunction_{l}_{m}_{n}.csv", index=False)
146/9:
# l/m/n values
l = 0
m = 0
n = 1
n_points = 50
x = np.linspace(-5, 5, n_points)
y = np.linspace(-5, 5, n_points)
z = np.linspace(-5, 5, n_points)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, int(n_points/2)], ZZ[int(n_points/2)].T, np.abs(norm_wavefunction[:, int(n_points/2), :])**2, cmap=cm.jet)
plt.show()
# Export Results
exp_data = {"X": XX.flatten(), "Y": YY.flatten(), "Z": ZZ.flatten(), "env": (np.abs(norm_wavefunction)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"wavefunction_{l}_{m}_{n}.csv", index=False)
146/10:
# l/m/n values
l = 1
m = 0
n = 0
n_points = 50
x = np.linspace(-5, 5, n_points)
y = np.linspace(-5, 5, n_points)
z = np.linspace(-5, 5, n_points)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, int(n_points/2)], ZZ[int(n_points/2)].T, np.abs(norm_wavefunction[:, int(n_points/2), :])**2, cmap=cm.jet)
plt.show()
# Export Results
exp_data = {"X": XX.flatten(), "Y": YY.flatten(), "Z": ZZ.flatten(), "env": (np.abs(norm_wavefunction)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"wavefunction_{l}_{m}_{n}.csv", index=False)
146/11:
# l/m/n values
l = 2
m = 0
n = 0
n_points = 50
x = np.linspace(-5, 5, n_points)
y = np.linspace(-5, 5, n_points)
z = np.linspace(-5, 5, n_points)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, int(n_points/2)], ZZ[int(n_points/2)].T, np.abs(norm_wavefunction[:, int(n_points/2), :])**2, cmap=cm.jet)
plt.show()
# Export Results
exp_data = {"X": XX.flatten(), "Y": YY.flatten(), "Z": ZZ.flatten(), "env": (np.abs(norm_wavefunction)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"wavefunction_{l}_{m}_{n}.csv", index=False)
146/12:
# l/m/n values
l = 3
m = 0
n = 0
n_points = 50
x = np.linspace(-5, 5, n_points)
y = np.linspace(-5, 5, n_points)
z = np.linspace(-5, 5, n_points)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, int(n_points/2)], ZZ[int(n_points/2)].T, np.abs(norm_wavefunction[:, int(n_points/2), :])**2, cmap=cm.jet)
plt.show()
# Export Results
exp_data = {"X": XX.flatten(), "Y": YY.flatten(), "Z": ZZ.flatten(), "env": (np.abs(norm_wavefunction)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"wavefunction_{l}_{m}_{n}.csv", index=False)
146/13:
l = 0
m = 0
n = 0
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"envolute_{l}_{m}_{n}.csv", index=False)
146/14:
sim_size = 8
lat_size = 0.15
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"envolute_{l}_{m}_{n}.csv", index=False)
146/15:
sim_size = 8
lat_size = 0.15
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"envolute_{l}_{m}_{n}.csv", index=False)
146/16:
sim_size = 8
lat_size = 0.15
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"envolute_{l}_{m}_{n}.csv", index=False)
146/17:
sim_size = 8
lat_size = 0.15
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
env = "S"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}.csv", index=False)
146/18:
sim_size = 8
lat_size = 0.15
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
env = "Z"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}.csv", index=False)
146/19:
sim_size = 8
lat_size = 0.15
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
env = "S"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_LH.csv", index=False)
146/20:
sim_size = 8
lat_size = 0.15
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
env = "X"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_LH.csv", index=False)
146/21:
sim_size = 8
lat_size = 0.15
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
env = "Y"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_LH.csv", index=False)
146/22:
sim_size = 8
lat_size = 0.15
l = 0
m = 0
n = 0
Eg = 1.42
B = 1
env = "Z"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_LH.csv", index=False)
146/23:
sim_size = 8
lat_size = 0.15
l = 1
m = 0
n = 0
Eg = 1.42
B = 1
env = "Z"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_LH.csv", index=False)
146/24:
sim_size = 8
lat_size = 0.15
l = 2
m = 0
n = 0
Eg = 1.42
B = 1
env = "Z"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_LH.csv", index=False)
146/25:
sim_size = 8
lat_size = 0.15
l = 3
m = 0
n = 0
Eg = 1.42
B = 1
env = "Z"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, B)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("S envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_LH.csv", index=False)
146/26:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("LH Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("HH Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "SO")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("SO Normalization\n", norm_factor)
149/1:
x = 1
assert x == 1
149/2:
x = 1
assert x == 2
149/3:
x = 1
assert x == 2, "x different from 1"
149/4:
def envolute_matrix_element(qd_1, e_1, qd_2, e_2):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    assert qd_1.band != qd_2.band, "Bands should be different"
    return
149/5:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
149/6:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "BC")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "BC")
envolute_matrix_element(qd_test_1, 1, qd_test_2, 2)
149/7:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "BC")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, 1, qd_test_2, 2)
149/8:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "BC")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, 1, qd_test_2, (8, 0.15, 1.42, 1))
150/1:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "BC")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.15, 1.42, 1))
150/2:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
%matplotlib inline
150/3:
def envolute_matrix_element(qd_i, e_f, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_f
    nf, lf = e_f
    mi = 1
    mf = 1
    assert qd_i.band != qd_f.band, "Bands should be different"
    # Loop through all possible m values
    # Calculate the matrix element for transition between 2 elements
    # This element is determined from the sum of the elements from the 4 envolutes
    Mx, My, Mz = 0, 0, 0
    for envolute in envolutes:
        XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, mi, ni, Eg, B)
        _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, mf, nf, Eg, B)
        Mx += env_i * XX * env_f.H
        My += env_i * YY * env_f.H
        Mz += env_i * ZZ * env_f.H
    # Determine the matrix element from n1, l1, m1 to n2, l2, m2
    return Mx, My, Mz
150/4:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    mi = 1
    mf = 1
    assert qd_i.band != qd_f.band, "Bands should be different"
    # Loop through all possible m values
    # Calculate the matrix element for transition between 2 elements
    # This element is determined from the sum of the elements from the 4 envolutes
    Mx, My, Mz = 0, 0, 0
    for envolute in envolutes:
        XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, mi, ni, Eg, B)
        _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, mf, nf, Eg, B)
        Mx += env_i * XX * env_f.H
        My += env_i * YY * env_f.H
        Mz += env_i * ZZ * env_f.H
    # Determine the matrix element from n1, l1, m1 to n2, l2, m2
    return Mx, My, Mz
150/5:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "BC")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.15, 1.42, 1))
150/6:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.15, 1.42, 1))
150/7:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    mi = 1
    mf = 1
    assert qd_i.band != qd_f.band, "Bands should be different"
    # Loop through all possible m values
    # Calculate the matrix element for transition between 2 elements
    # This element is determined from the sum of the elements from the 4 envolutes
    Mx, My, Mz = 0, 0, 0
    for envolute in envolutes:
        XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, mi, ni, Eg, B)
        _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, mf, nf, Eg, B)
        Mx += env_i * XX * env_f.getH()
        My += env_i * YY * env_f.getH()
        Mz += env_i * ZZ * env_f.getH()
    # Determine the matrix element from n1, l1, m1 to n2, l2, m2
    return Mx, My, Mz
150/8:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.15, 1.42, 1))
150/9:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    mi = 1
    mf = 1
    assert qd_i.band != qd_f.band, "Bands should be different"
    # Loop through all possible m values
    # Calculate the matrix element for transition between 2 elements
    # This element is determined from the sum of the elements from the 4 envolutes
    Mx, My, Mz = 0, 0, 0
    for envolute in envolutes:
        XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, mi, ni, Eg, B)
        _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, mf, nf, Eg, B)
        Mx += env_i * XX * np.transpose(np.complex(env_f))
        My += env_i * YY * np.transpose(np.complex(env_f))
        Mz += env_i * ZZ * np.transpose(np.complex(env_f))
    # Determine the matrix element from n1, l1, m1 to n2, l2, m2
    return Mx, My, Mz
150/10:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.15, 1.42, 1))
150/11:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    mi = 1
    mf = 1
    assert qd_i.band != qd_f.band, "Bands should be different"
    # Loop through all possible m values
    # Calculate the matrix element for transition between 2 elements
    # This element is determined from the sum of the elements from the 4 envolutes
    Mx, My, Mz = 0, 0, 0
    for envolute in envolutes:
        XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, mi, ni, Eg, B)
        _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, mf, nf, Eg, B)
        Mx += env_i * XX * np.transpose(np.conjugate(env_f))
        My += env_i * YY * np.transpose(np.conjugate(env_f))
        Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
    # Determine the matrix element from n1, l1, m1 to n2, l2, m2
    return Mx, My, Mz
150/12:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.15, 1.42, 1))
150/13:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    mi = 1
    mf = 1
    assert qd_i.band != qd_f.band, "Bands should be different"
    # Loop through all possible m values
    # Calculate the matrix element for transition between 2 elements
    # This element is determined from the sum of the elements from the 4 envolutes
    Mx, My, Mz = 0, 0, 0
    for envolute in envolutes:
        XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, mi, ni, Eg, B)
        _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, mf, nf, Eg, B)
        Mx += env_i * XX * np.transpose(np.conjugate(env_f))
        My += env_i * YY * np.transpose(np.conjugate(env_f))
        Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
    # Determine the matrix element from n1, l1, m1 to n2, l2, m2
    Mx = np.sum(Mx) * lat_size
    My = np.sum(My) * lat_size
    Mz = np.sum(Mz) * lat_size
    return Mx, My, Mz
150/14:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.15, 1.42, 1))
150/15:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/16:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    mi = 1
    mf = 1
    assert qd_i.band != qd_f.band, "Bands should be different"
    # Loop through all possible m values
    # Calculate the matrix element for transition between 2 elements
    # This element is determined from the sum of the elements from the 4 envolutes
    Mx, My, Mz = 0, 0, 0
    for envolute in envolutes:
        XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, mi, ni, Eg, B)
        _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, mf, nf, Eg, B)
        Mx += env_i * XX * np.transpose(np.conjugate(env_f))
        My += env_i * YY * np.transpose(np.conjugate(env_f))
        Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
    # Determine the matrix element from n1, l1, m1 to n2, l2, m2
    Mx = np.abs(np.sum(Mx) * lat_size)
    My = np.abs(np.sum(My) * lat_size)
    Mz = np.abs(np.sum(Mz) * lat_size)
    return Mx, My, Mz
150/17:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/18:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
from itertools import product
%matplotlib inline
150/19:
arr1 = [1, 2, 3]
arr2 = [4, 5, 6]

print(product(arr1, arr2))
150/20:
arr1 = [1, 2, 3]
arr2 = [4, 5, 6]

for val1, val2 in product(arr1, arr2):
    print(val1, val2)
150/21:
arr1 = [1, 2, 3]
arr2 = [4, 5, 6]

for val1, val2 in product(range(5), range(3)):
    print(val1, val2)
150/22:
arr1 = [1, 2, 3]
arr2 = [4, 5, 6]

for val1, val2 in product(range(-2, 2), range(-1, 1)):
    print(val1, val2)
150/23:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    m_i_max = 2 * li
    m_f_max = 2 * lf
    assert qd_i.band != qd_f.band, "Bands should be different"
    Mx_array = []
    My_array = []
    Mz_array = []
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in product(range(-m_i_max, m_i_max), range(-m_f_max, m_f_max)):
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            Mx += env_i * XX * np.transpose(np.conjugate(env_f))
            My += env_i * YY * np.transpose(np.conjugate(env_f))
            Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(np.sum(Mx) * lat_size))
        My_array.append(np.abs(np.sum(My) * lat_size))
        Mz_array.append(np.abs(np.sum(Mz) * lat_size))
    return Mx_array, My_array, Mz_array
150/24:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/25:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    m_i_max = 2 * li
    m_f_max = 2 * lf
    assert qd_i.band != qd_f.band, "Bands should be different"
    Mx_array = []
    My_array = []
    Mz_array = []
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in product(range(-m_i_max, m_i_max), range(-m_f_max, m_f_max)):
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            Mx += env_i * XX * np.transpose(np.conjugate(env_f))
            My += env_i * YY * np.transpose(np.conjugate(env_f))
            Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
            print("Matrix Elements")
            print(Mx, My, Mz)
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(np.sum(Mx) * lat_size))
        My_array.append(np.abs(np.sum(My) * lat_size))
        Mz_array.append(np.abs(np.sum(Mz) * lat_size))
    return Mx_array, My_array, Mz_array
150/26:
qd_test_1 = qbd.qd_results(3, 1.9, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1.9, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/27:
qd_test_1 = qbd.qd_results(3, 1.5, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/28:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    m_i_max = 2 * li
    m_f_max = 2 * lf
    assert qd_i.band != qd_f.band, "Bands should be different"
    Mx_array = []
    My_array = []
    Mz_array = []
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in product(range(-m_i_max, m_i_max), range(-m_f_max, m_f_max)):
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            Mx += env_i * XX * np.transpose(np.conjugate(env_f))
            My += env_i * YY * np.transpose(np.conjugate(env_f))
            Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(np.sum(Mx) * lat_size))
        My_array.append(np.abs(np.sum(My) * lat_size))
        Mz_array.append(np.abs(np.sum(Mz) * lat_size))
        print("Matrix Elements")
        print(Mx, My, Mz)
    return Mx_array, My_array, Mz_array
150/29:
qd_test_1 = qbd.qd_results(3, 1.5, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/30:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    m_i_max = 2 * li - 1
    m_f_max = 2 * lf - 1
    assert qd_i.band != qd_f.band, "Bands should be different"
    Mx_array = []
    My_array = []
    Mz_array = []
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in product(range(-m_i_max, m_i_max), range(-m_f_max, m_f_max)):
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            Mx += env_i * XX * np.transpose(np.conjugate(env_f))
            My += env_i * YY * np.transpose(np.conjugate(env_f))
            Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(np.sum(Mx) * lat_size))
        My_array.append(np.abs(np.sum(My) * lat_size))
        Mz_array.append(np.abs(np.sum(Mz) * lat_size))
        print("Matrix Elements")
        print(Mx, My, Mz)
    return Mx_array, My_array, Mz_array
150/31:
qd_test_1 = qbd.qd_results(3, 1.5, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/32:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    m_i_max = 2 * li - 1
    m_f_max = 2 * lf - 1
    assert qd_i.band != qd_f.band, "Bands should be different"
    Mx_array = []
    My_array = []
    Mz_array = []
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in product(range(-m_i_max, m_i_max), range(-m_f_max, m_f_max)):
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            Mx += env_i * XX * np.transpose(np.conjugate(env_f))
            My += env_i * YY * np.transpose(np.conjugate(env_f))
            Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(np.sum(Mx) * lat_size))
        My_array.append(np.abs(np.sum(My) * lat_size))
        Mz_array.append(np.abs(np.sum(Mz) * lat_size))
    return Mx_array, My_array, Mz_array
150/33:
qd_test_1 = qbd.qd_results(3, 1.5, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 1), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/34:
qd_test_1 = qbd.qd_results(3, 1.5, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 0), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/35:
qd_test_1 = qbd.qd_results(3, 1.5, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 2), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/36:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    assert qd_i.band != qd_f.band, "Bands should be different"
    Mx_array = []
    My_array = []
    Mz_array = []
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in product(range(-li, li), range(-lf, lf)):
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            Mx += env_i * XX * np.transpose(np.conjugate(env_f))
            My += env_i * YY * np.transpose(np.conjugate(env_f))
            Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(np.sum(Mx) * lat_size))
        My_array.append(np.abs(np.sum(My) * lat_size))
        Mz_array.append(np.abs(np.sum(Mz) * lat_size))
    return Mx_array, My_array, Mz_array
150/37:
qd_test_1 = qbd.qd_results(3, 1.5, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 2), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/38:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    assert qd_i.band != qd_f.band, "Bands should be different"
    Mx_array = []
    My_array = []
    Mz_array = []
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in product(range(-li, li), range(-lf, lf)):
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            Mx += env_i * XX * np.transpose(np.conjugate(env_f))
            My += env_i * YY * np.transpose(np.conjugate(env_f))
            Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(np.sum(Mx) * lat_size))
        My_array.append(np.abs(np.sum(My) * lat_size))
        Mz_array.append(np.abs(np.sum(Mz) * lat_size))
    Mx_final = np.average(np.array(Mx_array) > 0)
    My_final = np.average(np.array(My_array) > 0)
    My_final = np.average(np.array(Mz_array) > 0)
    return Mx_final, My_final, Mz_final
150/39:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    assert qd_i.band != qd_f.band, "Bands should be different"
    Mx_array = []
    My_array = []
    Mz_array = []
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in product(range(-li, li), range(-lf, lf)):
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            Mx += env_i * XX * np.transpose(np.conjugate(env_f))
            My += env_i * YY * np.transpose(np.conjugate(env_f))
            Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(np.sum(Mx) * lat_size))
        My_array.append(np.abs(np.sum(My) * lat_size))
        Mz_array.append(np.abs(np.sum(Mz) * lat_size))
    Mx_final = np.average(np.array(Mx_array) > 0)
    My_final = np.average(np.array(My_array) > 0)
    Mz_final = np.average(np.array(Mz_array) > 0)
    return Mx_final, My_final, Mz_final
150/40:
qd_test_1 = qbd.qd_results(3, 1.5, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 2), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/41:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    assert qd_i.band != qd_f.band, "Bands should be different"
    Mx_array = []
    My_array = []
    Mz_array = []
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in product(range(-li, li), range(-lf, lf)):
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            Mx += env_i * XX * np.transpose(np.conjugate(env_f))
            My += env_i * YY * np.transpose(np.conjugate(env_f))
            Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(np.sum(Mx) * lat_size))
        My_array.append(np.abs(np.sum(My) * lat_size))
        Mz_array.append(np.abs(np.sum(Mz) * lat_size))
    Mx_final = np.mean(np.array(Mx_array) > 0)
    My_final = np.mean(np.array(My_array) > 0)
    Mz_final = np.mean(np.array(Mz_array) > 0)
    return Mx_final, My_final, Mz_final
150/42:
qd_test_1 = qbd.qd_results(3, 1.5, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 2), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/43:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    assert qd_i.band != qd_f.band, "Bands should be different"
    Mx_array = []
    My_array = []
    Mz_array = []
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in product(range(-li, li), range(-lf, lf)):
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            Mx += env_i * XX * np.transpose(np.conjugate(env_f))
            My += env_i * YY * np.transpose(np.conjugate(env_f))
            Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(np.sum(Mx) * lat_size))
        My_array.append(np.abs(np.sum(My) * lat_size))
        Mz_array.append(np.abs(np.sum(Mz) * lat_size))
    print(np.array(Mx_array))
    Mx_final = np.mean(np.array(Mx_array) > 0)
    My_final = np.mean(np.array(My_array) > 0)
    Mz_final = np.mean(np.array(Mz_array) > 0)
    return Mx_final, My_final, Mz_final
150/44:
qd_test_1 = qbd.qd_results(3, 1.5, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 2), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/45:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    assert qd_i.band != qd_f.band, "Bands should be different"
    Mx_array = []
    My_array = []
    Mz_array = []
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in product(range(-li, li), range(-lf, lf)):
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            Mx += env_i * XX * np.transpose(np.conjugate(env_f))
            My += env_i * YY * np.transpose(np.conjugate(env_f))
            Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(np.sum(Mx) * lat_size))
        My_array.append(np.abs(np.sum(My) * lat_size))
        Mz_array.append(np.abs(np.sum(Mz) * lat_size))
    Mx_final = np.mean(np.array(Mx_array))
    My_final = np.mean(np.array(My_array))
    Mz_final = np.mean(np.array(Mz_array))
    return Mx_final, My_final, Mz_final
150/46:
qd_test_1 = qbd.qd_results(3, 1.5, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 2), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/47:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    assert qd_i.band != qd_f.band, "Bands should be different"
    Mx_array = []
    My_array = []
    Mz_array = []
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in product(range(-li, li), range(-lf, lf)):
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            Mx += env_i * XX * np.transpose(np.conjugate(env_f))
            My += env_i * YY * np.transpose(np.conjugate(env_f))
            Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(np.sum(Mx) * lat_size))
        My_array.append(np.abs(np.sum(My) * lat_size))
        Mz_array.append(np.abs(np.sum(Mz) * lat_size))
        print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    Mx_final = np.mean(np.array(Mx_array))
    My_final = np.mean(np.array(My_array))
    Mz_final = np.mean(np.array(Mz_array))
    return Mx_final, My_final, Mz_final
150/48:
qd_test_1 = qbd.qd_results(3, 1.5, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 2), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
150/49:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    assert qd_i.band != qd_f.band, "Bands should be different"
    Mx_array = []
    My_array = []
    Mz_array = []
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in product(range(-li, li), range(-lf, lf)):
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            Mx += env_i * XX * np.transpose(np.conjugate(env_f))
            My += env_i * YY * np.transpose(np.conjugate(env_f))
            Mz += env_i * ZZ * np.transpose(np.conjugate(env_f))
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(np.sum(Mx) * lat_size))
        My_array.append(np.abs(np.sum(My) * lat_size))
        Mz_array.append(np.abs(np.sum(Mz) * lat_size))
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    Mx_final = np.mean(np.array(Mx_array))
    My_final = np.mean(np.array(My_array))
    Mz_final = np.mean(np.array(Mz_array))
    return Mx_final, My_final, Mz_final
150/50:
qd_test_1 = qbd.qd_results(3, 1.5, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(3, 1, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_1, (0, 2), qd_test_2, (0,1), (8, 0.2, 1.42, 1))
151/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
from itertools import product
%matplotlib inline
151/2:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li), range(-lf, lf))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx)**2)
        My_array.append(np.abs(My)**2)
        Mz_array.append(np.abs(Mz)**2)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    Mx_final = np.mean(np.array(Mx_array))
    My_final = np.mean(np.array(My_array))
    Mz_final = np.mean(np.array(Mz_array))
    return Mx_final, My_final, Mz_final
151/3:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.7, 0.1, 0.1, "LH")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/4:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.7, 0.1, 0.1, "CB")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.3, 2.5, 2))
151/5:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.7, 0.1, 0.1, "CB")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.3, 2.5, 2))
151/6:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.3, 2.5, 2))
151/7:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.3, 2.5, 2))
151/8:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li), range(-lf, lf))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx)**2)
        My_array.append(np.abs(My)**2)
        Mz_array.append(np.abs(Mz)**2)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    Mx_final = np.mean(np.array(Mx_array))
    My_final = np.mean(np.array(My_array))
    Mz_final = np.mean(np.array(Mz_array))
    return Mx_final, My_final, Mz_final
151/9:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.3, 2.5, 2))
151/10:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.3, 2.5, 2))
151/11:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/12:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li), range(-lf, lf))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx)**2)
        My_array.append(np.abs(My)**2)
        Mz_array.append(np.abs(Mz)**2)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    Mx_final = np.mean(np.array(Mx_array))
    My_final = np.mean(np.array(My_array))
    Mz_final = np.mean(np.array(Mz_array))
    return Mx_final, My_final, Mz_final
151/13:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/14:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 1.1, 0.1, 0.1, "HH")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/15:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "HH")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/16:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li), range(-lf, lf))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx)**2)
        My_array.append(np.abs(My)**2)
        Mz_array.append(np.abs(Mz)**2)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    Mx_final = np.mean(np.array(Mx_array))
    My_final = np.mean(np.array(My_array))
    Mz_final = np.mean(np.array(Mz_array))
    return Mx_final/10e-9, My_final, Mz_final
151/17:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "HH")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/18:
sizes = np.linspace(2, 5, 10)
levels = [(0, 0), (0, 1), (0, 2), (0, 3)]
for i, j in product(levels):
    print(i, j)
151/19:
sizes = np.linspace(2, 5, 10)
levels = [(0, 0), (0, 1), (0, 2), (0, 3)]
for i, b, j, c in product(levels):
    print(i, j)
151/20:
sizes = np.linspace(2, 5, 10)
levels = [(0, 0), (0, 1), (0, 2), (0, 3)]
for i, b, j, c in product(levels, levels):
    print(i, j)
151/21:
sizes = np.linspace(2, 5, 10)
levels = [(0, 0), (0, 1), (0, 2), (0, 3)]
for i, j in product(levels, levels):
    print(i, j)
151/22:
sizes = np.linspace(2, 5, 10)
levels = [(0, 0), (0, 1), (0, 2), (0, 3)]
sim_properties = (20, 0.3, 1.42, 1.07)
for size in sizes:
    qd1 = qbd.qd_results(size, 0.210, 0.027, 0.027, "LH")
    qd2 = qbd.qd_results(size, 0.473, 0.0294, 0.0294, "CB")
    for state_lh, state_cb in product(levels, levels):
        envolute_matrix_element(qd_1, state_lh, qd_2, state_cb,)
151/23:
sizes = np.linspace(2, 5, 10)
levels = [(0, 0), (0, 1), (0, 2), (0, 3)]
sim_properties = (20, 0.3, 1.42, 1.07)
for size in sizes:
    qd1 = qbd.qd_results(size, 0.210, 0.027, 0.027, "LH")
    qd2 = qbd.qd_results(size, 0.473, 0.0294, 0.0294, "CB")
    for state_lh, state_cb in product(levels, levels):
        envolute_matrix_element(qd1, state_lh, qd2, state_cb,)
151/24:
sizes = np.linspace(2, 5, 10)
levels = [(0, 0), (0, 1), (0, 2), (0, 3)]
sim_properties = (20, 0.3, 1.42, 1.07)
for size in sizes:
    qd1 = qbd.qd_results(size, 0.210, 0.027, 0.027, "LH")
    qd2 = qbd.qd_results(size, 0.473, 0.0294, 0.0294, "CB")
    for state_lh, state_cb in product(levels, levels):
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/25:
sizes = np.linspace(3, 5, 10)
levels = [(0, 0), (0, 1), (0, 2), (0, 3)]
sim_properties = (20, 0.3, 1.42, 1.07)
for size in sizes:
    qd1 = qbd.qd_results(size, 0.210, 0.027, 0.027, "LH")
    qd2 = qbd.qd_results(size, 0.473, 0.0294, 0.0294, "CB")
    for state_lh, state_cb in product(levels, levels):
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/26:
sizes = np.linspace(5, 10, 10)
levels = [(0, 0), (0, 1), (0, 2), (0, 3)]
sim_properties = (20, 0.3, 1.42, 1.07)
for size in sizes:
    qd1 = qbd.qd_results(size, 0.210, 0.027, 0.027, "LH")
    qd2 = qbd.qd_results(size, 0.473, 0.0294, 0.0294, "CB")
    for state_lh, state_cb in product(levels, levels):
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/27:
sizes = np.linspace(10, 20, 10)
levels = [(0, 0), (0, 1), (0, 2), (0, 3)]
sim_properties = (50, 3, 1.42, 1.07)
for size in sizes:
    qd1 = qbd.qd_results(size, 0.210, 0.027, 0.027, "LH")
    qd2 = qbd.qd_results(size, 0.473, 0.0294, 0.0294, "CB")
    for state_lh, state_cb in product(levels, levels):
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/28:
sizes = np.linspace(10, 20, 10)
levels = [(0, 0), (0, 1), (0, 2), (0, 3)]
sim_properties = (50, 3, 1.42, 1.07)
for size in sizes:
    qd1 = qbd.qd_results(size, 0.210, 0.027, 0.027, "LH")
    qd2 = qbd.qd_results(size, 0.473, 0.0294, 0.0294, "CB")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/29:
sizes = np.linspace(10, 20, 10)
levels = [(0, 0), (0, 1), (0, 2), (0, 3)]
sim_properties = (50, 3, 1.42, 1.07)
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 0.210, 0.027, 0.027, "LH")
    qd2 = qbd.qd_results(size, 0.473, 0.0294, 0.0294, "CB")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb, "\n\n")
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/30:
sizes = np.linspace(10, 20, 10)
levels = [(0, 0), (0, 1), (0, 2), (0, 3)]
sim_properties = (50, 3, 1.42, 1.07)
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 0.210, 0.027, 0.027, "LH")
    qd2 = qbd.qd_results(size, 0.473, 0.0294, 0.0294, "CB")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/31:
sizes = np.linspace(3, 10 , 10)
levels = [(0, 0), (0, 1), (0, 2)]
sim_properties = (20, 0.3, 2.4, 1.07)
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.012, 0.012, "LH")
    qd2 = qbd.qd_results(size, 0.7, 0.024, 0.024, "CB")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/32:
sizes = np.linspace(3, 10 , 10)
levels = [(0, 0), (0, 1), (0, 2)]
sim_properties = (20, 0.3, 2.4, 1.07)
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.012, 0.012, "LH")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.024, 0.024, "CB")
    print(qd2.e_levels)
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/33:
sizes = np.linspace(3, 10 , 10)
levels = [(0, 0), (0, 1), (0, 2)]
sim_properties = (20, 0.3, 2.4, 1.07)
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.012, 0.012, "LH")
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    print("QD2 Energy Levels:")
    qd2 = qbd.qd_results(size, 0.7, 0.024, 0.024, "CB")
    print(qd2.e_levels)
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/34:
sizes = np.linspace(3, 10, 10)
levels = [(0, 0), (0, 1), (0, 2)]
sim_properties = (20, 0.3, 2.4, 1.07)
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    print("QD2 Energy Levels:")
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    print(qd2.e_levels)
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/35:
sizes = np.linspace(3, 10, 10)
levels = [(0, 0), (0, 1), (0, 2)]
sim_properties = (20, 0.3, 2.4, 1.07)
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    print(qd1.e_levels.shape)
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    print("QD2 Energy Levels:")
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    print(qd2.e_levels)
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/36:
sizes = np.linspace(3, 10, 10)
levels = [(0, 0), (0, 1), (0, 2)]
sim_properties = (20, 0.3, 2.4, 1.07)
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    print(qd1.e_levels.shape - 1)
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    print("QD2 Energy Levels:")
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    print(qd2.e_levels)
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/37:
sizes = np.linspace(3, 10, 10)
levels = [(0, 0), (0, 1), (0, 2)]
sim_properties = (20, 0.3, 2.4, 1.07)
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    qd1_levels = (qd1.e_levels.shape[0] - 1, qd1.e_levels.shape[1] - 1)
    print(qd1_levels)
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    print("QD2 Energy Levels:")
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    print(qd2.e_levels)
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/38:
sizes = np.linspace(3, 10, 10)
sim_properties = (20, 0.3, 2.4, 1.07)
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    qd1_levels = (qd1.e_levels.shape[0] - 1, qd1.e_levels.shape[1] - 1)
    print("QD1 Energy Levels:")
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    qd2_levels = (qd2.e_levels.shape[0] - 1, qd2.e_levels.shape[1] - 1)
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    for state_lh, state_cb in product(qd1_levels, qd2_levels):
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/39:
sizes = np.linspace(3, 10, 10)
sim_properties = (20, 0.3, 2.4, 1.07)
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    qd1_levels = (qd1.e_levels.shape[0] - 1, qd1.e_levels.shape[1] - 1)
    print("QD1 Energy Levels:")
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    qd2_levels = (qd2.e_levels.shape[0] - 1, qd2.e_levels.shape[1] - 1)
    print(qd2_levels)
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    for state_lh, state_cb in product(qd1_levels, qd2_levels):
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/40:
sizes = np.linspace(3, 10, 10)
sim_properties = (20, 0.3, 2.4, 1.07)
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    qd1_levels = (qd1.e_levels.shape[0] - 1, qd1.e_levels.shape[1] - 1)
    print("QD1 Energy Levels:")
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    qd2_levels = (qd2.e_levels.shape[0] - 1, qd2.e_levels.shape[1] - 1)
    print(qd2_levels)
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    for state_lh, state_cb in product(qd1_levels, qd2_levels):
        print(state_lh)
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/41:
sizes = np.linspace(3, 10, 10)
sim_properties = (20, 0.3, 2.4, 1.07)
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    qd1_levels = (qd1.e_levels.shape[0] - 1, qd1.e_levels.shape[1] - 1)
    print(qd1_levels)
    print("QD1 Energy Levels:")
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    qd2_levels = (qd2.e_levels.shape[0] - 1, qd2.e_levels.shape[1] - 1)
    print(qd2_levels)
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    for state_lh, state_cb in product(qd1_levels, qd2_levels):
        print(state_lh)
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/42:
sizes = np.linspace(3, 10, 10)
sim_properties = (20, 0.3, 2.4, 1.07)
levels = [(0, 0), (0, 1), (0, 2)]
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    print("QD1 Energy Levels:")
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    for state_lh, state_cb in product(levels, levels):
        print(state_lh)
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/43:
sizes = np.linspace(3, 10, 10)
sim_properties = (20, 0.3, 2.4, 1.07)
levels = [(0, 0), (0, 1), (0, 2)]
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    print("QD1 Energy Levels:")
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    for state_lh, state_cb in product(levels, levels):
        print(state_lh)
        print("Calculating from:", state_lh, state_cb)
        envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
151/44:
sizes = np.linspace(3, 10, 10)
sim_properties = (20, 0.3, 2.4, 1.07)
levels = [(0, 0), (0, 1), (0, 2)]
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    print("QD1 Energy Levels:")
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    for state_lh, state_cb in product(levels, levels):
        print(state_lh)
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            continue
151/45:
sizes = np.linspace(3, 10, 10)
sim_properties = (20, 0.6, 2.4, 1.07)
levels = [(0, 0), (0, 1), (0, 2)]
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    print("QD1 Energy Levels:")
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            continue
151/46:
sizes = np.linspace(3, 10, 4)
sim_properties = (20, 0.6, 2.4, 1.07)
levels = [(0, 0), (0, 1), (0, 2)]
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            continue
151/47:
sizes = np.linspace(3, 10, 4)
sim_properties = (20, 0.6, 2.4, 1.07)
levels = [(0, 0), (0, 1), (0, 2)]
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 1.1, 0.08, 0.08, "LH")
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            continue
151/48:
sizes = np.linspace(3, 10, 4)
sim_properties = (20, 0.6, 1.2, 1.07)
levels = [(0, 0), (0, 1), (0, 2)]
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 0.5, 0.08, 0.08, "LH")
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.3, 0.1, 0.1, "CB")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            continue
151/49:
sizes = np.linspace(3, 10, 4)
sim_properties = (20, 0.6, 1.2, 1.07)
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (1, 0), (1, 2), (1, 3), (1, 4), (2, 0), (2, 1)]
for size in sizes:
    print("Calculation for size: ", size, "\n\n\n")
    qd1 = qbd.qd_results(size, 0.5, 0.08, 0.08, "LH")
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.3, 0.1, 0.1, "CB")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            continue
151/50:
sizes = np.linspace(3, 10, 4)
sim_properties = (20, 0.6, 1.2, 1.07)
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (1, 0), (1, 2), (1, 3), (1, 4), (2, 0), (2, 1)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 0.5, 0.08, 0.08, "LH")
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.3, 0.1, 0.1, "CB")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            print("No present levels")
            continue
151/51:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx)**2)
        My_array.append(np.abs(My)**2)
        Mz_array.append(np.abs(Mz)**2)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    Mx_final = np.mean(np.array(Mx_array))
    My_final = np.mean(np.array(My_array))
    Mz_final = np.mean(np.array(Mz_array))
    return Mx_final/10e-9, My_final, Mz_final
151/52:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "HH")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/53:
sizes = np.linspace(3, 10, 4)
sim_properties = (20, 0.6, 1.2, 1.07)
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (1, 0), (1, 2), (1, 3), (1, 4), (2, 0), (2, 1)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 0.5, 0.08, 0.08, "LH")
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.3, 0.1, 0.1, "CB")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            print("No present levels")
            continue
151/54:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(Mx)
        My_array.append(My)
        Mz_array.append(Mz)
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array == 0
    my_zeros = My_array == 0
    mz_zeros = Mz_array == 0
    print(mx_zeros)
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.mean(np.array(My_array))
    Mz_final = np.mean(np.array(Mz_array))
    return Mx_final/10e-9, My_final, Mz_final
151/55:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "HH")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/56:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array == 0
    my_zeros = My_array == 0
    mz_zeros = Mz_array == 0
    print(mx_zeros)
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.mean(np.array(My_array))
    Mz_final = np.mean(np.array(Mz_array))
    return Mx_final/10e-9, My_final, Mz_final
151/57:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "HH")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/58:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array < 10e-7
    my_zeros = My_array < 10e-7
    mz_zeros = Mz_array < 10e-7
    print(mx_zeros)
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.mean(np.array(My_array))
    Mz_final = np.mean(np.array(Mz_array))
    return Mx_final/10e-9, My_final, Mz_final
151/59:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "HH")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/60:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array < 10e-6
    my_zeros = My_array < 10e-6
    mz_zeros = Mz_array < 10e-6
    print(mx_zeros)
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.mean(np.array(My_array))
    Mz_final = np.mean(np.array(Mz_array))
    return Mx_final/10e-9, My_final, Mz_final
151/61:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "HH")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/62:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-6
    my_zeros = My_array > 10e-6
    mz_zeros = Mz_array > 10e-6
    print(mx_zeros)
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.mean(My_array, weigths=my_zeros)
    Mz_final = np.mean(Mz_array, weigths=mz_zeros)
    return Mx_final, My_final, Mz_final
151/63:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "HH")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/64:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-6
    my_zeros = My_array > 10e-6
    mz_zeros = Mz_array > 10e-6
    print(mx_zeros)
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.average(My_array, weigths=my_zeros)
    Mz_final = np.average(Mz_array, weigths=mz_zeros)
    return Mx_final, My_final, Mz_final
151/65:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "HH")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/66:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-6
    my_zeros = My_array > 10e-6
    mz_zeros = Mz_array > 10e-6
    print(mx_zeros)
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.average(My_array, weigths=my_zeros)
    Mz_final = np.average(Mz_array, weigths=mz_zeros)
    return Mx_final, My_final, Mz_final
151/67:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "HH")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/68:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-6
    my_zeros = My_array > 10e-6
    mz_zeros = Mz_array > 10e-6
    # Compute the average
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.average(My_array, weigths=my_zeros)
    Mz_final = np.average(Mz_array, weigths=mz_zeros)
    return Mx_final, My_final, Mz_final
151/69:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["S", "X", "Y", "Z"]
    sim_size, lat_size, Eg, B = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, B)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, B)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-6
    my_zeros = My_array > 10e-6
    mz_zeros = Mz_array > 10e-6
    # Compute the average
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.average(My_array, weights=my_zeros)
    Mz_final = np.average(Mz_array, weights=mz_zeros)
    return Mx_final, My_final, Mz_final
151/70:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "HH")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
151/71:
sizes = np.linspace(3, 10, 4)
sim_properties = (20, 0.6, 1.2, 1.07)
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (1, 0), (1, 2), (1, 3), (1, 4), (2, 0), (2, 1)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 0.5, 0.08, 0.08, "LH")
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.3, 0.1, 0.1, "CB")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            print("No present levels")
            continue
151/72:
sizes = np.linspace(1, 5, 5)
sim_properties = (20, 0.6, 2.3, 1.07)
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (1, 0), (1, 2), (1, 3), (1, 4), (2, 0), (2, 1)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 1.2, 0.08, 0.08, "LH")
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            print("No present levels")
            continue
154/1:
import numpy as np
import matplotlib.pyplot as plt
154/2: R = np.loadtxt("R")
154/3: R = np.loadtxt("R.txt")
154/4: R = np.loadtxt("R.txt", separator=",")
154/5: R = np.loadtxt("R.txt", delimiter=",")
154/6:
R = np.loadtxt("R.txt", delimiter=",")
R
154/7:
data = np.loadtxt("R.txt", delimiter=",")
lmb = data[:, 0] * 1e9
R = data[:, 1]

print(lmb, R)
154/8:
def gaussian(x, x0):
    """
    Gaussian to test the script
    """
    return np.exp(-(x-x0)**2)
154/9: max_rectangle_area(lmb, R)
154/10:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    i = 0
    for i in range(len(lmd)):
        x1 = lmd[i]
        y1 = T[i]
        j = i + 1
        while j <= len(lmd) - 1:
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                if (y_scan <= y1 + y1 * 0.2) or (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
        i = i + 1
    print(max_area)
    print(max_matrix)
154/11: max_rectangle_area(lmb, R)
154/12:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    i = 0
    for i in range(len(lmd)):
        print(i)
        x1 = lmd[i]
        y1 = T[i]
        j = i + 1
        while j <= len(lmd) - 1:
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                if (y_scan <= y1 + y1 * 0.2) or (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
        i = i + 1
    print(max_area)
    print(max_matrix)
154/13: max_rectangle_area(lmb, R)
154/14:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    i = 0
    for i in range(len(lmd)):
        print(i)
        x1 = lmd[i]
        y1 = T[i]
        j = i + 1
        while j <= len(lmd) - 1:
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                if (y_scan <= y1 + y1 * 0.2) or (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
        i = i + 1
    print(max_area)
    print(max_matrix)
154/15: max_rectangle_area(lmb, R)
154/16:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    for i in range(len(lmd)):
        x1 = lmd[i]
        print(x1)
        y1 = T[i]
        j = i + 1
        while j <= len(lmd) - 1:
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                if (y_scan <= y1 + y1 * 0.2) or (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
        i = i + 1
    print(max_area)
    print(max_matrix)
154/17: max_rectangle_area(lmb, R)
154/18:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    for i in range(len(lmd)):
        x1 = lmd[i]
        y1 = T[i]
        print(y1)
        j = i + 1
        while j <= len(lmd) - 1:
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                if (y_scan <= y1 + y1 * 0.2) or (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
        i = i + 1
    print(max_area)
    print(max_matrix)
154/19: max_rectangle_area(lmb, R)
154/20:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Go to the end of the cicle
        while (j <= len(lmd) - 1):
            print("T[i]", T[i], "T[i + 1]", T[i + 1])
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                if (y_scan <= y1 + y1 * 0.2) or (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
        i = i + 1
    print(max_area)
    print(max_matrix)
154/21: max_rectangle_area(lmb, R)
154/22:
data = np.loadtxt("R.txt", delimiter=",")
lmb = data[:, 0] * 1e9
R = 1 + data[:, 1]

print(lmb, R)
154/23:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Go to the end of the cicle
        while (j <= len(lmd) - 1):
            print("T[i]", T[i], "T[i + 1]", T[i + 1])
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                if (y_scan <= y1 + y1 * 0.2) or (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
        i = i + 1
    print(max_area)
    print(max_matrix)
154/24: max_rectangle_area(lmb, R)
154/25:
data = np.loadtxt("R.txt", delimiter=",")
lmb = data[:, 0] * 1e9
R = 1 + data[:, 1]

plt.plot(lmb, R)
154/26:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Go to the end of the cicle
        while (j <= len(lmd) - 1):
            print(f"T[{i}]", T[i], f"T[{i} + 1]", T[i + 1])
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                
                # Core calculation if current y is within a tolerance of y_init then
                # a new value has been found
                if (y_scan <= y1 + y1 * 0.2) or (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/27: max_rectangle_area(lmb, R)
154/28: max_rectangle_area(lmb, R)
154/29:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Go to the end of the cicle
        while (j <= len(lmd) - 1):
            # print(f"T[{i}]", T[i], f"T[{i} + 1]", T[i + 1])
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                # Core calculation if current y is within a tolerance of y_init then
                # a new value has been found
                if (y_scan <= y1 + y1 * 0.2) or (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    print("Passed Here!")
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/30: max_rectangle_area(lmb, R)
154/31:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print("First point!")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Go to the end of the cicle
        while (j <= len(lmd) - 1):
            # print(f"T[{i}]", T[i], f"T[{i} + 1]", T[i + 1])
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                # Core calculation if current y is within a tolerance of y_init then
                # a new value has been found
                if (y_scan <= y1 + y1 * 0.2) or (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    print("Passed Here!")
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/32: max_rectangle_area(lmb, R)
154/33:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print("First point!")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Go to the end of the cicle
        while (j <= len(lmd) - 1):
            # print(f"T[{i}]", T[i], f"T[{i} + 1]", T[i + 1])
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                # Core calculation if current y is within a tolerance of y_init then
                # a new value has been found
                if (y_scan <= y1 + y1 * 0.2) and (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    print("Passed Here!")
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/34: max_rectangle_area(lmb, R)
154/35:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print("First point!")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Go to the end of the cicle
        while (j <= len(lmd) - 1):
            # print(f"T[{i}]", T[i], f"T[{i} + 1]", T[i + 1])
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                # Core calculation if current y is within a tolerance of y_init then
                # a new value has been found
                if (y_scan <= y1 + y1 * 0.2) and (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    print("Passed Here!")
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        print("Reached the end")
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/36: max_rectangle_area(lmb, R)
154/37:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print("First point!")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Go to the end of the cicle
        while (j <= len(lmd) - 1):
            # print(f"T[{i}]", T[i], f"T[{i} + 1]", T[i + 1])
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                # Core calculation if current y is within a tolerance of y_init then
                # a new value has been found
                if (y_scan <= y1 + y1 * 0.2) and (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    print("Passed Here!")
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        print(f"Found {x2}")
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        print("Reached the end")
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/38: max_rectangle_area(lmb, R)
154/39:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print("First point!")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Go to the end of the cicle
        while (j <= len(lmd) - 1):
            # print(f"T[{i}]", T[i], f"T[{i} + 1]", T[i + 1])
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                # Core calculation if current y is within a tolerance of y_init then
                # a new value has been found
                if (y_scan <= y1 + y1 * 0.2) and (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    print("Passed Here!")
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        print(f"Found {x2}")
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        print("Reached the end")
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                print("Im decreasing")
                area = 0
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/40: max_rectangle_area(lmb, R)
154/41:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print("First point!")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        area = 0
        # Go to the end of the cicle
        while (j <= len(lmd) - 1):
            # print(f"T[{i}]", T[i], f"T[{i} + 1]", T[i + 1])
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                # Core calculation if current y is within a tolerance of y_init then
                # a new value has been found
                if (y_scan <= y1 + y1 * 0.2) and (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    print("Passed Here!")
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        print(f"Found {x2}")
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        print("Reached the end")
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                print("Im decreasing")
                break
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/42: max_rectangle_area(lmb, R)
154/43:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        area = 0
        # Go to the end of the cicle
        while (j <= len(lmd) - 1):
            # print(f"T[{i}]", T[i], f"T[{i} + 1]", T[i + 1])
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                # Core calculation if current y is within a tolerance of y_init then
                # a new value has been found
                if (y_scan <= y1 + y1 * 0.2) and (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    print("Passed Here!")
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        print(f"Found {x2}")
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        print("Reached the end")
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                print("Im decreasing")
                break
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/44: max_rectangle_area(lmb, R)
154/45:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        area = 0
        # Go to the end of the cicle
        while (j <= len(lmd) - 1):
            # print(f"T[{i}]", T[i], f"T[{i} + 1]", T[i + 1])
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                # Core calculation if current y is within a tolerance of y_init then
                # a new value has been found
                if (y_scan <= y1 + y1 * 0.2) and (
                        y_scan >= y1 - y1 * 0.2):  # meter tolerância
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        print(f"Found {x2}")
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        print("Reached the end")
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                print("Im decreasing")
                break
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/46: max_rectangle_area(lmb, R)
154/47:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        area = 0
        # Go to the end of the cicle
        while (j <= len(lmd) - 1):
            # print(f"T[{i}]", T[i], f"T[{i} + 1]", T[i + 1])
            if T[i] <= T[i + 1]:
                # bloquear o scan se a função estiver num ponto com declive negativo
                x_scan = lmd[j]
                y_scan = T[j]
                # Core calculation if current y is within a tolerance of y_init then
                # a new value has been found
                if (y_scan <= y1 + y1 * 0.05) and (
                        y_scan >= y1 - y1 * 0.05):  # meter tolerância
                    if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                        j = j + 1
                    else:
                        # quando não há um mínimo local mas também não é o
                        # último ponto
                        x2 = x_scan
                        area = (x2 - x1) * y1
                        print(f"Found {x2}")
                        j = len(lmd)  # cortar ciclo
                else:
                    if j == len(lmd) - 1:
                        print("Reached the end")
                        # quando o x_scan alcança o limite da função
                        x2 = x_scan
                        area = (x2 - x1) * y1
                    j = j + 1
            else:
                print("Im decreasing")
                break
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/48: max_rectangle_area(lmb, R)
154/49:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        area = 0
        # Check if the slope is negative
        # If it is, then pass to the next point
        if !(T[i] <= T[i + 1]):
            print("Im decreasing!!")
            continue
        while (j <= len(lmd) - 1):
            # print(f"T[{i}]", T[i], f"T[{i} + 1]", T[i + 1])
            # bloquear o scan se a função estiver num ponto com declive negativo
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.05) and (
                    y_scan >= y1 - y1 * 0.05):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    print(f"Found {x2}")
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    print("Reached the end")
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/50:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        area = 0
        # Check if the slope is negative
        # If it is, then pass to the next point
        if not T[i] <= T[i + 1]:
            print("Im decreasing!!")
            continue
        while (j <= len(lmd) - 1):
            # print(f"T[{i}]", T[i], f"T[{i} + 1]", T[i + 1])
            # bloquear o scan se a função estiver num ponto com declive negativo
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.05) and (
                    y_scan >= y1 - y1 * 0.05):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    print(f"Found {x2}")
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    print("Reached the end")
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/51: max_rectangle_area(lmb, R)
154/52:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Initialize the area to always be 0 for a new point
        area = 0
        # Check if the slope is negative
        # If it is, then pass to the next point
        if not T[i] <= T[i + 1]:
            print("Im decreasing!!")
            continue
        # Enter the main loop
        while (j <= len(lmd) - 1):
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.05) and (
                    y_scan >= y1 - y1 * 0.05):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    print(f"Found {x2}")
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    print("Reached the end")
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/53: max_rectangle_area(lmb, R)
154/54:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Initialize the area to always be 0 for a new point
        area = 0
        # Check if the slope is negative
        # If it is, then pass to the next point
        if (not T[i] <= T[i + 1]) or (i = len(lmd)):
            print("Im decreasing!!")
            continue
        # Enter the main loop
        while (j <= len(lmd) - 1):
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.05) and (
                    y_scan >= y1 - y1 * 0.05):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    print(f"Found {x2}")
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    print("Reached the end")
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/55: max_rectangle_area(lmb, R)
154/56:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Initialize the area to always be 0 for a new point
        area = 0
        # Do not evaluate the last point
        if i = len(lmd):
            break
        # Check if the slope is negative
        # If it is, then pass to the next point
        if not T[i] <= T[i + 1]:
            print("Im decreasing!!")
            continue
        # Enter the main loop
        while (j <= len(lmd) - 1):
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.05) and (
                    y_scan >= y1 - y1 * 0.05):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    print(f"Found {x2}")
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    print("Reached the end")
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/57:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Initialize the area to always be 0 for a new point
        area = 0
        # Do not evaluate the last point
        if i == len(lmd):
            break
        # Check if the slope is negative
        # If it is, then pass to the next point
        if not T[i] <= T[i + 1]:
            print("Im decreasing!!")
            continue
        # Enter the main loop
        while (j <= len(lmd) - 1):
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.05) and (
                    y_scan >= y1 - y1 * 0.05):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    print(f"Found {x2}")
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    print("Reached the end")
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/58: max_rectangle_area(lmb, R)
154/59:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Initialize the area to always be 0 for a new point
        area = 0
        # Check if the slope is negative
        # If it is, then pass to the next point
        if (not T[i] <= T[i + 1]) or (i == len(lmd) - 1)
            print("Im decreasing!!")
            continue
        # Enter the main loop
        while (j <= len(lmd) - 1):
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.05) and (
                    y_scan >= y1 - y1 * 0.05):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    print(f"Found {x2}")
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    print("Reached the end")
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/60: max_rectangle_area(lmb, R)
154/61:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Initialize the area to always be 0 for a new point
        area = 0
        # Check if the slope is negative
        # If it is, then pass to the next point
        if (not T[i] <= T[i + 1]) or (i == len(lmd) - 1):
            print("Im decreasing!!")
            continue
        # Enter the main loop
        while (j <= len(lmd) - 1):
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.05) and (
                    y_scan >= y1 - y1 * 0.05):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    print(f"Found {x2}")
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    print("Reached the end")
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/62: max_rectangle_area(lmb, R)
154/63:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd)):
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Initialize the area to always be 0 for a new point
        area = 0
        if i == len(lmd) - 1:
            break
        # Check if the slope is negative
        # If it is, then pass to the next point
        if not T[i] <= T[i + 1]:
            print("Im decreasing!!")
            continue
        # Enter the main loop
        while (j <= len(lmd) - 1):
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.05) and (
                    y_scan >= y1 - y1 * 0.05):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    print(f"Found {x2}")
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    print("Reached the end")
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/64: max_rectangle_area(lmb, R)
154/65:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd) - 1): # The loop ignores the last point
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Initialize the area to always be 0 for a new point
        area = 0
        # Check if the slope is negative
        # If it is, then pass to the next point
        if not T[i] <= T[i + 1]:
            print("Im decreasing!!")
            continue
        # Enter the main loop
        while (j <= len(lmd) - 1):
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.05) and (
                    y_scan >= y1 - y1 * 0.05):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    print(f"Found {x2}")
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    print("Reached the end")
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
154/66: max_rectangle_area(lmb, R)
154/67:
x = np.linspace(0, 10, 150)
y = gaussian(x)
max_rectangle_area(x, y)
154/68:
x = np.linspace(0, 10, 150)
y = gaussian(x, 4)
max_rectangle_area(x, y)
154/69:
x = np.linspace(0, 10, 150)
y = gaussian(x, 4)
max_rectangle_area(x, y)
plt.plot(x, y)
154/70:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd) - 1): # The loop ignores the last point
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Initialize the area to always be 0 for a new point
        area = 0
        # Check if the slope is negative
        # If it is, then pass to the next point
        if not T[i] <= T[i + 1]:
            print("Im decreasing!!")
            continue
        # Enter the main loop
        while (j <= len(lmd) - 1):
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.05) and (
                    y_scan >= y1 - y1 * 0.05):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    print(f"Found {x2}")
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    print("Reached the end")
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
    return max_matrix
154/71:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd) - 1): # The loop ignores the last point
        print(f"Point: {lmd[i]}")
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Initialize the area to always be 0 for a new point
        area = 0
        # Check if the slope is negative
        # If it is, then pass to the next point
        if not T[i] <= T[i + 1]:
            continue
        # Enter the main loop
        while (j <= len(lmd) - 1):
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.05) and (
                    y_scan >= y1 - y1 * 0.05):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
    return max_matrix
154/72:
x = np.linspace(0, 10, 150)
y = gaussian(x, 4)
best_res = max_rectangle_area(x, y)
plt.plot(x, y)
154/73:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd) - 1): # The loop ignores the last point
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Initialize the area to always be 0 for a new point
        area = 0
        # Check if the slope is negative
        # If it is, then pass to the next point
        if not T[i] <= T[i + 1]:
            continue
        # Enter the main loop
        while (j <= len(lmd) - 1):
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.05) and (
                    y_scan >= y1 - y1 * 0.05):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
    return max_matrix
154/74:
x = np.linspace(0, 10, 150)
y = gaussian(x, 4)
best_res = max_rectangle_area(x, y)
plt.plot(x, y)
print(best_res)
154/75:
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
154/76:
x = np.linspace(0, 10, 150)
y = gaussian(x, 4)
best_res = max_rectangle_area(x, y)
plt.plot(x, y)
plt.add_patch(Rectangle((best_res[0][0], 0), best_res[1][0] - best_res[0][0], best_res[0][1]))
print(best_res)
154/77:
x = np.linspace(0, 10, 150)
y = gaussian(x, 4)
best_res = max_rectangle_area(x, y)
fig, ax = plt.subplots()
ax.plot(x, y)
ax.add_patch(Rectangle((best_res[0][0], 0), best_res[1][0] - best_res[0][0], best_res[0][1]))
print(best_res)
154/78:
def max_rectangle_area(lmd, T):
    # this function calculates maximum rectangular area under given plot

    # a primeira coluna da matriz corresponde ao comprimento de onda (x) e a
    # segunda coluna à reflexão (y)
    max_area = 0
    max_matrix = []
    # Loop through all values in R and lmb
    for i in range(len(lmd) - 1): # The loop ignores the last point
        # Get the first two values
        x1 = lmd[i]
        y1 = T[i]
        # Start analysing after the next point. Probably bigger values than 1 could be useful
        j = i + 1
        # Initialize the area to always be 0 for a new point
        area = 0
        # Check if the slope is negative
        # If it is, then pass to the next point
        if not T[i] <= T[i + 1]:
            continue
        # Enter the main loop
        while (j <= len(lmd) - 1):
            x_scan = lmd[j]
            y_scan = T[j]
            # Core calculation if current y is within a tolerance of y_init then
            # a new value has been found
            if (y_scan <= y1 + y1 * 0.2) and (
                    y_scan >= y1 - y1 * 0.2):  # meter tolerância
                if j < len(lmd) - 1 and T[j + 1] >= T[j]:
                    j = j + 1
                else:
                    # quando não há um mínimo local mas também não é o
                    # último ponto
                    x2 = x_scan
                    area = (x2 - x1) * y1
                    j = len(lmd)  # cortar ciclo
            else:
                if j == len(lmd) - 1:
                    # quando o x_scan alcança o limite da função
                    x2 = x_scan
                    area = (x2 - x1) * y1
                j = j + 1
        if area > max_area:
            max_area = area
            max_matrix = [(x1, y1), (x2, y1)]
            
    print(max_area)
    print(max_matrix)
    return max_matrix
154/79:
x = np.linspace(0, 10, 150)
y = gaussian(x, 4)
best_res = max_rectangle_area(x, y)
fig, ax = plt.subplots()
ax.plot(x, y)
ax.add_patch(Rectangle((best_res[0][0], 0), best_res[1][0] - best_res[0][0], best_res[0][1]))
print(best_res)
154/80:
for i in range(10):
    print(i)
154/81:
x = np.linspace(0, 10, 150)
y = gaussian(x, 4)
best_res = max_rectangle_area(lmd, R)
fig, ax = plt.subplots()
ax.plot(x, y)
ax.add_patch(Rectangle((best_res[0][0], 0), best_res[1][0] - best_res[0][0], best_res[0][1]))
print(best_res)
154/82:
x = np.linspace(0, 10, 150)
y = gaussian(x, 4)
best_res = max_rectangle_area(lmb, R)
fig, ax = plt.subplots()
ax.plot(lmb, R)
ax.add_patch(Rectangle((best_res[0][0], 0), best_res[1][0] - best_res[0][0], best_res[0][1]))
print(best_res)
154/83: 870 * 1000 * 0.25 ** 2
154/84: (870 - 1000) * 0.25 ** 2
156/1: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
156/2:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
from itertools import product
%matplotlib inline
156/3: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
156/4: qd_wavefunction.e_levels
156/5:
#angular momentum value
l = 2
#index of the energy level
k = 0
#z angular momentum
m = 1

#Calculate the radial part of the wavefunction
r,f_r = qd_wavefunction.norm_radial_wavefunction(l,k)
phi = np.linspace(0,2*np.pi,100)
#Angular part of the wavefunction
y_lm = np.absolute(special.sph_harm(m,l,0,phi))**2
#Combine both radial and angular parts
psi = np.array([y_lm*f_r_i for f_r_i in f_r])

#actual plotting
ax = plt.subplot(111, polar=True)
ctf = ax.contourf(phi,r,psi, cmap=cm.jet)
156/6:
# l/m/n values
l = 3
m = 0
n = 0
n_points = 50
x = np.linspace(-5, 5, n_points)
y = np.linspace(-5, 5, n_points)
z = np.linspace(-5, 5, n_points)
XX, YY, ZZ, norm_wavefunction = qd_wavefunction.norm_wavefunction(x, y, z, l, m, n)
print("Normalization")
print(np.sum(np.abs(norm_wavefunction)**2)*(x[1]-x[0])**3)
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX[:, :, int(n_points/2)], ZZ[int(n_points/2)].T, np.abs(norm_wavefunction[:, int(n_points/2), :])**2, cmap=cm.jet)
plt.show()
# Export Results
exp_data = {"X": XX.flatten(), "Y": YY.flatten(), "Z": ZZ.flatten(), "env": (np.abs(norm_wavefunction)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"wavefunction_{l}_{m}_{n}.csv", index=False)
156/7: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "L6mt", 2, 1, 0, 1.42, 1)
156/8: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "L6mt", 2, 1, 0, 2.5, 0.08, 0.08, 0.08)
156/9:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
156/10:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
B = 1
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "LH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_lh.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("LH Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "HH")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_hh.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("HH Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "SO")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_so.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, B)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("SO Normalization\n", norm_factor)
156/11:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
m = 0.08
Pl = 0.001
Pt = 0.002
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("LH Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("HH Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("SO Normalization\n", norm_factor)
156/12:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 1.42
m = 0.08
Pl = 0.08
Pt = 0.08
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("LH Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("HH Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("SO Normalization\n", norm_factor)
156/13:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 2.5
m = 0.08
Pl = 0.08
Pt = 0.08
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("LH Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("HH Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("SO Normalization\n", norm_factor)
157/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
from itertools import product
%matplotlib inline
157/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
157/3: qd_wavefunction.e_levels
157/4:
# Setup parameters
sim_size = 5
lat_size = 0.1
l = 2
m = 1
n = 0
Eg = 2.5
m = 0.08
Pl = 0.08
Pt = 0.08
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("LH Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("HH Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, m, Pl, Pt)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, m, Pl, Pt)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, m, Pl, Pt)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, m, Pl, Pt)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("SO Normalization\n", norm_factor)
158/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
from itertools import product
%matplotlib inline
158/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
159/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
from itertools import product
%matplotlib inline
159/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
160/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
from itertools import product
%matplotlib inline
160/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
160/3: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
160/4: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "L6mt", 2, 1, 0, 2.5, (0.08, 0.08))
160/5:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/6: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "L6mt", 1, 1, 0, 2.5, (0.08, 0.08))
160/7:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/8: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(5, 0.1, "L6mt", 1, 0, 0, 2.5, (0.08, 0.08))
160/9:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/10: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.5, "L6mt", 1, 0, 0, 2.5, (0.08, 0.08))
160/11:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/12:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/13: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mt", 1, 0, 0, 2.5, (0.08, 0.08))
160/14:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/15:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.log(np.abs(envolute[:, 50])**2), cmap=cm.jet)
plt.show()
160/16:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/17: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mt", 2, 0, 0, 2.5, (0.08, 0.08))
160/18:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/19: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mt", 2, 1, 0, 2.5, (0.08, 0.08))
160/20:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/21: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mt", 2, 2, 0, 2.5, (0.08, 0.08))
160/22:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/23: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mt", 1, 1, 1, 2.5, (0.08, 0.08))
160/24:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/25: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mt", 0, 0, 1, 2.5, (0.08, 0.08))
160/26:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/27: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mb", 0, 0, 1, 2.5, (0.08, 0.08))
160/28:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/29: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6tb", 0, 0, 1, 2.5, (0.08, 0.08))
160/30: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6pt", 0, 0, 1, 2.5, (0.08, 0.08))
160/31:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/32: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6pb", 0, 0, 1, 2.5, (0.08, 0.08))
160/33:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/34: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mb", 0, 0, 1, 2.5, (0.08, 0.08))
160/35:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
160/36:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import importlib
from itertools import product
%matplotlib inline
160/37:
# Setup parameters
sim_size = 10
lat_size = 0.2
l = 2
m = 1
n = 0
Eg = 2.5
P = (0.005, 0.005)
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("LH Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("HH Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("SO Normalization\n", norm_factor)
160/38:
# Setup parameters
sim_size = 10
lat_size = 0.15
l = 2
m = 0
n = 0
Eg = 1.42
B = 1
center = int(sim_size/lat_size/2)
print(center)
160/39:
# Setup parameters
sim_size = 10
lat_size = 0.15
l = 2
m = 0
n = 0
Eg = 1.42
P = (0.005, 0.005)
center = int(sim_size/lat_size/2)
print(center)
160/40:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
160/41:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "S", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "Y", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "X", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "Z", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("S envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("X envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("Y envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("Z envolute")
plt.show()
160/42:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
160/43:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
160/44:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
160/45:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, B)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, B)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, B)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, B)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
160/46:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
160/47:
sim_size = 8
lat_size = 0.15
l = 3
m = 0
n = 0
Eg = 2.5
P = (0.005, 0.005)
env = "L6mt"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_LH.csv", index=False)
160/48:
sim_size = 8
lat_size = 0.15
l = 3
m = 0
n = 0
Eg = 2.5
P = (0.005, 0.005)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
160/49:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
%matplotlib inline
160/50: import vtk
160/51: from pyevtk.hl import gridToVTK
160/52: gridToVTK("./test", XX_env_S, YY_env_S, ZZ_env_S, cellData = {'QD': envolute_S})
160/53: gridToVTK("./test", XX_env_S, YY_env_S, ZZ_env_S, cellData = {'QD': np.abs(envolute_S)**2})
160/54:
sim_size = 8
lat_size = 0.15
l = 3
m = 0
n = 0
Eg = 2.5
P = (0.005, 0.005)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
160/55: gridToVTK("./test", XX_env_S, YY_env_S, ZZ_env_S, cellData = {'QD': np.abs(envolute_S)**2})
160/56:
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK("./test", x, x, x, cellData = {'QD': np.abs(envolute_S)**2})
160/57: from pyevtk.hl import pointsToVTK
160/58:
x = np.arange(-sim_size, sim_size, lat_size)
pointsToVTK("./test", x, x, x, cellData = {'QD': np.abs(envolute_S)**2})
160/59:
x = np.arange(-sim_size, sim_size, lat_size)
pointsToVTK("./test", x, x, x, Data = {'QD': np.abs(envolute_S)**2})
160/60:
x = np.arange(-sim_size, sim_size, lat_size)
pointsToVTK("./test", x, x, x, data = {'QD': np.abs(envolute_S)**2})
160/61:
x = np.arange(-sim_size, sim_size, lat_size)
pointsToVTK("./test", XX_env_S, XX_env_S, XX_env_S, data = {'QD': np.abs(envolute_S)**2})
160/62: from pyevtk.hl import gridToVTK
160/63:
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK("./test", XX_env_S, XX_env_S, XX_env_S, data = {'QD': np.abs(envolute_S)**2})
160/64:
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK("./test", XX_env_S, XX_env_S, XX_env_S, CellData = {'QD': np.abs(envolute_S)**2})
160/65:
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK("./test", XX_env_S, XX_env_S, XX_env_S, cellData = {'QD': np.abs(envolute_S)**2})
160/66:
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK("./test", XX_env_S, YY_env_S, ZZ_env_S, cellData = {'QD': np.abs(envolute_S)**2})
160/67:
x = np.arange(-sim_size, sim_size + lat_size, lat_size)
gridToVTK("./test", XX_env_S, YY_env_S, ZZ_env_S, cellData = {'QD': np.abs(envolute_S)**2})
160/68:
x = np.arange(-sim_size, sim_size + lat_size, lat_size)
gridToVTK("./test", x, x, x, cellData = {'QD': np.abs(envolute_S)**2})
160/69: from pyevtk.hl import rectilinearToVTK
160/70: from pyevtk.hl import gridtoVTK
160/71: from pyevtk.hl import gridtoVTK
160/72: from pyevtk.hl import gridToVTK
160/73:
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK("./test", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
160/74:
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK("./test", x, x, x, pointData = {'QD': np.log10(np.abs(envolute_S)**2)})
160/75:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-6
    my_zeros = My_array > 10e-6
    mz_zeros = Mz_array > 10e-6
    # Compute the average
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.average(My_array, weights=my_zeros)
    Mz_final = np.average(Mz_array, weights=mz_zeros)
    return Mx_final, My_final, Mz_final
160/76:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "CB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, 2))
160/77:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "CB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, (0.005, 0.005)))
160/78:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "VB1")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, (0.005, 0.005)))
160/79:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, (0.005, 0.005)))
160/80:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB2")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, (0.005, 0.005)))
160/81:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-4
    my_zeros = My_array > 10e-4
    mz_zeros = Mz_array > 10e-4
    # Compute the average
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.average(My_array, weights=my_zeros)
    Mz_final = np.average(Mz_array, weights=mz_zeros)
    return Mx_final, My_final, Mz_final
160/82:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB2")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, (0.005, 0.005)))
160/83:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB2")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, (0.00005, 0.00005)))
160/84:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB2")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, (0.1, 0.1)))
160/85:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-4
    my_zeros = My_array > 10e-4
    mz_zeros = Mz_array > 10e-4
    print(mx_zeros)
    # Compute the average
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.average(My_array, weights=my_zeros)
    Mz_final = np.average(Mz_array, weights=mz_zeros)
    return Mx_final, My_final, Mz_final
160/86:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB2")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 2), (8, 0.3, 2.5, (0.1, 0.1)))
160/87:
qd_test_1 = qbd.qd_results(5, 1.1, 0.1, 0.1, "CB2")
qd_test_2 = qbd.qd_results(5, 0.6, 0.4, 0.4, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.3, 2.5, (0.1, 0.1)))
160/88:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB2")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.3, 2.5, (0.1, 0.1)))
160/89:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB2")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.3, 2, (1e-6, 1e-6)))
160/90:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB2")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 0), (8, 0.3, 2, (1e-6, 1e-6)))
160/91:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB2")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 0), (8, 0.3, 2, (1, 1)))
160/92:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-6
    my_zeros = My_array > 10e-6
    mz_zeros = Mz_array > 10e-6
    # Compute the average
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.average(My_array, weights=my_zeros)
    Mz_final = np.average(Mz_array, weights=mz_zeros)
    return Mx_final, My_final, Mz_final
160/93:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB2")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB1")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 0), (8, 0.3, 2, (1, 1)))
160/94:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB2")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB1")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 0), (8, 0.3, 2, (1e-12, 1e-12)))
160/95:
sim_size = 8
lat_size = 0.15
l = 3
m = 0
n = 0
Eg = 2.5
P = (1e-12, 1e-12)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
160/96:
# Setup parameters
sim_size = 10
lat_size = 0.2
l = 2
m = 1
n = 0
Eg = 2.2
P = (1e-12, 1e-12)
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("LH Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("HH Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("SO Normalization\n", norm_factor)
160/97:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB2")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB1")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 0), (10, 0.15, 2, (1e-12, 1e-12)))
160/98:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "CB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 0), (10, 0.15, 2, (1e-12, 1e-12)))
160/99:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "CB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 0), (10, 0.15, 0.4, (1e-12, 1e-12)))
160/100:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "CB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 0), (10, 0.15, 0.4, (1e-30, 1e-30)))
160/101:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB1")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 0), (10, 0.15, 0.4, (1e-30, 1e-30)))
160/102:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 0), (10, 0.15, 0.4, (1e-30, 1e-30)))
160/103:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 0), (8, 0.2, 0.4, (1e-25, 1e-25)))
160/104:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 0.4, (1e-25, 1e-25)))
160/105:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 0.4, (0.1, 0.1)))
160/106:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 0.4, (1e6, 1e6)))
161/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
%matplotlib inline
161/2: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mb", 0, 0, 1, 2.5, (0.08, 0.08))
161/3:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
161/4: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
161/5: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mb", 0, 0, 1, 2.5, (0.08, 0.08))
161/6:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
161/7: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mb", 0, 0, 1, 2.5, (1e-9, 1e-9))
161/8:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
161/9: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mb", 0, 0, 1, 2.5, (1e-18, 1e-18))
161/10:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
161/11:
# Setup parameters
sim_size = 10
lat_size = 0.2
l = 2
m = 1
n = 0
Eg = 2.2
P = (1e-12, 1e-12)
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("LH Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("HH Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("SO Normalization\n", norm_factor)
161/12:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
161/13:
# Setup parameters
sim_size = 10
lat_size = 0.15
l = 2
m = 0
n = 0
Eg = 1.42
P = (0.005, 0.005)
center = int(sim_size/lat_size/2)
print(center)
161/14:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
161/15:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
161/16:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
161/17:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 0.4, (1e6, 1e6)))
161/18:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-6
    my_zeros = My_array > 10e-6
    mz_zeros = Mz_array > 10e-6
    # Compute the average
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.average(My_array, weights=my_zeros)
    Mz_final = np.average(Mz_array, weights=mz_zeros)
    return Mx_final, My_final, Mz_final
161/19:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 0.4, (1e6, 1e6)))
161/20:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 0.4, (1e-5, 1e-5)))
161/21:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 0.4, (1, 1)))
161/22:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB1")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 0.4, (1, 1)))
161/23:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 0.4, (1, 1)))
161/24:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 0), (8, 0.2, 0.4, (1, 1)))
161/25:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 0.4, (1, 1)))
161/26:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 0.4, (1e-34, 1e-34)))
161/27:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 0.4, (1e-18, 1e-18)))
161/28:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 0.4, (1e-14, 1e-14)))
161/29:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 0.4, (1e-9, 1e-9)))
161/30:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 0.4, (1e-10, 1e-10)))
161/31:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 0.4, (1e-11, 1e-11)))
162/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
%matplotlib inline
162/2:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-6
    my_zeros = My_array > 10e-6
    mz_zeros = Mz_array > 10e-6
    # Compute the average
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.average(My_array, weights=my_zeros)
    Mz_final = np.average(Mz_array, weights=mz_zeros)
    return Mx_final, My_final, Mz_final
162/3:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 0.4, (1e-11, 1e-11)))
162/4:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 0.4, (1e-17, 1e-17)))
162/5:
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 0.4, (1e-8, 1e-8)))
162/6:
p = 1e-8
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 0.4, (p, p)))
162/7:
p = 1e-5
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 0.4, (p, p)))
162/8:
p = 8.5e-16
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 0.4, (p, p)))
162/9:
p = 8.5e-16
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 2.5, (p, p)))
163/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
%matplotlib inline
163/2: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mb", 0, 0, 1, 2.5, (1e-25, 1e-25))
163/3: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
163/4: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mb", 0, 0, 1, 2.5, (1e-25, 1e-25))
163/5:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
163/6:
# Setup parameters
sim_size = 10
lat_size = 0.2
l = 2
m = 1
n = 0
Eg = 2.2
P = (1e-12, 1e-12)
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("LH Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("HH Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("SO Normalization\n", norm_factor)
164/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
%matplotlib inline
164/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
164/3: XX_env, YY_env, ZZ_env, envolute, t_matrix = qd_wavefunction.norm_envolute(10, 0.2, "L6mb", 0, 0, 1, 2.5, (1e-25, 1e-25))
164/4:
# l/m/n values
fig, ax = plt.subplots(figsize=(6, 6))
ax.contourf(XX_env[:, :, 50], ZZ_env[50].T, np.abs(envolute[:, 50])**2, cmap=cm.jet)
plt.show()
164/5:
# Setup parameters
sim_size = 10
lat_size = 0.2
l = 2
m = 1
n = 0
Eg = 2.2
P = (1e-12, 1e-12)
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB1 Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB2 Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("VB1 Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("VB2 Normalization\n", norm_factor)
164/6:
# Setup parameters
sim_size = 10
lat_size = 0.2
l = 2
m = 1
n = 0
Eg = 2.2
P = (1e-25, 1e-25)
# Guarantee normalization for the CB
qd_wavefunction_cb = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_cb = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_cb:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB1 Normalization\n", norm_factor)

# Normalization for Light Holes
norm_factor = 0
qd_wavefunction_lh = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_lh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_lh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("CB2 Normalization\n", norm_factor)

# Normalization for Heavy Holes
norm_factor = 0
qd_wavefunction_hh = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_hh = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_hh:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("VB1 Normalization\n", norm_factor)

norm_factor = 0
qd_wavefunction_so = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction_cb.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)
envolutes_so = [envolute_S, envolute_Y, envolute_X, envolute_Z]
norm_factor = 0
for envolute in envolutes_so:
    norm_factor += np.sum(np.abs(envolute)**2)*(lat_size)**3
print("VB2 Normalization\n", norm_factor)
164/7:
# Setup parameters
sim_size = 10
lat_size = 0.15
l = 2
m = 0
n = 0
Eg = 1.42
P = (1e-25, 1e-25)
center = int(sim_size/lat_size/2)
print(center)
164/8:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
164/9:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
164/10:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
164/11:
# Guarantee normalization for the CB
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "VB2")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
164/12:
sim_size = 8
lat_size = 0.15
l = 3
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
164/13:
sim_size = 8
lat_size = 0.15
l = 3
m = 0
n = 0
Eg = 0.4
P = (1e-25, 1e-25)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
164/14:
sim_size = 8
lat_size = 0.15
l = 3
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
164/15:
sim_size = 8
lat_size = 0.15
l = 3
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(4, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
164/16:
sim_size = 15
lat_size = 0.3
l = 3
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(4, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
164/17:
sim_size = 15
lat_size = 0.3
l = 3
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
exp_df = pd.DataFrame(exp_data)
exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
164/18: from pyevtk.hl import gridToVTK
164/19:
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK("./test", x, x, x, pointData = {'QD': np.log10(np.abs(envolute_S)**2)})
164/20:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-6
    my_zeros = My_array > 10e-6
    mz_zeros = Mz_array > 10e-6
    # Compute the average
    Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.average(My_array, weights=my_zeros)
    Mz_final = np.average(Mz_array, weights=mz_zeros)
    return Mx_final, My_final, Mz_final
164/21:
p = 1e-25
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 2.5, (p, p)))
164/22:
p = 1e-25
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 1), (8, 0.2, 2.5, (p, p)))
164/23:
p = 1e-25
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 2.5, (p, p)))
164/24:
p = 1e-25
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB1")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 2.5, (p, p)))
164/25:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-5
    my_zeros = My_array > 10e-5
    mz_zeros = Mz_array > 10e-5
    # Compute the average
    if mx_zeros is False:
        Mx_final = 0
    else:
        Mx_final = np.average(Mx_array, weights=mx_zeros)
    My_final = np.average(My_array, weights=my_zeros)
    Mz_final = np.average(Mz_array, weights=mz_zeros)
    return Mx_final, My_final, Mz_final
164/26:
p = 1e-25
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB1")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 2.5, (p, p)))
164/27:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-5
    my_zeros = My_array > 10e-5
    mz_zeros = Mz_array > 10e-5
    # Compute the average
    if True in mx_zeros:
        Mx_final = np.average(Mx_array, weights=mx_zeros)
    else:
        Mx_final = 0
    if True in my_zeros:
        My_final = np.average(My_array, weights=my_zeros)
    else:
        My_final = 0
    if True in mz_zeros:
        Mz_final = np.average(Mz_array, weights=mz_zeros)
    else:
        Mz_final = 0
    return Mx_final, My_final, Mz_final
164/28:
p = 1e-25
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB1")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 2.5, (p, p)))
164/29:
p = 1e-25
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "CB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 2.5, (p, p)))
164/30:
p = 1e-25
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB1")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 2.5, (p, p)))
164/31:
p = 1e-25
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 1), (8, 0.2, 2.5, (p, p)))
164/32:
p = 1e-25
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 1), qd_test_1, (0, 0), (8, 0.2, 2.5, (p, p)))
164/33:
p = 1e-25
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB2")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 2.5, (p, p)))
164/34:
p = 1e-25
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB1")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 0), (8, 0.2, 2.5, (p, p)))
164/35:
p = 1e-25
qd_test_1 = qbd.qd_results(5, 1.1, 0.08, 0.08, "CB1")
qd_test_2 = qbd.qd_results(5, 0.6, 0.08, 0.08, "VB1")
envolute_matrix_element(qd_test_2, (0, 0), qd_test_1, (0, 2), (8, 0.2, 2.5, (p, p)))
164/36:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator from the input values
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-5
    my_zeros = My_array > 10e-5
    mz_zeros = Mz_array > 10e-5
    # Check if the mask does not sum to 0 and determine the average
    if True in mx_zeros:
        Mx_final = np.average(Mx_array, weights=mx_zeros)
    else:
        Mx_final = 0
    if True in my_zeros:
        My_final = np.average(My_array, weights=my_zeros)
    else:
        My_final = 0
    if True in mz_zeros:
        Mz_final = np.average(Mz_array, weights=mz_zeros)
    else:
        Mz_final = 0
    return Mx_final, My_final, Mz_final
164/37:
sizes = np.linspace(1, 5, 5)
sim_properties = (20, 0.3, 2.3, (1e-25, 1e-25))
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (1, 0), (1, 2), (1, 3), (1, 4), (2, 0), (2, 1)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 1.2, 0.08, 0.08, "VB1")
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB1")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            print("No present levels")
            continue
165/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
%matplotlib inline
165/2:
sizes = np.linspace(1, 5, 5)
sim_properties = (20, 0.3, 2.3, (1e-25, 1e-25))
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 2), (1, 3)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 1.2, 0.08, 0.08, "VB1")
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB1")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            print("No present levels")
            continue
165/3:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator from the input values
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        print("Calculating....")
        print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-5
    my_zeros = My_array > 10e-5
    mz_zeros = Mz_array > 10e-5
    # Check if the mask does not sum to 0 and determine the average
    if True in mx_zeros:
        Mx_final = np.average(Mx_array, weights=mx_zeros)
    else:
        Mx_final = 0
    if True in my_zeros:
        My_final = np.average(My_array, weights=my_zeros)
    else:
        My_final = 0
    if True in mz_zeros:
        Mz_final = np.average(Mz_array, weights=mz_zeros)
    else:
        Mz_final = 0
    return Mx_final, My_final, Mz_final
165/4:
sizes = np.linspace(1, 5, 5)
sim_properties = (20, 0.3, 2.3, (1e-25, 1e-25))
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 2), (1, 3)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 1.2, 0.08, 0.08, "VB1")
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB1")
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            print("No present levels")
            continue
166/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
%matplotlib inline
166/2:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator from the input values
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        # print("Calculating....")
        # print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    # print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-5
    my_zeros = My_array > 10e-5
    mz_zeros = Mz_array > 10e-5
    # Check if the mask does not sum to 0 and determine the average
    if True in mx_zeros:
        Mx_final = np.average(Mx_array, weights=mx_zeros)
    else:
        Mx_final = 0
    if True in my_zeros:
        My_final = np.average(My_array, weights=my_zeros)
    else:
        My_final = 0
    if True in mz_zeros:
        Mz_final = np.average(Mz_array, weights=mz_zeros)
    else:
        Mz_final = 0
    return Mx_final, My_final, Mz_final
166/3:
sizes = np.linspace(1, 5, 5)
sim_properties = (20, 0.3, 2.3, (1e-25, 1e-25))
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 2), (1, 3)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 1.2, 0.08, 0.08, "VB1")
    if (qd1.e_levels == []):
        continue
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB1")
    if (qd2.e_levels == []):
        continue
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            print("No present levels")
            continue
166/4:
sizes = np.linspace(1, 5, 5)
sim_properties = (20, 0.3, 2.3, (1e-25, 1e-25))
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 2), (1, 3)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 1.2, 0.08, 0.08, "VB1")
    if not qd1.e_levels:
        continue
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB1")
    if not qd2.e_levels:
        continue
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            print("No present levels")
            continue
166/5:
sizes = np.linspace(1, 5, 5)
sim_properties = (20, 0.3, 2.3, (1e-25, 1e-25))
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 2), (1, 3)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 1.2, 0.08, 0.08, "VB1")
    if qd1.e_levels.empty:
        continue
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB1")
    if qd.e_levels.empty:
        continue
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            print("No present levels")
            continue
166/6:
sizes = np.linspace(1, 5, 5)
sim_properties = (20, 0.3, 2.3, (1e-25, 1e-25))
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 2), (1, 3)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 1.2, 0.08, 0.08, "VB1")
    if qd1.e_levels.empty:
        continue
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB1")
    if qd2.e_levels.empty:
        continue
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        print("Calculating from:", state_lh, state_cb)
        try:
            envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
        except IndexError:
            print("No present levels")
            continue
167/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
%matplotlib inline
167/2:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator from the input values
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        # print("Calculating....")
        # print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    # print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-5
    my_zeros = My_array > 10e-5
    mz_zeros = Mz_array > 10e-5
    # Check if the mask does not sum to 0 and determine the average
    if True in mx_zeros:
        Mx_final = np.average(Mx_array, weights=mx_zeros)
    else:
        Mx_final = 0
    if True in my_zeros:
        My_final = np.average(My_array, weights=my_zeros)
    else:
        My_final = 0
    if True in mz_zeros:
        Mz_final = np.average(Mz_array, weights=mz_zeros)
    else:
        Mz_final = 0
    return Mx_final, My_final, Mz_final
167/3:
sizes = np.linspace(1, 5, 5)
sim_properties = (20, 0.3, 2.3, (1e-25, 1e-25))
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 2), (1, 3)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 1.2, 0.08, 0.08, "VB1")
    if qd1.e_levels.empty:
        continue
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB1")
    if qd2.e_levels.empty:
        continue
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        try:
            print("Calculating from:", state_lh, state_cb)
            Mx, My, Mz = envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
            print("Mx: ", Mx, "My: ", My, "Mz: ", Mz)
        except IndexError:
            continue
168/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
%matplotlib inline
168/2:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator from the input values
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        # print("Calculating....")
        # print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    # print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-5
    my_zeros = My_array > 10e-5
    mz_zeros = Mz_array > 10e-5
    # Check if the mask does not sum to 0 and determine the average
    if True in mx_zeros:
        Mx_final = np.average(Mx_array, weights=mx_zeros)
    else:
        Mx_final = 0
    if True in my_zeros:
        My_final = np.average(My_array, weights=my_zeros)
    else:
        My_final = 0
    if True in mz_zeros:
        Mz_final = np.average(Mz_array, weights=mz_zeros)
    else:
        Mz_final = 0
    return Mx_final, My_final, Mz_final
168/3:
sizes = np.linspace(1, 5, 5)
sim_properties = (20, 0.3, 2.3, (1e-25, 1e-25))
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 2), (1, 3)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 1.2, 0.08, 0.08, "VB1")
    if qd1.e_levels.empty:
        continue
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB1")
    if qd2.e_levels.empty:
        continue
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        try:
            Mx, My, Mz = envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
            print("Calculating from:", state_lh, state_cb)
            print("Mx: ", Mx, "My: ", My, "Mz: ", Mz)
        except IndexError:
            continue
170/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
%matplotlib inline
170/2:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk import gridToVTK
%matplotlib inline
170/3:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
170/4:
sim_size = 15
lat_size = 0.3
l = 3
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"./band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.log10(np.abs(envolute_S)**2)})
170/5:
sim_size = 15
lat_size = 0.3
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"./band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.log10(np.abs(envolute_S)**2)})
170/6:
sim_size = 15
lat_size = 0.3
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"./band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
170/7:
sim_size = 15
lat_size = 0.3
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"./band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
170/8:
sim_size = 15
lat_size = 0.3
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"./band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
170/9:
sim_size = 15
lat_size = 0.1
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"./band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
170/10:
sim_size = 15
lat_size = 0.1
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"./band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
170/11:
sim_size = 10
lat_size = 0.1
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"./band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
170/12:
sim_size = 10
lat_size = 0.05
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"./band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
171/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
171/2:
sim_size = 10
lat_size = 0.1
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"./band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
172/2:
sim_size = 10
lat_size = 0.1
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"./band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/3:
sim_size = 10
lat_size = 0.1
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/4:
sim_size = 10
lat_size = 0.1
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/5:
sim_size = 10
lat_size = 0.1
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6pt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/6:
sim_size = 10
lat_size = 0.1
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6pb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/7:
sim_size = 10
lat_size = 0.3
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6pb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/8:
sim_size = 10
lat_size = 0.2
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6pb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/9:
sim_size = 10
lat_size = 0.15
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6pb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/10:
sim_size = 15
lat_size = 0.15
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6pb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/11:
sim_size = 15
lat_size = 0.3
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6pb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/12:
sim_size = 10
lat_size = 0.2
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6pb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/13:
sim_size = 10
lat_size = 0.2
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/14:
sim_size = 10
lat_size = 0.2
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6mb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/15:
sim_size = 10
lat_size = 0.2
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6pt"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/16:
sim_size = 10
lat_size = 0.2
l = 0
m = 0
n = 0
Eg = 2.5
P = (1e-25, 1e-25)
env = "L6pb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/17:
sim_size = 10
lat_size = 0.2
l = 0
m = 0
n = 0
Eg = 0.4
P = (1e-25, 1e-25)
env = "L6pb"
band = "CB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/18:
sim_size = 10
lat_size = 0.2
l = 0
m = 0
n = 0
Eg = 0.4
P = (1e-25, 1e-25)
env = "L6pb"
band = "CB2"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/19:
sim_size = 10
lat_size = 0.2
l = 0
m = 0
n = 0
Eg = 0.4
P = (1e-25, 1e-25)
env = "L6pt"
band = "CB2"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/20:
sim_size = 10
lat_size = 0.2
l = 0
m = 0
n = 0
Eg = 0.4
P = (1e-25, 1e-25)
env = "L6pt"
band = "VB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/21:
sim_size = 10
lat_size = 0.2
l = 0
m = 0
n = 0
Eg = 0.4
P = (1e-25, 1e-25)
env = "L6pb"
band = "VB1"
center = int(sim_size/lat_size/2)
print(center)
qd_wavefunction = qbd.qd_results(3, 1, 0.08, 0.08, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env, l, m, n, Eg, P)
fig, ax = plt.subplots(figsize=(13, 13))
ax.contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[10])**2, cmap=cm.jet)
ax.set_title("L6mt envolute")
plt.show()
# exp_data = {"X": XX_env_S.flatten(), "Y": YY_env_S.flatten(), "Z": ZZ_env_S.flatten(), "env": (np.abs(envolute_S)**2).flatten()}
# exp_df = pd.DataFrame(exp_data)
# exp_df.to_csv(f"{env}_envolute_{l}_{m}_{n}_{band}.csv", index=False)
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"Article_2_Results/band_{band}_envolute_{env}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
172/22:
sizes = np.linspace(1, 5, 5)
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 2), (1, 3)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 1.2, 0.08, 0.08, "VB1")
    if qd1.e_levels.empty:
        continue
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB1")
    if qd2.e_levels.empty:
        continue
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        try:
            Mx, My, Mz = envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
            print("Calculating from:", state_lh, state_cb)
            print("Mx: ", Mx, "My: ", My, "Mz: ", Mz)
        except IndexError:
            continue
172/23:
def envolute_matrix_element(qd_i, e_i, qd_f, e_f, sim_properties):
    """
    Determines the envolute matrix elements between qd_1 and qd_2
    """
    # assert qd_i.band != qd_f.band, "Bands should be different"
    envolutes = ["L6mt", "L6mb", "L6pt", "L6pb"]
    sim_size, lat_size, Eg, P = sim_properties
    ni, li = e_i
    nf, lf = e_f
    Mx_array = []
    My_array = []
    Mz_array = []
    # Define the iterator from the input values
    if li != 0 and lf != 0:
        iterator = product(range(-li, li + 1), range(-lf, lf + 1))
    elif li == 0 and lf != 0:
        iterator = product([0], range(-lf, lf + 1))
    elif li != 0 and lf == 0:
        iterator = product(range(-li, li + 1), [0])
    else:
        iterator = zip([0], [0])
    # Loop through all possible m value combinations
    for m_i_i, m_f_i in iterator:
        # print("Calculating....")
        # print(m_i_i, m_f_i)
        # Calculate the matrix element for transition between 2 elements (for a specific m value)
        # This element is determined from the sum of the elements from the 4 envolutes
        Mx, My, Mz = 0, 0, 0
        for envolute in envolutes:
            XX, YY, ZZ, env_i, _ = qd_i.norm_envolute(sim_size, lat_size, envolute, li, m_i_i, ni, Eg, P)
            _, _, _, env_f, _ = qd_f.norm_envolute(sim_size, lat_size, envolute, lf, m_f_i, nf, Eg, P)
            # Function integration
            Mx += np.sum(env_i * XX * np.conjugate(env_f)) * lat_size ** 3
            My += np.sum(env_i * YY * np.conjugate(env_f)) * lat_size ** 3
            Mz += np.sum(env_i * ZZ * np.conjugate(env_f)) * lat_size ** 3
        # Determine the matrix element from n1, l1, m1 to n2, l2, m2
        Mx_array.append(np.abs(Mx))
        My_array.append(np.abs(My))
        Mz_array.append(np.abs(Mz))
    # Put all Mx/My/Mz values under 1e-7 to 0
    Mx_array = np.array(Mx_array)
    My_array = np.array(My_array)
    Mz_array = np.array(Mz_array)
    # print("Mx Values", Mx_array, "My_values", My_array, "Mz Values", Mz_array, sep="\n")
    # Obtain the mean of the non-zero values
    # Create a mask for the weigths
    mx_zeros = Mx_array > 10e-5
    my_zeros = My_array > 10e-5
    mz_zeros = Mz_array > 10e-5
    # Check if the mask does not sum to 0 and determine the average
    if True in mx_zeros:
        Mx_final = np.average(Mx_array, weights=mx_zeros)
    else:
        Mx_final = 0
    if True in my_zeros:
        My_final = np.average(My_array, weights=my_zeros)
    else:
        My_final = 0
    if True in mz_zeros:
        Mz_final = np.average(Mz_array, weights=mz_zeros)
    else:
        Mz_final = 0
    return Mx_final, My_final, Mz_final
172/24:
sizes = np.linspace(1, 5, 5)
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
levels = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 2), (1, 3)]
for size in sizes:
    print("Calculation for size: ", size, "\n")
    qd1 = qbd.qd_results(size, 1.2, 0.08, 0.08, "VB1")
    if qd1.e_levels.empty:
        continue
    print("QD1 Energy Levels:")
    print(qd1.e_levels)
    qd2 = qbd.qd_results(size, 0.7, 0.1, 0.1, "CB1")
    if qd2.e_levels.empty:
        continue
    print("QD2 Energy Levels:")
    print(qd2.e_levels)
    print("\n")
    for state_lh, state_cb in product(levels, levels):
        try:
            Mx, My, Mz = envolute_matrix_element(qd1, state_lh, qd2, state_cb, sim_properties)
            print("Calculating from:", state_lh, state_cb)
            print("Mx: ", Mx, "My: ", My, "Mz: ", Mz)
        except IndexError:
            continue
174/1:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
174/2: qbd.qd_results(3, 1, 0.08, 0.08, "Lm6t")
174/3: qbd.qd_results(3, 1, 0.08, 0.08, "CB1")
174/4: qd_cicle = qbd.qd_results(3, 1, 0.08, 0.08, "CB1")
174/5: qd_cicle.energy_levels
174/6: qd_cicle.energy_levels()
174/7: qd_cicle.e_levels
174/8: qd_cicle = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
174/9: qd_cicle.e_levels
174/10: values = qd_cicle.e_levels.values
174/11: values
174/12: array1 = np.array([[1, 2, 3], [4, 5, 6]])
174/13:
array1 = np.array([[1, 2, 3], [4, 5, 6]])
array2 = np.array([[7, 8, 9], [10, 11, 12]])
174/14: list(product(array1, array2))
174/15: values.flatten()
174/16: values.flatten(order="F")
174/17: values
174/18: values.shape
174/19: list(product(range(values.shape[0]), range(values.shape[1])))
174/20: values = qd_cicle.e_levels.values.flatten
174/21: levels = list(product(range(values.shape[0]), range(values.shape[1])))
174/22:
values = qd_cicle.e_levels.values
list_values = values.flatten
174/23: levels = list(product(range(values.shape[0]), range(values.shape[1])))
174/24: list_values
174/25:
values = qd_cicle.e_levels.values
list_values = values.flatten()
174/26: levels = list(product(range(values.shape[0]), range(values.shape[1])))
174/27: list_values
174/28: levels(list_values != NaN)
174/29: levels(list_values != nan)
174/30: levels(list_values != np.NaN)
174/31:
values = qd_cicle.e_levels.values
list_values = values.flatten()
174/32: levels = np.array(product(range(values.shape[0]), range(values.shape[1])))
174/33: levels
174/34: levels = list(product(range(values.shape[0]), range(values.shape[1])))
174/35: levels
174/36: levels[1, 2, 3]
174/37: levels[1]
174/38: levels[1:2]
174/39: levels[1]
174/40: levels[1:4]
174/41: levels[1;2]
174/42: levels[1 2]
174/43: levels[[2][1]]
174/44: levels[[2]]
174/45: levels[1]
174/46: levels
174/47: np.array(levels)
174/48:
def interband_transition_elements(qd_1, qd_2):
    """
    Calculates the interband transition elements between qd_1 and qd_2
    """
    # Create a list with all the present (n, l) level combinations
    qd1_e_values = qd_1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd_2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    for qd1_level, qd2_level in product(qd1_levels, qd2_levels):
        print(qd1_level, qd2_level)
    return
174/49:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
interband_transition_elements(qd1, qd2)
174/50:
def interband_transition_elements(qd_1, qd_2):
    """
    Calculates the interband transition elements between qd_1 and qd_2
    """
    # Create a list with all the present (n, l) level combinations
    qd1_e_values = qd_1.e_levels.values
    qd1_e_values_list = qd1_e_values.flatten()
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd_2.e_levels.values
    qd2_e_values_list = qd2_e_values.flatten()
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    for qd1_level, qd2_level in product(qd1_levels, qd2_levels):
        print(qd1_level, qd2_level)
    return
174/51:
def interband_transition_elements(qd_1, qd_2):
    """
    Calculates the interband transition elements between qd_1 and qd_2
    """
    # Create a list with all the present (n, l) level combinations
    qd1_e_values = qd_1.e_levels.values
    qd1_e_values_list = qd1_e_values.flatten()
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd_2.e_levels.values
    qd2_e_values_list = qd2_e_values.flatten()
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(product(qd1_levels, qd2_levels), product(qd1_e_values_list, qd2_e_values_list)):
        print(qd1_level, qd2_level, qd1_energy, qd2_energy)
    return
174/52:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
interband_transition_elements(qd1, qd2)
174/53:
def interband_transition_elements(qd1, qd2):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd_2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten()):
        print(qd1_level, qd2_level, qd1_energy, qd2_energy)
    return
174/54:
def interband_transition_elements(qd1, qd2):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd_2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        
        print(qd1_level, qd2_level, qd1_energy, qd2_energy)
    return
174/55:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
interband_transition_elements(qd1, qd2)
174/56:
def interband_transition_elements(qd1, qd2):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        
        print(qd1_level, qd2_level, qd1_energy, qd2_energy)
    return
174/57:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
interband_transition_elements(qd1, qd2)
174/58:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2)
174/59:
def interband_transition_elements(qd1, qd2):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    # Cicle through all the (n, l) combination of both qds
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        
        print(qd1_level, qd2_level, qd1_energy, qd2_energy)
    return
174/60:
def interband_transition_elements(qd1, qd2):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        if qd1_energy == np.NaN or qd2.energy == np.NaN:
            continue
        print(qd1_level, qd2_level, qd1_energy, qd2_energy)
    return
174/61:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2)
174/62:
def interband_transition_elements(qd1, qd2):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        if qd1_energy == np.NaN or qd2_energy == np.NaN:
            continue
        print(qd1_level, qd2_level, qd1_energy, qd2_energy)
    return
174/63:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2)
174/64:
def interband_transition_elements(qd1, qd2):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        if qd1_energy == np.NaN or qd2_energy == np.NaN:
            continue
        print(qd1_level, qd2_level, qd1_energy, qd2_energy, type(qd1_energy))
    return
174/65:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2)
174/66:
def interband_transition_elements(qd1, qd2):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        if qd1_energy == np.nan or qd2_energy == np.NaN:
            continue
        print(qd1_level, qd2_level, qd1_energy, qd2_energy, type(qd1_energy))
    return
174/67:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2)
174/68:
def interband_transition_elements(qd1, qd2):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        print(qd1_energy.is_nan())
        if qd1_energy == np.nan or qd2_energy == np.NaN:
            continue
        print(qd1_level, qd2_level, qd1_energy, qd2_energy, type(qd1_energy))
    return
174/69:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2)
174/70:
def interband_transition_elements(qd1, qd2):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        print(qd1_energy.isnan())
        if qd1_energy == np.nan or qd2_energy == np.NaN:
            continue
        print(qd1_level, qd2_level, qd1_energy, qd2_energy, type(qd1_energy))
    return
174/71:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2)
174/72:
from band_model import qd_base_data as qbd
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
174/73:
def interband_transition_elements(qd1, qd2):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        print(math.isnan(qd1_energy))
        if qd1_energy == np.nan or qd2_energy == np.NaN:
            continue
        print(qd1_level, qd2_level, qd1_energy, qd2_energy, type(qd1_energy))
    return
174/74:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2)
174/75:
def interband_transition_elements(qd1, qd2):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        print(qd1_level, qd2_level, qd1_energy, qd2_energy, type(qd1_energy))
    return
174/76:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2)
174/77:
def interband_transition_elements(qd1, qd2):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        # Ignore all combination where either the energy of qd1 or qd2 is nan
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        print(qd1_level, qd2_level, qd1_energy, qd2_energy, type(qd1_energy))
    return
174/78:
from band_model import qd_base_data as qbd
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
174/79:
def interband_transition_elements(qd1, qd2, sim_properties):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        # Ignore all combination where either the energy of qd1 or qd2 is nan
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        print(qd1_level, qd2_level, qd1_energy, qd2_energy, type(qd1_energy))
        mx, my, mz = eme(qd1, qd1_level, qd2, qd2_level, sim_properties)
        print(mx, my, mz)
    return
174/80:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2)
174/81:
qd1 = qbd.qd_results(5, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.5, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2, sim_properties)
174/82:
def interband_transition_elements(qd1, qd2, sim_properties):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    transition_list = []
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        # Ignore all combination where either the energy of qd1 or qd2 is nan
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        transition_list.append((qd1_energy, qd2_energy, eme(qd1, qd1_level, qd2, qd2_level, sim_properties))
    return
174/83:
def interband_transition_elements(qd1, qd2, sim_properties):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    transition_list = []
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        # Ignore all combination where either the energy of qd1 or qd2 is nan
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        transition_list.append((qd1_energy, qd2_energy, eme(qd1, qd1_level, qd2, qd2_level, sim_properties))
    return transition_list
174/84:
def interband_transition_elements(qd1, qd2, sim_properties):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    transition_list = []
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        # Ignore all combination where either the energy of qd1 or qd2 is nan
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        transition_list.append((qd1_energy, qd2_energy, eme(qd1, qd1_level, qd2, qd2_level, sim_properties)))
    return transition_list
174/85:
def interband_transition_elements(qd1, qd2, sim_properties):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    # Determine the energy difference between the state in qd1 and qd2
    # Assuming 0 in to of Valence Band
    # Evb = -Eqd-vb
    # Ecb = Eg + Eqd-cb
    if qd1.band == "CB":
        qd1_e_values += sim_properties[2]
    else:
        qd1_e_values = - qd2_e_values
    if qd2.band == "CB":
        qd2_e_values += sim_properties[2]
    else:
        qd2_e_values = - qd2_e_values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    transition_list = []
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        # Ignore all combination where either the energy of qd1 or qd2 is nan
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        transition_list.append((qd1_energy - qd2_energy, eme(qd1, qd1_level, qd2, qd2_level, sim_properties)))
    return transition_list
174/86:
qd1 = qbd.qd_results(3, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(3, 0.5, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2, sim_properties)
174/87:
def interband_transition_elements(qd1, qd2, sim_properties):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    # Determine the energy difference between the state in qd1 and qd2
    # Assuming 0 in to of Valence Band
    # Evb = -Eqd-vb
    # Ecb = Eg + Eqd-cb
    qd1_e_values = qd1.e_levels.values
    if qd1.band == "CB":
        qd1_e_values += sim_properties[2]
    else:
        qd1_e_values = - qd2_e_values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    if qd2.band == "CB":
        qd2_e_values += sim_properties[2]
    else:
        qd2_e_values = - qd2_e_values
    transition_list = []
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        # Ignore all combination where either the energy of qd1 or qd2 is nan
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        transition_list.append((qd1_energy - qd2_energy, eme(qd1, qd1_level, qd2, qd2_level, sim_properties)))
    return transition_list
174/88:
qd1 = qbd.qd_results(3, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(3, 0.5, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2, sim_properties)
174/89:
def interband_transition_elements(qd1, qd2, sim_properties):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    # Determine the energy difference between the state in qd1 and qd2
    # Assuming 0 in to of Valence Band
    # Evb = -Eqd-vb
    # Ecb = Eg + Eqd-cb
    qd1_e_values = qd1.e_levels.values
    if qd1.band == "CB":
        qd1_e_values += sim_properties[2]
    else:
        qd1_e_values = - qd1_e_values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    if qd2.band == "CB":
        qd2_e_values += sim_properties[2]
    else:
        qd2_e_values = - qd2_e_values
    transition_list = []
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        # Ignore all combination where either the energy of qd1 or qd2 is nan
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        transition_list.append((qd1_energy - qd2_energy, eme(qd1, qd1_level, qd2, qd2_level, sim_properties)))
    return transition_list
174/90:
qd1 = qbd.qd_results(3, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(3, 0.5, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2, sim_properties)
174/91: 2.3-0.66-0.22
174/92:
def interband_transition_elements(qd1, qd2, sim_properties):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    # Determine the energy difference between the state in qd1 and qd2
    # Assuming 0 in to of Valence Band
    # Evb = -Eqd-vb
    # Ecb = Eg + Eqd-cb
    qd1_e_values = qd1.e_levels.values
    if qd1.band == "CB":
        qd1_e_values += sim_properties[2]
    else:
        qd1_e_values = - qd1_e_values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    if qd2.band == "CB":
        qd2_e_values += sim_properties[2]
    else:
        qd2_e_values = - qd2_e_values
    transition_list = []
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        # Ignore all combination where either the energy of qd1 or qd2 is nan
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        transition_list.append((qd1_energy + qd2_energy, eme(qd1, qd1_level, qd2, qd2_level, sim_properties)))
    return transition_list
174/93:
qd1 = qbd.qd_results(3, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(3, 0.5, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2, sim_properties)
174/94:
def interband_transition_elements(qd1, qd2, sim_properties):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    # Determine the energy difference between the state in qd1 and qd2
    # Assuming 0 in to of Valence Band
    # Evb = -Eqd-vb
    # Ecb = Eg + Eqd-cb
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    transition_list = []
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        # Ignore all combination where either the energy of qd1 or qd2 is nan
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        transition_list.append((sim_properties[2] + qd1_energy + qd2_energy,
                                eme(qd1, qd1_level, qd2, qd2_level, sim_properties)))
    return transition_list
174/95:
qd1 = qbd.qd_results(3, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(3, 0.5, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
interband_transition_elements(qd1, qd2, sim_properties)
174/96:
def interband_transition_elements(qd1, qd2, sim_properties):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    # Determine the energy difference between the state in qd1 and qd2
    # Assuming 0 in to of Valence Band
    # Evb = -Eqd-vb
    # Ecb = Eg + Eqd-cb
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    transition_list = []
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        # Ignore all combinations where either the energy of qd1 or qd2 is nan
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        transition_list.append((sim_properties[2] + qd1_energy + qd2_energy,
                                eme(qd1, qd1_level, qd2, qd2_level, sim_properties)))
    return transition_list
174/97:
def inter_absorption_ij(energy,
                        t_energy,
                        matrix_elements,
                        gauss_dispersion=0.025,
                        qd_density=(1 / 50, 1 / 50, 1 / 50),
                        n_index=2.5):
    """Gaussian absorption profile for energy transition from an initial to a
    final state
    Args:
        energy (array): Base array [eV]
        t_energy (double): Transition energy (energy difference between the
                            initial and final states) [eV]
        gauss_dispersion (double): Dispersion value for the Gaussian profile
                            (default - 0.025 eV)
        matrix_elements (tuple): Matrix elements for the different
                            polarizations [nm]
        qd_density (tuple): Linear qd density for the 3 different dimensions
                        (default - (1/50nm, 1/50nm, 1/50nm)) [nm-1]
        n_index (array): Refractive index array - should be the same shape
                        as the energy or single valued (default = 2)
    Returns:
        abs_ij (array): Absorption for the transition i->j [cm-1]
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * energy) /
                         (n_index * c * h * e0))
    # Volumetric fraction in nm-2cm-1
    # These units serve to cancel the nm2 from the matrix element
    rho_density = qd_density[0] * qd_density[1] * qd_density[2] * 10**7
    volume_fraction = (6 * rho_density) / np.pi  # Volumetric fraction of QDs
    delta = (1 / (np.sqrt(np.pi) * gauss_dispersion)) * \
        np.exp(-((energy - t_energy) / gauss_dispersion)
               ** 2)  # Define delta function
    abs_ij = 2 * matrix_elements**2 * constant_fraction * \
        volume_fraction * delta  # Calculate absorption
    return abs_ij
174/98:
qd1 = qbd.qd_results(3, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(3, 0.5, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(0, 2, 100)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += inter_absorption_ij(energy, t_energy, matrix_element)
174/99:
qd1 = qbd.qd_results(3, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(3, 0.5, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(0, 2, 100)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += inter_absorption_ij(energy, t_energy, matrix_element)
    
plt.plot(energy, absorption)
174/100:
qd1 = qbd.qd_results(4, 1, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(4, 0.5, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(0, 2, 100)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += inter_absorption_ij(energy, t_energy, matrix_element)
    
plt.plot(energy, absorption)
174/101:
qd1 = qbd.qd_results(4, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(4, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(0, 2, 100)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += inter_absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.1)
    
plt.plot(energy, absorption)
174/102:
qd1 = qbd.qd_results(1.4, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(1.4, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(0, 2, 100)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += inter_absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.1)
    
plt.plot(energy, absorption)
174/103:
qd1 = qbd.qd_results(1.4, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(1.4, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 100)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += inter_absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.1)
    
plt.plot(energy, absorption)
174/104:
qd1 = qbd.qd_results(1.4, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(1.4, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 100)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += inter_absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
174/105:
qd1 = qbd.qd_results(2, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(2, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 100)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += inter_absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
174/106:
qd1 = qbd.qd_results(2, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(2, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += inter_absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
174/107:
def interband_transition_elements(qd1, qd2, sim_properties):
    """
    Calculates the interband transition elements between qd1 and qd2
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    transition_list = []
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        # Ignore all combinations where either the energy of qd1 or qd2 is nan
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        transition_list.append((sim_properties[2] + qd1_energy + qd2_energy,
                                eme(qd1, qd1_level, qd2, qd2_level, sim_properties)))
    return transition_list
174/108:
qd1 = qbd.qd_results(3, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(3, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += inter_absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
174/109:
def interband_transition_elements(qd1, qd2, sim_properties):
    """
    Calculates all the interband transition elements between qd1 and qd2
    Returns:
        transition_list (list): List with the transition elements (Transition energy, (Mx, My, Mz))
    """
    # Create a list with all the present (n, l) level combinations for each qd
    qd1_e_values = qd1.e_levels.values
    qd1_levels = list(product(range(qd1_e_values.shape[0]), range(qd1_e_values.shape[1])))
    qd2_e_values = qd2.e_levels.values
    qd2_levels = list(product(range(qd2_e_values.shape[0]), range(qd2_e_values.shape[1])))
    transition_list = []
    # Cicle through all the (n, l) combination of both qds, coupled with each particular energy level
    for ((qd1_level, qd2_level), (qd1_energy, qd2_energy)) in zip(
        product(qd1_levels, qd2_levels), 
        product(qd1_e_values.flatten(), qd2_e_values.flatten())):
        # Ignore all combinations where either the energy of qd1 or qd2 is nan
        if math.isnan(qd1_energy) or math.isnan(qd2_energy):
            continue
        transition_list.append((sim_properties[2] + qd1_energy + qd2_energy,
                                eme(qd1, qd1_level, qd2, qd2_level, sim_properties)))
    return transition_list
174/110:
def inter_absorption_ij(energy,
                        t_energy,
                        matrix_elements,
                        gauss_dispersion=0.025,
                        n_index=2.5):
    """Gaussian absorption density profile for energy transition from an initial to a
    final state
    Args:
        energy (array): Base array [eV]
        t_energy (double): Transition energy (energy difference between the
                            initial and final states) [eV]
        gauss_dispersion (double): Dispersion value for the Gaussian profile
                            (default - 0.025 eV)
        matrix_elements (tuple): Matrix elements for the different
                            polarizations [nm]
        qd_density (tuple): Linear qd density for the 3 different dimensions
                        (default - (1/50nm, 1/50nm, 1/50nm)) [nm-1]
        n_index (array): Refractive index array - should be the same shape
                        as the energy or single valued (default = 2)
    Returns:
        abs_ij (array): Absorption for the transition i->j [cm-1]
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * energy) /
                         (n_index * c * h * e0))
    # Volumetric fraction in nm-2cm-1
    # These units serve to cancel the nm2 from the matrix element
    # rho_density = qd_density[0] * qd_density[1] * qd_density[2] * 10**7
    # volume_fraction = (6 * rho_density) / np.pi  # Volumetric fraction of QDs
    delta = (1 / (np.sqrt(np.pi) * gauss_dispersion)) * \
        np.exp(-((energy - t_energy) / gauss_dispersion)
               ** 2)  # Define delta function
    abs_ij = 2 * matrix_elements**2 * constant_fraction * \
        delta  # Calculate absorption
    return abs_ij
174/111:
qd1 = qbd.qd_results(3, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(3, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += inter_absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
174/112:
def inter_absorption_ij(energy,
                        t_energy,
                        matrix_elements,
                        gauss_dispersion=0.025,
                        n_index=2.5):
    """Gaussian absorption density profile for energy transition from an initial to a
    final state
    Args:
        energy (array): Base array [eV]
        t_energy (double): Transition energy (energy difference between the
                            initial and final states) [eV]
        gauss_dispersion (double): Dispersion value for the Gaussian profile
                            (default - 0.025 eV)
        matrix_elements (tuple): Matrix elements for the different
                            polarizations [nm]
        qd_density (tuple): Linear qd density for the 3 different dimensions
                        (default - (1/50nm, 1/50nm, 1/50nm)) [nm-1]
        n_index (array): Refractive index array - should be the same shape
                        as the energy or single valued (default = 2)
    Returns:
        abs_ij (array): Absorption density for the transition i->j [cm-1nm-3]
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * energy) /
                         (n_index * c * h * e0))
    # Volumetric fraction in nm-2cm-1
    # These units serve to cancel the nm2 from the matrix element
    # rho_density = qd_density[0] * qd_density[1] * qd_density[2] * 10**7
    # volume_fraction = (6 * rho_density) / np.pi  # Volumetric fraction of QDs
    delta = (1 / (np.sqrt(np.pi) * gauss_dispersion)) * \
        np.exp(-((energy - t_energy) / gauss_dispersion)
               ** 2)  # Define delta function
    abs_ij = 2 * matrix_elements**2 * constant_fraction * \
        delta  # Calculate absorption
    return abs_ij
174/113:
def inter_absorption_ij(energy,
                        t_energy,
                        matrix_elements,
                        gauss_dispersion=0.025,
                        n_index=2.5):
    """Gaussian absorption density profile for energy transition from an initial to a
    final state
    Args:
        energy (array): Base array [eV]
        t_energy (double): Transition energy (energy difference between the
                            initial and final states) [eV]
        gauss_dispersion (double): Dispersion value for the Gaussian profile
                            (default - 0.025 eV)
        matrix_elements (tuple): Matrix elements for the different
                            polarizations [nm]
        qd_density (tuple): Linear qd density for the 3 different dimensions
                        (default - (1/50nm, 1/50nm, 1/50nm)) [nm-1]
        n_index (array): Refractive index array - should be the same shape
                        as the energy or single valued (default = 2)
    Returns:
        abs_ij (array): Absorption density for the transition i->j [cm-1nm-3]
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * energy) /
                         (n_index * c * h * e0))
    # Volumetric fraction in nm-2cm-1
    # These units serve to cancel the nm2 from the matrix element
    # rho_density = qd_density[0] * qd_density[1] * qd_density[2] * 10**7
    # volume_fraction = (6 * rho_density) / np.pi  # Volumetric fraction of QDs
    delta = (1 / (np.sqrt(np.pi) * gauss_dispersion)) * \
        np.exp(-((energy - t_energy) / gauss_dispersion)
               ** 2)  # Define delta function
    abs_ij = 2 * matrix_elements**2 * constant_fraction * \
        delta # Calculate absorption
    return abs_ij
174/114:
qd1 = qbd.qd_results(1.5, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(1.5, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += inter_absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
174/115:
def inter_absorption_ij(energy,
                        t_energy,
                        matrix_elements,
                        gauss_dispersion=0.025,
                        n_index=2.5):
    """Gaussian absorption density profile for energy transition from an initial to a
    final state
    Args:
        energy (array): Base array [eV]
        t_energy (double): Transition energy (energy difference between the
                            initial and final states) [eV]
        gauss_dispersion (double): Dispersion value for the Gaussian profile
                            (default - 0.025 eV)
        matrix_elements (tuple): Matrix elements for the different
                            polarizations [nm]
        qd_density (tuple): Linear qd density for the 3 different dimensions
                        (default - (1/50nm, 1/50nm, 1/50nm)) [nm-1]
        n_index (array): Refractive index array - should be the same shape
                        as the energy or single valued (default = 2)
    Returns:
        abs_ij (array): Absorption density for the transition i->j [cm-1nm-3]
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * energy) /
                         (n_index * c * h * e0))
    # Volumetric fraction in nm-2cm-1
    # These units serve to cancel the nm2 from the matrix element
    # rho_density = qd_density[0] * qd_density[1] * qd_density[2] * 10**7
    # volume_fraction = (6 * rho_density) / np.pi  # Volumetric fraction of QDs
    delta = (1 / (np.sqrt(np.pi) * gauss_dispersion)) * \
        np.exp(-((energy - t_energy) / gauss_dispersion)
               ** 2)  # Define delta function
    abs_ij = 2 * matrix_elements**2 * constant_fraction * \
        delta * 1e7 # Calculate absorption
    return abs_ij
174/116:
qd1 = qbd.qd_results(1.5, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(1.5, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += inter_absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
174/117:
def inter_absorption_ij(energy,
                        t_energy,
                        matrix_elements,
                        gauss_dispersion=0.025,
                        n_index=2.5):
    """Gaussian absorption density profile for energy transition from an initial to a
    final state
    Args:
        energy (array): Base array [eV]
        t_energy (double): Transition energy (energy difference between the
                            initial and final states) [eV]
        gauss_dispersion (double): Dispersion value for the Gaussian profile
                            (default - 0.025 eV)
        matrix_elements (tuple): Matrix elements for the different
                            polarizations [nm]
        qd_density (tuple): Linear qd density for the 3 different dimensions
                        (default - (1/50nm, 1/50nm, 1/50nm)) [nm-1]
        n_index (array): Refractive index array - should be the same shape
                        as the energy or single valued (default = 2)
    Returns:
        abs_ij (array): Absorption density for the transition i->j [cm-1nm-3]
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * energy) /
                         (n_index * c * h * e0))
    # Approximate the delta function
    delta = (1 / (np.sqrt(np.pi) * gauss_dispersion)) * \
        np.exp(-((energy - t_energy) / gauss_dispersion)
               ** 2)
    abs_ij = 2 * matrix_elements**2 * constant_fraction * \
        delta * 1e7 # Calculate absorption
    return abs_ij
174/118:
def inter_absorption_ij(energy,
                        t_energy,
                        matrix_elements,
                        gauss_dispersion=0.025,
                        n_index=2.5):
    """Gaussian absorption density profile for energy transition from an initial to a
    final state
    Args:
        energy (array): Base array [eV]
        t_energy (double): Transition energy (energy difference between the
                            initial and final states) [eV]
        gauss_dispersion (double): Dispersion value for the Gaussian profile
                            (default - 0.025 eV)
        matrix_elements (tuple): Matrix elements for the different
                            polarizations [nm]
        qd_density (tuple): Linear qd density for the 3 different dimensions
                        (default - (1/50nm, 1/50nm, 1/50nm)) [nm-1]
        n_index (array): Refractive index array - should be the same shape
                        as the energy or single valued (default = 2)
    Returns:
        abs_ij (array): Absorption density for the transition i->j [cm-1nm-3]
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * energy) /
                         (n_index * c * h * e0))
    # Approximate the delta function
    delta = (1 / (np.sqrt(np.pi) * gauss_dispersion)) * \
        np.exp(-((energy - t_energy) / gauss_dispersion)
               ** 2)
    # Calculate absorption coefficient
    # The 1e7 normalizes the units to nm3/cm
    abs_ij = 2 * matrix_elements**2 * constant_fraction * \
        delta * 1e7
    return abs_ij
177/1:
from band_model import qd_base_data as qbd
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
177/2: qd1 = qbd.qd_results(0.5, 1.2, 0.08, 0.08, "CB1")
177/3:
qd1 = qbd.qd_results(0.5, 1.2, 0.08, 0.08, "CB1")
qd1.e_levels
177/4:
qd1 = qbd.qd_results(0.5, 1.2, 0.08, 0.08, "CB1")
qd1.e_levels.values
177/5:
qd1 = qbd.qd_results(0.5, 1.2, 0.08, 0.08, "CB1")
assert(qd1.e_levels.values != [])
177/6:
qd1 = qbd.qd_results(0.5, 1.2, 0.08, 0.08, "CB1")
assert(qd1.e_levels.values != [], "QD with no energy levels")
177/7:
qd1 = qbd.qd_results(0.5, 1.2, 0.08, 0.08, "CB1")
assert qd1.e_levels.values != [], "QD with no energy levels"
178/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
178/2:
qd1 = qbd.qd_results(1.5, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(1.5, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.3, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
178/3:
qd1 = qbd.qd_results(5, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.5, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
179/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
179/2:
qd1 = qbd.qd_results(5, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.5, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
179/3:
qd1 = qbd.qd_results(1, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(1, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.5, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
179/4:
qd1 = qbd.qd_results(2, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(2, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.5, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
179/5:
qd1 = qbd.qd_results(2, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(2, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.5, 2.3, (1.3e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
179/6:
qd1 = qbd.qd_results(2, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(2, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.5, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
179/7:
qd1 = qbd.qd_results(2, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(2, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.15, 2.3, (1e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
179/8:
qd1 = qbd.qd_results(5, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.2, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
180/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
180/2:
qd1 = qbd.qd_results(5, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.25, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
181/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
181/2:
qd1 = qbd.qd_results(5, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.2, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
182/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
182/2:
qd1 = qbd.qd_results(5, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.25, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
183/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
183/2:
qd1 = qbd.qd_results(2, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(2, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.25, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
184/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
185/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
185/2:
qd1 = qbd.qd_results(2, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(2, 0.7, 0.08, 0.08, "VB1")
sim_properties = (10, 0.25, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
186/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
186/2:
qd1 = qbd.qd_results(5, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.25, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
187/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
187/2:
qd1 = qbd.qd_results(5, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(5, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.4, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(1, 2.3, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
187/3:
qd1 = qbd.qd_results(7, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(7, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.4, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
energy = np.linspace(0, 2.5, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
188/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
188/2:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
188/3: math.sqrt(3*scc.e*scc.m_e/2)
188/4: math.sqrt(1.6*scc.e*scc.m_e/2)
188/5:
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
size = 0.3
qd1 = qbd.qd_results(size, 1.2, me, me, "CB1")
qd2 = qbd.qd_results(size, 0.7, mh, mh, "VB1")
sim_properties = (20, 0.4, 2.3, (Pl, Pt))
188/6:
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
size = 0.3
Eg = 2.3
sim_properties = (20, 0.2, Eg, (Pl, Pt))
qd1 = qbd.qd_results(size, 0.85, me, me, "CB1")
qd2 = qbd.qd_results(size, 0.85, mh, mh, "VB1")
188/7:
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
size = 0.3
Eg = 2.3
sim_properties = (20, 0.2, Eg, (Pl, Pt))
qdcb1 = qbd.qd_results(size, 0.85, me, me, "CB1")
qdcb2 = qbd.qd_results(size, 0.85, me, me, "CB2")
qdvb1 = qbd.qd_results(size, 0.85, mh, mh, "VB1")
qdvb2 = qbd.qd_results(size, 0.85, mh, mh, "VB2")
188/8:
# List a few energy levels
gs = (0, 0)
e1 = (0, 1)
e2 = (0, 2)
e3 = (0, 3)
e4 = (1, 0)
188/9: ab.envolute_matrix_element(qdcb1, gs, qdvb1, gs, sim_properties)
188/10:
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
size = 0.3
Eg = 2.3
sim_properties = (20, 0.2, Eg, (Pl, Pt))
qdcb1 = qbd.qd_results(size, 0.85, me, me, "CB1")
qdcb2 = qbd.qd_results(size, 0.85, me, me, "CB2")
qdvb1 = qbd.qd_results(size, 0.85, mh, mh, "VB1")
qdvb2 = qbd.qd_results(size, 0.85, mh, mh, "VB2")
188/11:
# List a few energy levels
gs = (0, 0)
e1 = (0, 1)
e2 = (0, 2)
e3 = (0, 3)
e4 = (1, 0)
188/12: ab.envolute_matrix_element(qdcb1, gs, qdvb1, gs, sim_properties)
188/13: ab.envolute_matrix_element(qdcb1, (0, 0), qdvb1, (0, 0), sim_properties)
188/14:
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
size = 0.3
Eg = 2.3
sim_properties = (20, 0.2, Eg, (Pl, Pt))
qdcb1 = qbd.qd_results(size, 0.85, me, me, "CB1")
qdcb2 = qbd.qd_results(size, 0.85, me, me, "CB2")
qdvb1 = qbd.qd_results(size, 0.85, mh, mh, "VB1")
qdvb2 = qbd.qd_results(size, 0.85, mh, mh, "VB2")
print(qdcb1.e_levels)
print(qdcb2.e_levels)
print(qdvb1.e_levels)
print(qdvb2.e_levels)
188/15:
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
size = 3
Eg = 2.3
sim_properties = (20, 0.2, Eg, (Pl, Pt))
qdcb1 = qbd.qd_results(size, 0.85, me, me, "CB1")
qdcb2 = qbd.qd_results(size, 0.85, me, me, "CB2")
qdvb1 = qbd.qd_results(size, 0.85, mh, mh, "VB1")
qdvb2 = qbd.qd_results(size, 0.85, mh, mh, "VB2")
print(qdcb1.e_levels)
print(qdcb2.e_levels)
print(qdvb1.e_levels)
print(qdvb2.e_levels)
188/16:
# List a few energy levels
gs = (0, 0)
e1 = (0, 1)
e2 = (0, 2)
e3 = (0, 3)
e4 = (1, 0)
188/17: ab.envolute_matrix_element(qdcb1, (0, 0), qdvb1, (0, 0), sim_properties)
188/18:
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
size = 3
Eg = 2.3
sim_properties = (15, 0.2, Eg, (Pl, Pt))
qdcb1 = qbd.qd_results(size, 0.85, me, me, "CB1")
qdcb2 = qbd.qd_results(size, 0.85, me, me, "CB2")
qdvb1 = qbd.qd_results(size, 0.85, mh, mh, "VB1")
qdvb2 = qbd.qd_results(size, 0.85, mh, mh, "VB2")
print(qdcb1.e_levels)
print(qdcb2.e_levels)
print(qdvb1.e_levels)
print(qdvb2.e_levels)
188/19:
# List a few energy levels
gs = (0, 0)
e1 = (0, 1)
e2 = (0, 2)
e3 = (0, 3)
e4 = (1, 0)
188/20: ab.envolute_matrix_element(qdcb1, (0, 0), qdvb1, (0, 0), sim_properties)
188/21:
ab.envolute_matrix_element(qdcb1, (0, 0), qdvb1, (0, 0), sim_properties)
ab.envolute_matrix_element(qdcb1, (0, 0), qdvb2, (0, 0), sim_properties)
ab.envolute_matrix_element(qdcb2, (0, 0), qdvb1, (0, 0), sim_properties)
ab.envolute_matrix_element(qdcb2, (0, 0), qdvb2, (0, 0), sim_properties)
188/22:
dummy = ab.envolute_matrix_element(qdcb1, (0, 0), qdvb1, (0, 0), sim_properties)
print("CB1 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb1, (0, 0), qdvb2, (0, 0), sim_properties)
print("CB1 → VB2: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, (0, 0), qdvb1, (0, 0), sim_properties)
print("CB2 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, (0, 0), qdvb2, (0, 0), sim_properties)
print("CB2 → VB2: ", dummy)
188/23:
dummy = ab.envolute_matrix_element(qdcb1, (0, 0), qdvb1, (0, 0), sim_properties)
print("CB1 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb1, (0, 1), qdvb2, (0, 1), sim_properties)
print("CB1 → VB2: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, (0, 0), qdvb1, (0, 0), sim_properties)
print("CB2 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, (0, 0), qdvb2, (0, 0), sim_properties)
print("CB2 → VB2: ", dummy)
188/24:
energy_level = (0, 1)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb1, energy_level, sim_properties)
print("CB1 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb2, energy_level, sim_properties)
print("CB1 → VB2: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb1, energy_level, sim_properties)
print("CB2 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb2, energy_level, sim_properties)
print("CB2 → VB2: ", dummy)
188/25:
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
size = 3
Eg = 2.3
sim_properties = (10, 0.2, Eg, (Pl, Pt))
qdcb1 = qbd.qd_results(size, 0.85, me, me, "CB1")
qdcb2 = qbd.qd_results(size, 0.85, me, me, "CB2")
qdvb1 = qbd.qd_results(size, 0.85, mh, mh, "VB1")
qdvb2 = qbd.qd_results(size, 0.85, mh, mh, "VB2")
print(qdcb1.e_levels)
print(qdcb2.e_levels)
print(qdvb1.e_levels)
print(qdvb2.e_levels)
188/26:
energy_level = (0, 0)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb1, energy_level, sim_properties)
print("CB1 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb2, energy_level, sim_properties)
print("CB1 → VB2: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb1, energy_level, sim_properties)
print("CB2 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb2, energy_level, sim_properties)
print("CB2 → VB2: ", dummy)
188/27:
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
size = 4
Eg = 2.3
sim_properties = (10, 0.2, Eg, (Pl, Pt))
qdcb1 = qbd.qd_results(size, 0.85, me, me, "CB1")
qdcb2 = qbd.qd_results(size, 0.85, me, me, "CB2")
qdvb1 = qbd.qd_results(size, 0.85, mh, mh, "VB1")
qdvb2 = qbd.qd_results(size, 0.85, mh, mh, "VB2")
print(qdcb1.e_levels)
print(qdcb2.e_levels)
print(qdvb1.e_levels)
print(qdvb2.e_levels)
188/28:
energy_level = (0, 0)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb1, energy_level, sim_properties)
print("CB1 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb2, energy_level, sim_properties)
print("CB1 → VB2: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb1, energy_level, sim_properties)
print("CB2 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb2, energy_level, sim_properties)
print("CB2 → VB2: ", dummy)
188/29:
energy_level = (0, 1)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb1, energy_level, sim_properties)
print("CB1 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb2, energy_level, sim_properties)
print("CB1 → VB2: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb1, energy_level, sim_properties)
print("CB2 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb2, energy_level, sim_properties)
print("CB2 → VB2: ", dummy)
188/30:
energy_level = (1, 0)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb1, energy_level, sim_properties)
print("CB1 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb2, energy_level, sim_properties)
print("CB1 → VB2: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb1, energy_level, sim_properties)
print("CB2 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb2, energy_level, sim_properties)
print("CB2 → VB2: ", dummy)
188/31:
energy_level = (0, 2)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb1, energy_level, sim_properties)
print("CB1 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb2, energy_level, sim_properties)
print("CB1 → VB2: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb1, energy_level, sim_properties)
print("CB2 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb2, energy_level, sim_properties)
print("CB2 → VB2: ", dummy)
188/32:
energy_level = (0, 0)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb1, energy_level, sim_properties)
print("CB1 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb1, energy_level, qdvb2, energy_level, sim_properties)
print("CB1 → VB2: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb1, energy_level, sim_properties)
print("CB2 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, energy_level, qdvb2, energy_level, sim_properties)
print("CB2 → VB2: ", dummy)
188/33:
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
size = 4
Eg = 2.3
sim_properties = (10, 0.15, Eg, (Pl, Pt))
qdcb1 = qbd.qd_results(size, 0.85, me, me, "CB1")
qdcb2 = qbd.qd_results(size, 0.85, me, me, "CB2")
qdvb1 = qbd.qd_results(size, 0.85, mh, mh, "VB1")
qdvb2 = qbd.qd_results(size, 0.85, mh, mh, "VB2")
print(qdcb1.e_levels)
print(qdcb2.e_levels)
print(qdvb1.e_levels)
print(qdvb2.e_levels)
188/34:
e_i = (0, 0)
e_f = (0, 0)
dummy = ab.envolute_matrix_element(qdcb1, e_i, qdvb1, e_f, sim_properties)
print("CB1 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb1, e_i, qdvb2, e_f, sim_properties)
print("CB1 → VB2: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, e_i, qdvb1, e_f, sim_properties)
print("CB2 → VB1: ", dummy)
dummy = ab.envolute_matrix_element(qdcb2, e_i, qdvb2, e_f, sim_properties)
print("CB2 → VB2: ", dummy)
190/1: import numpy as np
191/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
191/2:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
191/3: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
191/4: qd_wavefunction.e_levels
191/5:
qd1 = qbd.qd_results(4, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(4, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.4, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
nenergy = np.linspace(0, 2.5, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
191/6:
qd1 = qbd.qd_results(4, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(4, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.4, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
energy = np.linspace(0, 2.5, 300)
absorption = np.zeros_like(energy)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
191/7:
qd1 = qbd.qd_results(4, 1.2, 0.08, 0.08, "CB1")
qd2 = qbd.qd_results(4, 0.7, 0.08, 0.08, "VB1")
sim_properties = (20, 0.4, 2.3, (2e-25, 1e-25))
print(qd1.e_levels)
print(qd2.e_levels)
energy = np.linspace(0, 2.5, 300)
absorption = np.zeros_like(energy)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
for transition in transitions:
    t_energy = transition[0]
    matrix_element = transition[1][2]
    absorption += ab.absorption_ij(energy, t_energy, matrix_element, gauss_dispersion=0.05)
    
plt.plot(energy, absorption)
191/8:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
191/9:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.1, 3, 10)

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, "CB1")
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
192/2:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.5, 3, 10)

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, "CB1")
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/3: m_values
192/4: Mx = [m_value[0][1][2] for m_value in m_values]
192/5: m_value
192/6: m_values
192/7: m_values[0]
192/8:
for m_value in m_values:
    print(m_value)
192/9:
for m_value in m_values:
    print(m_value[0])
192/10:
for m_value in m_values:
    print(m_value)
192/11:
for m_value in m_values:
    print(m_value[1])
192/12: exec_time = [m_value[1] for m_value in m_values]
192/13:
for m_value in m_values:
    print(m_value[0])
192/14:
for m_value in m_values:
    print(m_value[0][0])
192/15:
for m_value in m_values:
    print(m_value[0][0][0])
192/16:
for m_value in m_values:
    print(m_value[0][0][1])
192/17:
for m_value in m_values:
    print(m_value[0][0][1][2])
192/18:
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
192/19:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.5, 3, 10)

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, "CB1")
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))

# Get all the M values for the first transition
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
plt.plot(lat_size, Mx, lat_size, My, lat_size, Mz)
plt.plot(lat_size, exec_time)
192/20:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.5, 3, 10)

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, "CB1")
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))

# Get all the M values for the first transition
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2)
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
192/21:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.5, 3, 10)

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, "CB1")
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))

# Get all the M values for the first transition
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2)
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
192/22:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.5, 3, 10)

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, "CB1")
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))

# Get all the M values for the first transition
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(1, 2))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
192/23:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.5, 3, 10)

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, "CB1")
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/24:
# Get all the M values for the first transition
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2)
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
192/25:
# Get all the M values for the first transition
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(1, 3))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
192/26:
# Get all the M values for the first transition
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(3, 1))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
192/27:
# Get all the M values for the first transition
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(7, 7))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
192/28:
# Get all the M values for the first transition
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(6, 10))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
192/29:
# Get all the M values for the first transition
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
192/30: np.concatenate((lat_size, Mx))
192/31: np.concatenate((lat_size, Mx), axis=-1)
192/32: np.concatenate((lat_size, Mx), axis=0)
192/33: np.concatenate((lat_size, Mx), axis=1)
192/34: lat_size.shape
192/35: Mx.shape
192/36: np.concatenate((lat_size[:, np.newaxis], Mx[:, np.newaxis]), axis=1)
192/37: np.concatenate((lat_size[:, np.newaxis], Mx[:, np.newaxis], My[:np.newaxis]), axis=1)
192/38: np.concatenate((lat_size[:, np.newaxis], Mx[:, np.newaxis], My[:,np.newaxis]), axis=1)
192/39:
# Get all the M values for the first transition
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}.txt", mx_export)
192/40:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.5, 3, 10)
band_i = "CB1"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/41:
# Get all the M values for the first transition
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}.txt", mx_export)
192/42:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.1, 3, 50)
band_i = "CB1"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/43:
# Get all the M values for the first transition
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][0][1][0] for m_value in m_values])
My = np.array([m_value[0][0][1][1] for m_value in m_values])
Mz = np.array([m_value[0][0][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}.txt", mx_export)
192/44:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.5, 3, 50)
band_i = "CB1"
band_f = "VB2"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/45:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/46:
# Get all the M values for the first transition
transition = 1
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/47:
# Get all the M values for the first transition
transition = 2
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/48:
# Get all the M values for the first transition
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/49:
# Get all the M values for the first transition
transition = 4
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/50:
# Get all the M values for the first transition
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/51:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.6, 4, 50)
band_i = "CB1"
band_f = "VB2"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/52:
# Get all the M values for the first transition
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/53:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.6, 4, 100)
band_i = "CB1"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/54:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/55:
# Get all the M values for the first transition
transition = 1
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/56:
# Get all the M values for the first transition
transition = 2
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/57:
# Get all the M values for the first transition
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/58:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.6, 4, 100)
band_i = "CB1"
band_f = "VB2"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/59:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/60:
# Get all the M values for the first transition
transition = 1
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/61:
# Get all the M values for the first transition
transition = 2
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/62:
# Get all the M values for the first transition
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/63:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.6, 4, 100)
band_i = "CB2"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/64:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/65:
# Get all the M values for the first transition
transition = 1
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/66:
# Get all the M values for the first transition
transition = 2
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/67:
# Get all the M values for the first transition
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/68:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 20
lat_size = np.linspace(0.6, 4, 100)
band_i = "CB2"
band_f = "VB2"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/69:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/70:
# Get all the M values for the first transition
transition = 1
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/71:
# Get all the M values for the first transition
transition = 2
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/72:
# Get all the M values for the first transition
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/73:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = np.linspace(10, 30, 100)
lat_size = 0.6
band_i = "CB1"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for sim_size_i in sim_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/74:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/75:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/76:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/77:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/78:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/79:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/80:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = np.linspace(10, 30, 100)
lat_size = 0.6
band_i = "CB1"
band_f = "VB2"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for sim_size_i in sim_size:
    print("Running for Simulation size: ", sim_size_i)
    sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/81:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/82:
# Get all the M values for the first transition
transition = 1
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/83:
# Get all the M values for the first transition
transition = 2
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/84:
# Get all the M values for the first transition
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/85:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = np.linspace(10, 30, 100)
lat_size = 0.6
band_i = "CB2"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for sim_size_i in sim_size:
    print("Running for Simulation size: ", sim_size_i)
    sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/86:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/87:
# Get all the M values for the first transition
transition = 1
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/88:
# Get all the M values for the first transition
transition = 2
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/89:
# Get all the M values for the first transition
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/90:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = np.linspace(10, 30, 100)
lat_size = 0.6
band_i = "CB2"
band_f = "VB2"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for sim_size_i in sim_size:
    print("Running for Simulation size: ", sim_size_i)
    sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/91:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/92:
# Get all the M values for the first transition
transition = 1
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/93:
# Get all the M values for the first transition
transition = 2
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/94:
# Get all the M values for the first transition
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/95:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = np.linspace(10, 30, 100)
lat_size = 0.6
band_i = "CB1"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for sim_size_i in sim_size:
    print("Running for Simulation size: ", sim_size_i)
    sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
192/96:
# Get all the M values for the first transition
transition = 0
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/97:
# Get all the M values for the first transition
transition = 1
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/98:
# Get all the M values for the first transition
transition = 2
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/99:
# Get all the M values for the first transition
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(sim_size, Mx, sim_size, My, sim_size, Mz)
ax[0].set(title="Simulation vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Simulation Size (nm)")
ax[1].plot(sim_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Simulation Size (nm)")
mx_export = np.concatenate((sim_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
np.savetxt(f"Sim_size_M_exec_time_LatSize_{lat_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
192/100:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.01, 0.1, 50)
band_i = "CB1"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
194/1:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.02, 0.1, 50)
band_i = "CB1"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
194/2:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
194/3:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.03, 0.1, 50)
band_i = "CB1"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
195/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
196/1: import numpy
197/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
197/2:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.03, 0.1, 100)
band_i = "CB1"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
197/3:
# Export all the data to file
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")

# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
res_df = pd.DataFrame(Results)
res_df.to_csv(f"Lat_size_M_exec_time_SSize_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn_{transition}.csv",
             sep=" ", index=False)
# mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
# np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
197/4:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.03, 0.5, 100)
band_i = "CB1"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
197/5:
# Export all the data to file
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")

# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
res_df = pd.DataFrame(Results)
res_df.to_csv(f"Lat_size_M_exec_time_SSize_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn_{transition}.csv",
             sep=" ", index=False)
# mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
# np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
197/6:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.1, 0.8, 100)
band_i = "CB1"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
197/7:
# Export all the data to file
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")

# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
res_df = pd.DataFrame(Results)
res_df.to_csv(f"Lat_size_M_exec_time_SSize_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn_{transition}.csv",
             sep=" ", index=False)
# mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
# np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
197/8:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.3, 1.2, 100)
band_i = "CB1"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
197/9:
# Export all the data to file
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")

# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
res_df = pd.DataFrame(Results)
res_df.to_csv(f"Lat_size_M_exec_time_SSize_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn_{transition}.csv",
             sep=" ", index=False)
# mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
# np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
197/10:
# Define the constant variables
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

# Transitions from CB1 to VB1
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

m_values = []

# Cicle through all the lattice size values
for lat_size_i in lat_size:
    print("Running for Lattice size: ", lat_size_i)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
197/11:
# Export all the data to file
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")

# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
res_df = pd.DataFrame(Results)
res_df.to_csv(f"Lat_size_M_exec_time_SSize_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn_{transition}.csv",
             sep=" ", index=False)
# mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
# np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
197/12:
# Export all the data to file
transition = 3
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].plot(lat_size, Mx, lat_size, My, lat_size, Mz)
ax[0].set(title="Lattice vs Mx/My/Mz")
ax[0].set_ylabel("Mx/My/Mz (1/nm)")
ax[0].set_xlabel("Lattice Size (nm)")
ax[1].plot(lat_size, exec_time)
ax[1].set(title="Exec Time vs Lattice")
ax[1].set_ylabel("Exec Time (s)")
ax[1].set_xlabel("Lattice Size (nm)")

# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
res_df = pd.DataFrame(Results)
res_df.to_csv(f"Lat_size_M_exec_time_SSize_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn_{transition}.csv",
             sep=" ", index=False)
# mx_export = np.concatenate((lat_size[:, np.newaxis], exec_time[:, np.newaxis], Mx[:, np.newaxis], My[:, np.newaxis], Mz[:, np.newaxis]), axis=1)
# np.savetxt(f"Lat_size_M_exec_time_SimSize_{sim_size}_QDsize_{qd_size}_{band_i}_{band_f}_transition_{transition}.txt", mx_export)
198/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
198/2: product(np.linspace(0, 10, 10), np.linspace(10, 11, 10))
198/3: list(product(np.linspace(0, 10, 10), np.linspace(10, 11, 10)))
198/4:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 2)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 2)
band_i = "CB1"
band_f = "VB1"

# Cicle through all the lattice size values
for lat_size_i, me in product(lat_size, me_array):
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    # Show the current step
    print("\rRunning for Lattice size: ", lat_size_i. " and param: ", me, end="")
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])

    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_me_{me}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
198/5:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 2)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 2)
band_i = "CB1"
band_f = "VB1"

# Cicle through all the lattice size values
for lat_size_i, me in product(lat_size, me_array):
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    # Show the current step
    print("\rRunning for Lattice size: ", lat_size_i, " and param: ", me, end="")
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])

    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_me_{me}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
199/2:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 2)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 2)
band_i = "CB1"
band_f = "VB1"

# Cicle through all the lattice size values
for lat_size_i, me in product(lat_size, me_array):
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    # Show the current step
    print("\rRunning for Lattice size: ", lat_size_i, " and param: ", me, end="")
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])

    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_me_{me}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/3:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 2)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 2)
band_i = "CB1"
band_f = "VB1"

# Cicle through all the lattice size values
for lat_size_i, me in product(lat_size, me_array):
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    # Show the current step
    print("\rRunning for Lattice size: ", lat_size_i, " and param: ", me, end="")
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    print(lat_size, exec_time, Mx, My, Mz)
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_me_{me}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/4:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
%matplotlib inline
199/5:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 2)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 2)
band_i = "CB1"
band_f = "VB1"

total_runs = len(product(lat_size, me_array))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    run_i += 1
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    print(lat_size, exec_time, Mx, My, Mz)
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_me_{me}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/6:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 2)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 2)
band_i = "CB1"
band_f = "VB1"

total_runs = len(listproduct(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    run_i += 1
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    print(lat_size, exec_time, Mx, My, Mz)
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_me_{me}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/8:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 2)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 2)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    run_i += 1
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    print(lat_size, exec_time, Mx, My, Mz)
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_me_{me}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/9:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warning
%matplotlib inline
warning.filterwarnings()
199/10:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings()
199/11:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
199/12:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 2)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 2)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    run_i += 1
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_me_{me}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/13:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 2)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 2)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    run_i += 1
    # Show the current step
    print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_me_{me}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/14:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 2)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 2)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_me_{me}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/15:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 10)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    prop = "me_" + me
    print(prop)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_me_{me}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/16:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 10)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    prop = f"me_{me}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{prop}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/17:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
199/18:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 10)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    prop = f"me_{me:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{prop}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/19:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = 0.08
mh = np.linspace(0.05, 0.15, 10)
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    prop = f"me_{me:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{prop}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/20:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh_array = np.linspace(0.05, 0.15, 10)
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for mh in mh_array:
    prop = f"mh_{mh:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{prop}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/21:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh_array = np.linspace(0.05, 0.15, 10)
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for mh in mh_array:
    prop = f"mh_{mh:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{prop}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/22:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt_array = np.linspace(2.5e-25, 7e-25, 10)
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for Pt in Pt_array:
    prop = f"Pt_{Pt:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{prop}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/23:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt_array = np.linspace(2.5e-25, 7e-25, 10)
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for Pt in Pt_array:
    prop = f"Pt_{Pt:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{prop}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
200/1: !ls
199/24:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl_array = np.linspace(2.5e-25, 7e-25, 10)
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for Pl in Pl_array:
    prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{prop}_{sim_size}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/25:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = np.linspace(3, 6, 10)
qd_size_array = np.linspace(2.5e-25, 7e-25, 10)
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for qd_size in qd_size_array:
    prop = f""
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{prop}_{sim_size}_QSize_{qd_size:.2f}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/26:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size_array = np.linspace(2.5e-25, 7e-25, 10)
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for qd_size in qd_size_array:
    prop = f""
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{prop}_{sim_size}_QSize_{qd_size:.2f}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/27:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size_array = np.linspace(3, 6, 10)
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for qd_size in qd_size_array:
    prop = f""
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{prop}_{sim_size}_QSize_{qd_size:.2f}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/28:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size_array = np.linspace(5, 30, 10)
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for sim_size in sim_size_array:
    prop = f""
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size:.2f}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/29:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
199/30:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size_array = np.linspace(5, 30, 10)
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for sim_size in sim_size_array:
    prop = f""
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size:.2f}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/31:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = np.linspace(0.4, 2, 10)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for m_e in me_array:
    prop = f"me_{me:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/32:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.4, 2, 10)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for m_e in me_array:
    prop = f"me_{me:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/33:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.4, 2, 10)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for m_e in me_array:
    prop = f"me_{m_e:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/34:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.4, 2, 10)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    prop = f"me_{m_e:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/35:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
199/36:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.4, 2, 10)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    prop = f"me_{m_e:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/37:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
199/38:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 10)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    prop = f"me_{m_e:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/39:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh_array = np.linspace(0.05, 0.15, 10)
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for mh in mh_array:
    prop = f"mh_{m_e:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/40:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
199/41:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh_array = np.linspace(0.05, 0.15, 10)
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for mh in mh_array:
    prop = f"mh_{mh:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/42:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = np.linspace(0.05, 0.15, 10)
mh_array = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    prop = f"me_{me:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/43:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 10)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, mh_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    prop = f"me_{me:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/44:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 10)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    prop = f"me_{me:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/45:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt_array = np.linspace(2.5e-25, 7e-25, 10)
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for Py in Pt_array:
    prop = f"Pt_{Pt:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/46:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl_array = np.linspace(2.5e-25, 7e-25, 10)
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for Pl in Pl_array:
    prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/47:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size_array = np.linspace(3, 6, 10)
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for qd_size in qd_size_array:
    prop = f""
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size:.2f}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/48:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt_array = np.linspace(2.5e-25, 7e-25, 10)
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for Pt in Pt_array:
    prop = f"Pt_{Pt:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/49:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size_array = np.linspace(10, 30, 10)
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB2"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for sim_size in sim_size_array:
    prop = f""
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size:.2f}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/50:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size_array = np.linspace(10, 30, 10)
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for sim_size in sim_size_array:
    prop = f""
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 1
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size:.2f}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/51:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size_array = np.linspace(3, 6, 10)
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for qd_size in qd_size_array:
    prop = f""
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 1
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size:.2f}_{band_i}_{band_f}_trn0.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/52:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.5, 0.15, 10)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    prop = f"me_{me:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 1
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/53:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me_array = np.linspace(0.05, 0.15, 10)
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for me in me_array:
    prop = f"me_{me:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 1
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/54:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh_array = np.linspace(0.05, 0.15, 10)
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for mh in mh_array:
    prop = f"mh_{mh:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 1
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/55:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt_array = np.linspace(2.5e-25, 7e-25, 10)
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for Pt in Pt_array:
    prop = f"Pt_{Pt:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 1
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/56:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt_array = 4.7e-25
Pl = np.linspace(2.5e-25, 7e-25, 10)
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for Pl in Pl_array:
    prop = f"Pl_{Pl:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 1
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/57:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl_array = np.linspace(2.5e-25, 7e-25, 10)
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for Pl in Pl_array:
    prop = f"Pl_{Pl:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 1
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/58:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt_array = np.linspace(2.5e-25, 7e-25, 10)
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for Pt in Pt_array:
    prop = f"Pt_{Pt:.2f}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 1
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/59:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt_array = np.linspace(2.5e-25, 7e-25, 10)
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for Pt in Pt_array:
    prop = f"Pt_{Pt:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 1
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/60:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = np.linspace(2.5e-25, 7e-25, 10)
Pl_array = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for Pl in Pl_array:
    prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 1
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/61:
# Define the constant variables
# Default values
# me_array = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.95
# Vvb = 0.95
# sim_size = 10
# lat_size = np.linspace(0.4, 2, 2)
# band_i = "CB1"
# band_f = "VB1"

me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl_array = np.linspace(2.5e-25, 7e-25, 10)
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = 10
lat_size = np.linspace(0.4, 2, 100)
band_i = "CB1"
band_f = "VB1"

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

# Cicle through all the lattice size values
for Pl in Pl_array:
    prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for lat_size_i in lat_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 1
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Lat_Size": lat_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/62:
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl_array = np.linspace(2.5e-25, 7e-25, 10)
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = np.linspace(10, 30, 100)
lat_size = 0.8
band_i = "CB1"
band_f = "VB1"

total_runs = 10*100
run_i = 0

# Cicle through all the lattice size values
for Pl in Pl_array:
    prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for sim_size_i in sim_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Sim_size": sim_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_SSize_time_LSize_{lat_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/63:
me = 0.08
mh = 0.08
Pt_array = np.linspace(2.5e-25, 7e-25, 10)
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.95
Vvb = 0.95
sim_size = np.linspace(10, 30, 100)
lat_size = 0.8
band_i = "CB1"
band_f = "VB1"

total_runs = 10*100
run_i = 0

# Cicle through all the lattice size values
for Pt in Pt_array:
    prop = f"Pt_{Pt:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)

    m_values = []
    
    for sim_size_i in sim_size:
        run_i += 1
        # Show the current step
        print(f"\rRun {run_i:04d}/{total_runs:04d}", end="")
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
    # Export all the data to file
    transition = 0
    exec_time = np.array([m_value[1] for m_value in m_values])
    Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
    My = np.array([m_value[0][transition][1][1] for m_value in m_values])
    Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
    # Export the results using a DataFrame
    Results = {
        "Sim_size": sim_size,
        "Exec_Time": exec_time,
        "Mx": Mx,
        "My": My,
        "Mz": Mz
    }
    filename=f"Article_2_Results/M_SSize_time_LSize_{lat_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
    res_df = pd.DataFrame(Results)
    res_df.to_csv(filename, sep=" ", index=False)
199/64:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB"
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
201/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
201/2:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB"
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band)
201/3:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band)
201/4:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(3, Vcb, me, me, band)
201/5:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(3, Vcb, me, me, band)
qd1.e_levels
201/6:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(3, Vcb, me, me, band)
qd1.e_levels.non_null
201/7:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(3, Vcb, me, me, band)
qd1.e_levels.notnull()
201/8:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(7, Vcb, me, me, band)
qd1.e_levels.notnull()
201/9:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(7, Vcb, me, me, band)
qd1.e_levels.notnull().shape
201/10:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(7, Vcb, me, me, band)
qd1.e_levels.notnull().sum
201/11:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(7, Vcb, me, me, band)
qd1.e_levels.notnull().sum()
201/12:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(7, Vcb, me, me, band)
print(qd1.e_levels)
qd1.e_levels.notnull().sum().sum()
201/13:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(7, Vcb, me, me, band)
print(qd1.e_levels)
qd1.e_levels.values().isnan().sum()
201/14:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(7, Vcb, me, me, band)
print(qd1.e_levels)
qd1.e_levels.values.isnan().sum()
201/15:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(7, Vcb, me, me, band)
print(qd1.e_levels)
np.isnan(qd1.e_levels.values).sum()
201/16:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(7, Vcb, me, me, band)
print(qd1.e_levels)
np.isnan(qd1.e_levels.values)
201/17:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(7, Vcb, me, me, band)
print(qd1.e_levels)
np.isfinite(qd1.e_levels.values)
201/18:
me = 0.08
qd_size = np.linspace(0.5, 5, 100)
Vcb = 0.4
band = "CB1"
qd1 = qbd.qd_results(7, Vcb, me, me, band)
print(qd1.e_levels)
np.isfinite(qd1.e_levels.values).sum()
201/19:
def update_step(it_num, total_it):
    """Helper function to update the iterations in a function"""
    print(f"Iteration {it:04d}/{n:04d}\r")
    pass
201/20:
# Define the constant variables
# Default values
n = 100
me = 0.08
qd_size = np.linspace(0.5, 5, n)
Vcb = 0.4
band = "CB1"
it = 0
n_levels = list()
for qd_size_i in qd_size:
    it += 1
    update_step(it, n)
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

export_file = "QSize_NLevels_CB1.csv"
export_data = {
    "QSize": qd_size,
    "NLevels": np.array(n_levels)
}
pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
201/21:
# Define the constant variables
# Default values
n = 100
me = 0.08
qd_size = np.linspace(0.5, 5, n)
Vcb = 0.4
band = "CB1"
it = 0
n_levels = list()

for qd_size_i in qd_size:
    it += 1
    update_step(it, n)
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

export_file = "QSize_NLevels_CB1.csv"
export_data = {
    "QSize": qd_size,
    "NLevels": np.array(n_levels)
}
pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
201/22:
# Define the constant variables
# Default values
n = 100
me = 0.08
qd_size = np.linspace(0.5, 5, n)
Vcb = 0.4
band = "CB1"
it = 0
n_levels = list()

for qd_size_i in qd_size:
    it += 1
    update_step(it, n)
    qd1 = qbd.qd_results(qd_size_i, Vcb, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

export_file = "QSize_NLevels_CB1.csv"
export_data = {
    "QSize": qd_size,
    "NLevels": np.array(n_levels)
}
pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
201/23:
def update_step(it_num, total_it):
    """Helper function to update the iterations in a function"""
    print(f"\rIteration {it:04d}/{n:04d}")
    pass
201/24:
# Define the constant variables
# Default values
n = 100
me = 0.08
qd_size = np.linspace(0.5, 5, n)
Vcb = 0.4
band = "CB1"
it = 0
n_levels = list()

for qd_size_i in qd_size:
    it += 1
    update_step(it, n)
    qd1 = qbd.qd_results(qd_size_i, Vcb, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

export_file = "QSize_NLevels_CB1.csv"
export_data = {
    "QSize": qd_size,
    "NLevels": np.array(n_levels)
}
pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
201/25:
def update_step(it_num, total_it):
    """Helper function to update the iterations in a function"""
    print(f"\rIteration {it:04d}/{n:04d}", end="")
    pass
201/26:
# Define the constant variables
# Default values
n = 100
me = 0.08
qd_size = np.linspace(0.5, 5, n)
Vcb = 0.4
band = "CB1"
it = 0
n_levels = list()

for qd_size_i in qd_size:
    it += 1
    update_step(it, n)
    qd1 = qbd.qd_results(qd_size_i, Vcb, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

export_file = "QSize_NLevels_CB1.csv"
export_data = {
    "QSize": qd_size,
    "NLevels": np.array(n_levels)
}
pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
201/27:
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    print(f"\rIteration {it:04d}/{n:04d}", end="")
    pass
202/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
202/2:
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    print(f"\rIteration {it:04d}/{n:04d}", end="")
    pass
202/3:
# Define the constant variables
# Default values
n = 1000
me = 0.08
qd_size = np.linspace(0.5, 10, n)
Vcb = 0.4
band = "CB1"
it = 0
n_levels = list()

for qd_size_i in qd_size:
    it += 1
    update_step(it, n)
    qd1 = qbd.qd_results(qd_size_i, Vcb, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

export_file = "QSize_NLevels_CB1.csv"
export_data = {
    "QSize": qd_size,
    "NLevels": np.array(n_levels)
}
pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
202/4:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    print(f"\rIteration {it:04d}/{n:04d}", end="")
    pass
202/5:
# Define the constant variables
# Default values
n = 1000
me = 0.08
qd_size = np.linspace(0.5, 10, n)
Vcb = 0.4
band = "CB1"
it = 0
n_levels = list()

for qd_size_i in qd_size:
    it += 1
    update_step(it, n)
    qd1 = qbd.qd_results(qd_size_i, Vcb, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

export_file = "{dir_prefix}/QSize_NLevels_CB1.csv"
export_data = {
    "QSize": qd_size,
    "NLevels": np.array(n_levels)
}
pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
202/6:
# Define the constant variables
# Default values
n = 1000
me = 0.08
qd_size = np.linspace(0.5, 10, n)
Vcb = 0.4
band = "CB1"
it = 0
n_levels = list()

for qd_size_i in qd_size:
    it += 1
    update_step(it, n)
    qd1 = qbd.qd_results(qd_size_i, Vcb, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

export_file = f"{dir_prefix}/QSize_NLevels_CB1.csv"
export_data = {
    "QSize": qd_size,
    "NLevels": np.array(n_levels)
}
pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
202/7:
n = 1000*2
me = 0.08
qd_size = np.linspace(0.5, 10, n)
Vcb = [0.4, 1.5]
band = "CB1"
it = 0
v_results=list()
for V in Vcb:
    n_levels = list()
    for qd_size_i in qd_size:
        it += 1
        update_step(it, n)
        qd1 = qbd.qd_results(qd_size_i, V, me, me, band)
        n_levels.append(np.isfinite(qd1.e_levels.values).sum())
    v_results.append(np.array(n_levels))

export_file = f"{dir_prefix}/QSize_NLevels_CB1.csv"
export_data = {
    "QSize": qd_size,
    "NLevels_04": v_results[0],
    "NLevels_15": v_results[1]
}
pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
203/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
203/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    print(f"\rIteration {it:04d}/{n:04d}", end="")
    pass
203/3:
n = 1000
qd_size = np.linspace(0.5, 10, n)
Vcb = [0.4, 1.5]
me = 0.08
band = "CB1"
it = 0
v_results=list()

for V in Vcb:
    n_levels = list()
    for qd_size_i in qd_size:
        it += 1
        update_step(it, 2*n)
        qd1 = qbd.qd_results(qd_size_i, V, me, me, band)
        n_levels.append(np.isfinite(qd1.e_levels.values).sum())
    v_results.append(np.array(n_levels))

export_file = f"{dir_prefix}/QSize_NLevels_CB1.csv"
export_data = {
    "QSize": qd_size,
    "NLevels_04": v_results[0],
    "NLevels_15": v_results[1]
}
pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
203/4:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
qd_size = np.linspace(0.5, 10, 1000)
Vcb = np.linspace(0.1, 2.3, 10)
me = 0.08
band = "CB1"
it = 0
v_results=list()

for V in Vcb:
    n_levels = list()
    for qd_size_i in qd_size:
        it += 1
        update_step(it, 10*1000)
        qd1 = qbd.qd_results(qd_size_i, V, me, me, band)
        n_levels.append(np.isfinite(qd1.e_levels.values).sum())
    v_results.append(np.array(n_levels))

export_file = f"{dir_prefix}/QSize_NLevels_CB1.csv"
export_data = {
    "QSize": qd_size
}
export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
203/5:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    print(f"\rIteration {it:04d}/{total_it:04d}", end="")
    pass
203/6:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
203/7:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
qd_size = np.linspace(0.5, 10, 1000)
Vcb = np.linspace(0.1, 2.3, 10)
me = 0.08
band = "CB1"
it = 0
v_results=list()

for qd_size_i, V_i in product(qd_size, Vcb):
    it += 1
    update_step(10*1000)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(1000, 10)
    

export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=qd_size, index=Vcb)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
203/8:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    print(f"\rIteration {it:04d}/{total_it:04d}", end="")
    pass
203/9:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
203/10:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
qd_size = np.linspace(0.5, 10, 1000)
Vcb = np.linspace(0.1, 2.3, 10)
me = 0.08
band = "CB1"
it = 0
v_results=list()

for qd_size_i, V_i in product(qd_size, Vcb):
    it += 1
    update_step(10*1000)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(1000, 10)
    

export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=qd_size, index=Vcb)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
203/11:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
qd_size = np.linspace(0.5, 10, 1000)
Vcb = np.linspace(0.1, 2.3, 10)
me = 0.08
band = "CB1"
it = 0
v_results=list()

for qd_size_i, V_i in product(qd_size, Vcb):
    it += 1
    update_step(it, 10*1000)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(1000, 10)
    

export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=qd_size, index=Vcb)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
204/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
204/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
204/3:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
qd_size = np.linspace(0.5, 10, 10)
me = 0.08
band = "CB1"
it = 0
v_results=list()

for qd_size_i, V_i in product(qd_size, Vcb):
    it += 1
    update_step(it, 10*1000)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(1000, 10)
    

export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=qd_size, index=Vcb)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
204/4:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
qd_size = np.linspace(0.5, 10, 10)
Vcb = np.linspace(0.1, 2.3, 1)
me = 0.08
band = "CB1"
it = 0

for qd_size_i, V_i in product(qd_size, Vcb):
    it += 1
    update_step(it, 10*1000)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(1000, 10)
    

export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=qd_size, index=Vcb)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
204/5:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
qd_size = np.linspace(0.5, 10, 10)
Vcb = np.linspace(0.1, 2.3, 2)
me = 0.08
band = "CB1"
it = 0
n_levels = list()
for qd_size_i, V_i in product(qd_size, Vcb):
    it += 1
    update_step(it, 10*1000)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(10, 2)
    

export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=qd_size, index=Vcb)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
204/6:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
qd_size = np.linspace(0.5, 10, 10)
Vcb = np.linspace(0.1, 2.3, 2)
me = 0.08
band = "CB1"
it = 0
n_levels = list()
for qd_size_i, V_i in product(qd_size, Vcb):
    it += 1
    update_step(it, 10*1000)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(10, 2)
print(n_levels)

export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=qd_size, index=Vcb)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
204/7:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
qd_size = np.linspace(0.5, 10, 10)
Vcb = np.linspace(0.1, 2.3, 2)
me = 0.08
band = "CB1"
it = 0
n_levels = list()
for qd_size_i, V_i in product(qd_size, Vcb):
    print(qd_size_i, V_i)
    it += 1
    update_step(it, 10*1000)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(10, 2)
print(n_levels)

export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=qd_size, index=Vcb)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
204/8:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
qd_size = np.linspace(0.5, 10, 10)
Vcb = np.linspace(0.1, 2.3, 2)
me = 0.08
band = "CB1"
it = 0
n_levels = list()
for qd_size_i, V_i in product(qd_size, Vcb):
    print(qd_size_i, V_i)
    it += 1
    update_step(it, 10*1000)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(2, 10)
print(n_levels)

export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=qd_size, index=Vcb)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
204/9:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
qd_size = np.linspace(0.5, 10, 10)
Vcb = np.linspace(0.1, 2.3, 2)
me = 0.08
band = "CB1"
it = 0
n_levels = list()
for qd_size_i, V_i in product(qd_size, Vcb):
    print(qd_size_i, V_i)
    it += 1
    # update_step(it, 10*1000)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())
    print(n_levels)

n_levels = np.array(n_levels).reshape(2, 10)

export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=qd_size, index=Vcb)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
204/10:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
qd_size = np.linspace(0.5, 10, 10)
Vcb = np.linspace(0.1, 2.3, 2)
me = 0.08
band = "CB1"
it = 0
n_levels = list()
for qd_size_i, V_i in product(qd_size, Vcb):
    print(qd_size_i, V_i)
    it += 1
    # update_step(it, 10*1000)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())
    print(n_levels)

n_levels = np.array(n_levels).reshape(2, 10)
print(n_levels)
export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=qd_size, index=Vcb)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
204/11:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
qd_size = np.linspace(0.5, 10, 10)
Vcb = np.linspace(0.1, 2.3, 2)
me = 0.08
band = "CB1"
it = 0
n_levels = list()
for qd_size_i, V_i in product(qd_size, Vcb):
    print(qd_size_i, V_i)
    it += 1
    # update_step(it, 10*1000)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())
    print(n_levels)

n_levels = np.array(n_levels).reshape(10, 2)
print(n_levels)
export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=qd_size, index=Vcb)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
204/12:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
n_size = 10
v_size = 10
qd_size = np.linspace(0.5, 10, n_size)
Vcb = np.linspace(0.1, 2.3, v_size)
me = 0.08
band = "CB1"
it = 0
n_levels = list()
for qd_size_i, V_i in product(qd_size, Vcb):
    it += 1
    update_step(it, n_size*v_size)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(n_size, v_size)
export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=Vcb, index=qd_size)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
204/13:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
n_size = 10
v_size = 10
qd_size = np.linspace(0.5, 10, n_size)
Vcb = np.linspace(0.1, 2.3, v_size)
me = 0.08
band = "CB1"
it = 0
n_levels = list()
for qd_size_i, V_i in product(qd_size, Vcb):
    it += 1
    update_step(it, n_size*v_size)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(n_size, v_size)
export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=Vcb, index=qd_size)
print(df)
# export_data.update({f"PBarrier_{i}": data for i, data in enumerate(n_results)})
# pd.DataFrame(export_data).to_csv(export_file, sep=" ", index=False)
204/14:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
n_size = 10
v_size = 2
qd_size = np.linspace(0.5, 10, n_size)
Vcb = np.linspace(0.1, 2.3, v_size)
me = 0.08
band = "CB1"
it = 0
n_levels = list()
for qd_size_i, V_i in product(qd_size, Vcb):
    it += 1
    update_step(it, n_size*v_size)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(n_size, v_size)
export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=Vcb, index=qd_size).to_csv(export_file, sep=" ")
204/15:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
n_size = 10
v_size = 10
qd_size = np.linspace(0.5, 10, n_size)
Vcb = np.linspace(0.1, 2.3, v_size)
me = 0.08
band = "CB1"
it = 0
n_levels = list()
for qd_size_i, V_i in product(qd_size, Vcb):
    it += 1
    update_step(it, n_size*v_size)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(n_size, v_size)
export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=Vcb, index=qd_size).to_csv(export_file, sep=" ")
204/16:
# Calculate number of energy levels for different QD size
# and different potential Barriers
# This serves to define the default QDSize and the
# minimum potential barrier to be used later
n_size = 150
v_size = 150
qd_size = np.linspace(0.5, 10, n_size)
Vcb = np.linspace(0.1, 2.3, v_size)
me = 0.08
band = "CB1"
it = 0
n_levels = list()
for qd_size_i, V_i in product(qd_size, Vcb):
    it += 1
    update_step(it, n_size*v_size)
    qd1 = qbd.qd_results(qd_size_i, V_i, me, me, band)
    n_levels.append(np.isfinite(qd1.e_levels.values).sum())

n_levels = np.array(n_levels).reshape(n_size, v_size)
export_file = f"{dir_prefix}/QSize_PBarrier_NLevels_CB1.csv"
df = pd.DataFrame(n_levels, columns=Vcb, index=qd_size).to_csv(export_file, sep=" ")
204/17:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)

total_runs = len(list(product(lat_size, me_array)))
run_i = 0

for Pl, lat_size_i in product(np.linspace(1e-25,1e-24,n_param), lat_size):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
print(Results)
#     filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
#     res_df = pd.DataFrame(Results)
#     res_df.to_csv(filename, sep=" ", index=False)
204/18:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)

for Pl, lat_size_i in product(np.linspace(1e-25,1e-24,n_param), lat_size):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
print(Results)
#     filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
#     res_df = pd.DataFrame(Results)
#     res_df.to_csv(filename, sep=" ", index=False)
204/19:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)

run_i = 0
for Pl, lat_size_i in product(np.linspace(1e-25,1e-24,n_param), lat_size):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
print(Results)
#     filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
#     res_df = pd.DataFrame(Results)
#     res_df.to_csv(filename, sep=" ", index=False)
204/20:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)

run_i = 0
m_values = list()
for Pl, lat_size_i in product(np.linspace(1e-25,1e-24,n_param), lat_size):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
print(Results)
#     filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
#     res_df = pd.DataFrame(Results)
#     res_df.to_csv(filename, sep=" ", index=False)
204/21:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)

run_i = 0
m_values = list()
for Pl, lat_size_i in product(np.linspace(1e-25,1e-24,n_param), lat_size):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
print(Results)
#     filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
#     res_df = pd.DataFrame(Results)
#     res_df.to_csv(filename, sep=" ", index=False)
204/22:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)

run_i = 0
m_values = list()
for lat_size_i, Pl in product(lat_size, np.linspace(1e-25,1e-24,n_param)):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
print(Results)
#     filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
#     res_df = pd.DataFrame(Results)
#     res_df.to_csv(filename, sep=" ", index=False)
204/23:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)

run_i = 0
m_values = list()
for Pl, lat_size_i in product(np.linspace(1e-25,1e-24,n_param), lat_size):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
print(pd.DataFrame(Mx, columns=np.linspace(1e-25,1e-24,n_param), index=lat_size))
#     filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
#     res_df = pd.DataFrame(Results)
#     res_df.to_csv(filename, sep=" ", index=False)
204/24:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)

run_i = 0
m_values = list()
for Pl, lat_size_i in product(np.linspace(1e-25,1e-24,n_param), lat_size):
    print(Pl, lat_size_i)
    run_i += 1
    # update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
print(pd.DataFrame(Mx, columns=np.linspace(1e-25,1e-24,n_param), index=lat_size))
#     filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
#     res_df = pd.DataFrame(Results)
#     res_df.to_csv(filename, sep=" ", index=False)
204/25:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)

run_i = 0
m_values = list()
for Pl, lat_size_i in product(np.linspace(1e-25,1e-24,n_param), lat_size):
    run_i += 1
    # update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    print(Pl, lat_size_i, transitions[transistion][1][0])
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
print(pd.DataFrame(Mx, columns=np.linspace(1e-25,1e-24,n_param), index=lat_size))
#     filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
#     res_df = pd.DataFrame(Results)
#     res_df.to_csv(filename, sep=" ", index=False)
204/26:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)

run_i = 0
m_values = list()
for Pl, lat_size_i in product(np.linspace(1e-25,1e-24,n_param), lat_size):
    run_i += 1
    # update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    print(Pl, lat_size_i, transitions[transition][1][0])
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
print(pd.DataFrame(Mx, columns=np.linspace(1e-25,1e-24,n_param), index=lat_size))
#     filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
#     res_df = pd.DataFrame(Results)
#     res_df.to_csv(filename, sep=" ", index=False)
204/27:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)

run_i = 0
m_values = list()
for lat_size_i, Pl in product(lat_size, np.linspace(1e-25,1e-24,n_param)):
    run_i += 1
    # update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    print(Pl, lat_size_i, transitions[transition][1][0])
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
Results = {
    "Lat_Size": lat_size,
    "Exec_Time": exec_time,
    "Mx": Mx,
    "My": My,
    "Mz": Mz
}
print(pd.DataFrame(Mx, columns=np.linspace(1e-25,1e-24,n_param), index=lat_size))
#     filename=f"Article_2_Results/M_Lat_time_SSize_{sim_size}_{prop}_QSize_{qd_size}_{band_i}_{band_f}_trn{transition}.csv"
#     res_df = pd.DataFrame(Results)
#     res_df.to_csv(filename, sep=" ", index=False)
204/28:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
for lat_size_i, Pl in product(lat_size, param):
    run_i += 1
    # update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    print(Pl, lat_size_i, transitions[transition][1][0])
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_Pl"))
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_Pl"))
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_Pl"))
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_Pl"))
204/29:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
for lat_size_i, Pl in product(lat_size, param):
    run_i += 1
    # update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    print(Pl, lat_size_i, transitions[transition][1][0])
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, sep=" ", columns=param, index=lat_size).to_csv(export_name("Mx_LSize_Pl"))
pd.DataFrame(My, sep=" ", columns=param, index=lat_size).to_csv(export_name("My_LSize_Pl"))
pd.DataFrame(Mz, sep=" ", columns=param, index=lat_size).to_csv(export_name("Mz_LSize_Pl"))
pd.DataFrame(exec_time, sep=" ", columns=param, index=lat_size).to_csv(export_name("ETime_LSize_Pl"))
204/30:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
for lat_size_i, Pl in product(lat_size, param):
    run_i += 1
    # update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    print(Pl, lat_size_i, transitions[transition][1][0])
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_Pl", sep=" "))
204/31:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3
n_param = 2
me = 0.08
mh = 0.08
Pt = 4.7e-25
Pl = 3.4e-25
qd_size = 3
Eg = 2.3
Vcb = 0.4
Vvb = 1.5
sim_size = 10
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
for lat_size_i, Pl in product(lat_size, param):
    run_i += 1
    # update_step(run_i, n_param*n_lat)
    # prop = f"Pl_{Pl:.2g}"
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    print(Pl, lat_size_i, transitions[transition][1][0])
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")
204/32:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 3; n_param = 2 
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
print("Running for Pl")
for lat_size_i, Pl in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
print("Running for Pt")
for lat_size_i, Pt in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(0.05, 0.15, n_param)
print("Running for me")
for lat_size_i, me in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(0.05, 0.15, n_param)
print("Running for mh")
for lat_size_i, mh in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(2, 10, n_param)
print("Running for QSize")
for lat_size_i, qd_size in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(10, 30, n_param)
print("Running for SSize")
for lat_size_i, sim_size in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
205/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
205/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
205/3:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
print("Running for Pl")
for lat_size_i, Pl in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
print("Running for Pt")
for lat_size_i, Pt in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(0.05, 0.15, n_param)
print("Running for me")
for lat_size_i, me in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(0.05, 0.15, n_param)
print("Running for mh")
for lat_size_i, mh in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(2, 10, n_param)
print("Running for QSize")
for lat_size_i, qd_size in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(10, 30, n_param)
print("Running for SSize")
for lat_size_i, sim_size in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
206/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
206/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
206/3: np.linspace(0.05, 0.15, n_param)
206/4: np.linspace(0.05, 0.15, 10)
206/5: np.round(np.linspace(0.05, 0.15, 10), 2)
206/6:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.round(np.linspace(1e-25, 1e-24, n_param), 2)
print("Running for Pl")
for lat_size_i, Pl in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(1e-25, 1e-24, n_param), 2)
print("Running for Pt")
for lat_size_i, Pt in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for lat_size_i, me in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for lat_size_i, mh in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 2)
print("Running for QSize")
for lat_size_i, qd_size in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 2)
print("Running for SSize")
for lat_size_i, sim_size in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
206/7:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
206/8:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
206/9: param = np.round(np.linspace(1e-25, 1e-24, n_param), 2)
206/10: np.round(np.linspace(1e-25, 1e-24, n_param), 2)
206/11: np.format_scientific(np.linspace(1e-25, 1e-24, n_param), 2)
206/12: np.format_float_scientific(np.linspace(1e-25, 1e-24, n_param), 2)
206/13: np.around(np.linspace(1e-25, 1e-24, n_param), 2)
206/14: np.linspace(1e-25, 1e-24, n_param)
206/15:
np.linspace(1e-25, 1e-24, n_param)
[print(f"{point:.2g}") for point in np.linspace(1e-25, 1e-24, n_param)]
206/16: [print(f"{point:.2g}") for point in np.linspace(1e-25, 1e-24, n_param)]
206/17: [f"{point:.2g}" for point in np.linspace(1e-25, 1e-24, n_param)]
206/18:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for lat_size_i, Pl in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for lat_size_i, Pt in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for lat_size_i, me in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for lat_size_i, mh in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for lat_size_i, qd_size in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for lat_size_i, sim_size in product(lat_size, param):
    run_i += 1
    update_step(run_i, n_param*n_lat)
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param)
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param)
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param)
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param)
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
207/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
207/2:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
207/3:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
207/4:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_lat, n_param).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_lat, n_param).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_lat, n_param).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_lat, n_param).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
207/5:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 10; n_param = 2
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
207/6:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
207/7:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
207/8:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 10; n_param = 2
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
        print(m_values[transition][1][0])
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
207/9:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 10; n_param = 2
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
        print(m_values[0][transition][1][0])
raise Exception("Stop early")
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
207/10:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 10; n_param = 2
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
        print(Pl, lat_size, m_values)
raise Exception("Stop early")
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
207/11:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 10; n_param = 2
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
        print("\n", Pl, lat_size, transitions[transition][1][0])
raise Exception("Stop early")
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
207/12:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 10; n_param = 2
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
        print("\n", Pl, lat_size_i, transitions[transition][1][0])
raise Exception("Stop early")
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
207/13:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 10; n_param = 2
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        # update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        print(transitions)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
207/14:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
207/15:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
207/16:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 10; n_param = 2
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        # update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        print(len(transitions), transitions)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
207/17:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
207/18:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
207/19:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_tran = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_tran = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_tran = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_tran = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_tran = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_tran = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_SSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_SSize"), sep=" ")
207/20:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_SSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_SSize"), sep=" ")
207/21:
n_sim= 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 1
sim_size = np.linspace(10, 30, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (lat_size, sim_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (lat_size, sim_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (lat_size, sim_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (lat_size, sim_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (lat_size, sim_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (lat_size, sim_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
207/22:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_SSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_SSize"), sep=" ")
207/23:
n_sim= 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 30, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (lat_size, sim_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (lat_size, sim_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (lat_size, sim_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (lat_size, sim_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (lat_size, sim_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (lat_size, sim_size_i, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
207/24:
n_sim= 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 30, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
207/25:
n_sim= 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 30, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
208/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
208/2:
n_sim= 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 30, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
208/3:
n_sim= 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 30, n_sim)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
208/4:
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 30, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
208/5:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
208/6:
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 30, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
208/7:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
208/8:
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 25, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
209/1: from qd_base_data import qd_results
210/1: from band_model.qd_base_data import qd_results
210/2: ?qD_results
210/3: ?qd_results
210/4: qd_results(1.5, 1, 0.1, 0.1, band="CB")
210/5: qd_results(1.5, 1, 0.1, 0.1, band="CB1")
210/6: qd = qd_results(1.5, 1, 0.1, 0.1, band="CB1")
210/7: qd.e_va
210/8: qd.e_levels
210/9: 2*9.109e-31/(6.582e-16)**2
210/10: 1/4.205 * 10 * 0.22
210/11: qd = qd_results(3, 1, 0.1, 0.1, band="CB1")
210/12: qd.e_levels
210/13: h
210/14: qd = qd_results(2.5, 1, 0.1, 0.1, band="CB1")
210/15: qd.e_levels
210/16: 0.145/(4.205*0.1)
210/17: 1-0.624
210/18: 0.5678/(4.205*m)
210/19: 0.5678/(4.205*0.1)
210/20: 0.96804/(4.205*0.1)
210/21: ls
210/22: qd
210/23: import numpy as np
210/24: x = np.linspace(-5, 5, 100)
210/25: qd.norm_wavefunction(x, x, x, 1, 0, 0)
211/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
211/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
211/3:
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 25, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
212/1: from band_model import qd_base_data
212/2: from band_model.qd_base_data import qd_results
212/3: ?qd_results
212/4: ?qd_results
212/5: qd = qd_results(2.5, 1, 0.1, 0.1, "CB1")
212/6: qd.e_levels
212/7: qd = qd_results(3.5, 1, 0.1, 0.1, "CB1")
212/8: qd.e_levels
212/9: qd = qd_results(2.5, 1, 0.1, 0.1, "CB1")
212/10: qd.e_levels
212/11: qd = qd_results(3.5, 1, 0.1, 0.1, "CB1")
212/12: qd.e_levels
212/13: qd = qd_results(3.5, 1.5, 0.1, 0.1, "CB1")
212/14: qd.e_levels
211/4:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
211/5:
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 25, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, 50)
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, 5), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, n_lat)
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
213/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
213/2:
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 25, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, 50)
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, 5), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, n_lat)
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
213/3:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
213/4:
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 25, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, 50)
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, 5), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, n_lat)
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
214/1: ls
214/2: from band_model.qd_base_data import qd_results
214/3: qd_results(3.5, 1, 0.1, 0.1, "CB1")
214/4: qd = qd_results(3.5, 1, 0.1, 0.1, "CB1")
214/5: qd.e_levels
215/1: from band_model.qd_base_data import qd_results
215/2: qd = qd_results(3.5, 1, 0.1, 0.1, "CB1")
215/3: qd.e_levels
216/1: from band_model.qd_base_data import qd_results
216/2: qd = qd_results(3.5, 1, 0.1, 0.1, "CB1")
216/3: qd.e_levels
213/5: m_values
213/6:
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
213/7:
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(5, 50).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(5, 50).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(5, 50).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(5, 50).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(5, 50).T
213/8:
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, n_lat)
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
213/9:
n_lat = 100; n_param = 10
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 25, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, 25)
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, 5), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(5, 25).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(5, 25).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(5, 25).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(5, 25).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, n_lat)
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
213/10:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
213/11:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
213/12:
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, 25)
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, 5), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(5, 25).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(5, 25).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(5, 25).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(5, 25).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")
213/13: m_values
213/14:
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(5, 25).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(5, 25).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(5, 25).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(5, 25).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(5, 25).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" "
213/15:
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(5, 25).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(5, 25).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(5, 25).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(5, 25).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(5, 25).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")
213/16: param
213/17: sim_size
213/18: m_values.shape
213/19: len(m_values)
213/20: exec_time = np.array([m_value[1] for m_value in m_values]).reshape(5, 25).T
213/21: exec_time
213/22:
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, 25)
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, 5), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pt, Pl))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(5, 25).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(5, 25).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(5, 25).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(5, 25).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(5, 25).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
column_vals = [f"{point:.2g}" for point in param]
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")
213/23:
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(5, 25).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(5, 25).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(5, 25).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(5, 25).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(5, 25).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=5, index=25).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=5, index=25).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=5, index=25).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=5, index=25).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
column_vals = [f"{point:.2g}" for point in param]
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")
213/24: len(m_values)
218/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
218/2:
# Global properties
Band_i = "VB1"; band_f = "CB1"
transition = 0
n_param = 5
218/3:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8, sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param*n_lat)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions))

# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/4:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8, sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions))

# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/5:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
218/6:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8, sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions))

# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/7:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8, sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions))

# Export the results using a DataFrame
pd.DataFrame(Mx).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/8:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8, sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions))

# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/9:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8, sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions))

# Export the results using a DataFrame
pd.DataFrame(Mx, column=[1] index=param).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/10:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8, sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions))

# Export the results using a DataFrame
pd.DataFrame(Mx, column=[1], index=param).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/11:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8, sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions))

# Export the results using a DataFrame
pd.DataFrame(Mx, columns=[1], index=param).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/12:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8, sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions))

# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/13:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8, sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/14:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8, sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/15:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/16:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
218/17:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/18:
# Global properties
band_i = "VB1"; band_f = "CB1"
transition = 0
n_param = 5
218/19:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
218/20:
# Global properties
band_i = "VB1"; band_f = "CB1"
transition = 0
n_param = 100
218/21:
# Global properties
band_i = "VB1"; band_f = "CB1"
transition = 0
n_param = 100
218/22:
# Global properties
band_i = "VB1"; band_f = "CB1"
transition = 0
n_param = 2
218/23:
# Global properties
band_i = "VB1"; band_f = "CB1"
transition = 0
n_param = 2
218/24:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_me"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_me"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_me"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_me"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_me"), sep=" ")
218/25:
# mh
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for mh in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_mh"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_mh"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_mh"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_mh"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_mh"), sep=" ")
218/26:
# Pt
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)

for Pt in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_Pt"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_Pt"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_Pt"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_Pt"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_Pt"), sep=" ")
218/27:
# Pl
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)

for Pl in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_Pl"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_Pl"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_Pl"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_Pl"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_Pl"), sep=" ")
218/28:
#Qsize
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(2, 7, n_param)

for qd_size in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_QSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_QSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_QSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_QSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_QSize"), sep=" ")
219/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
219/2:
# Global properties
band_i = "VB1"; band_f = "CB1"
transition = 0
n_param = 100
219/3:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_me"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_me"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_me"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_me"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_me"), sep=" ")
219/4:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
219/5:
# Global properties
band_i = "VB1"; band_f = "CB1"
transition = 0
n_param = 100
219/6:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_me"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_me"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_me"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_me"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_me"), sep=" ")
219/7:
# mh
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for mh in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_mh"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_mh"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_mh"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_mh"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_mh"), sep=" ")
219/8:
# Pt
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)

for Pt in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_Pt"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_Pt"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_Pt"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_Pt"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_Pt"), sep=" ")
219/9:
# Pl
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)

for Pl in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_Pl"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_Pl"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_Pl"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_Pl"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_Pl"), sep=" ")
219/10:
#Qsize
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(2, 7, n_param)

for qd_size in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_QSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_QSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_QSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_QSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_QSize"), sep=" ")
219/11: m_value[2]
219/12: m_values[2]
219/13: transitions
219/14: transition
219/15: transitions
219/16: m_value[2]
219/17: [print(m_value[2]) for m_value in m_values]
219/18:
# Global properties
band_i = "VB1"; band_f = "CB2"
transition = 0
n_param = 100
219/19:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_me"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_me"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_me"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_me"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_me"), sep=" ")
219/20:
# mh
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for mh in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_mh"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_mh"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_mh"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_mh"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_mh"), sep=" ")
219/21:
# Pt
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)

for Pt in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_Pt"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_Pt"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_Pt"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_Pt"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_Pt"), sep=" ")
219/22:
# Pl
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)

for Pl in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_Pl"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_Pl"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_Pl"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_Pl"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_Pl"), sep=" ")
219/23:
#Qsize
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(2, 7, n_param)

for qd_size in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_QSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_QSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_QSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_QSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_QSize"), sep=" ")
219/24:
# Global properties
band_i = "VB2"; band_f = "CB1"
transition = 0
n_param = 100
219/25:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_me"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_me"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_me"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_me"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_me"), sep=" ")
219/26:
# mh
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for mh in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_mh"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_mh"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_mh"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_mh"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_mh"), sep=" ")
219/27:
# Pt
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)

for Pt in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_Pt"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_Pt"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_Pt"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_Pt"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_Pt"), sep=" ")
219/28:
# Pl
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)

for Pl in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_Pl"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_Pl"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_Pl"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_Pl"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_Pl"), sep=" ")
219/29:
#Qsize
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(2, 7, n_param)

for qd_size in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_QSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_QSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_QSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_QSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_QSize"), sep=" ")
219/30:
# Global properties
band_i = "VB2"; band_f = "CB2"
transition = 0
n_param = 100
219/31:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_me"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_me"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_me"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_me"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_me"), sep=" ")
219/32:
# mh
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for mh in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_mh"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_mh"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_mh"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_mh"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_mh"), sep=" ")
219/33:
# Pt
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)

for Pt in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_Pt"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_Pt"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_Pt"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_Pt"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_Pt"), sep=" ")
219/34:
# Pl
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)

for Pl in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_Pl"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_Pl"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_Pl"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_Pl"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_Pl"), sep=" ")
219/35:
#Qsize
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(2, 7, n_param)

for qd_size in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_QSize"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_QSize"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_QSize"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_QSize"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_QSize"), sep=" ")
219/36:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
# Results
qd1 = qbd.qd_results(qd_size, Vcb, me, me, band_i)
qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, band_f)
transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
219/37: transitions
219/38: qd1.e_levels
219/39: qd2.e_levels
219/40: pd.DataFrame(transitions)
219/41: transitions
219/42: [[i, trn, mx, my, mz] for i, (t, (mx, my, mz)) in enumerate(transitions)]
219/43: [[i, trn, mx, my, mz] for i, (trn, (mx, my, mz)) in enumerate(transitions)]
219/44: pd.DataFrame([[i, trn, mx, my, mz] for i, (trn, (mx, my, mz)) in enumerate(transitions)])
219/45: pd.DataFrame([[i+1, trn, mx, my, mz] for i, (trn, (mx, my, mz)) in enumerate(transitions)])
219/46:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, b_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    results_df = pd.DataFrame([[i+1, trn, mx, my, mz] for i, (trn, (mx, my, mz)) in enumerate(transitions)])
    results_df.to_csv(f"M_default_{b_i}_{b_f}.csv", sep=" ")
219/47:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vcb, me, me, b_i)
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    results_df = pd.DataFrame([[i+1, trn, mx, my, mz] for i, (trn, (mx, my, mz)) in enumerate(transitions)])
    # results_df.to_csv(f"M_default_{b_i}_{b_f}.csv", sep=" ")
219/48:     qd1 = qbd.qd_results(qd_size, Vcb, me, me, "CB1")
219/49:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
219/50:
# me
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
m_values = list()
param = np.linspace(0.05, 0.15, n_param)

for me in param:
    run_i += 1
    update_step(run_i, n_param)
    sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    # Also determine the time to run a particular simulation
    start = timeit.default_timer()
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    stop = timeit.default_timer()
    m_values.append((transitions, stop-start, len(transitions)))
                    
exec_time = np.array([m_value[1] for m_value in m_values])
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
My = np.array([m_value[0][transition][1][1] for m_value in m_values])
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
n_trn = np.array([m_value[2] for m_value in m_values])
# Export the results using a DataFrame
pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_me"), sep=" ")
pd.DataFrame(My, index=param).to_csv(export_name("My_me"), sep=" ")
pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_me"), sep=" ")
pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_me"), sep=" ")
pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_me"), sep=" ")
219/51:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    results_df = pd.DataFrame([[i+1, trn, mx, my, mz] for i, (trn, (mx, my, mz)) in enumerate(transitions)])
    # results_df.to_csv(f"M_default_{b_i}_{b_f}.csv", sep=" ")
219/52:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    results_df = pd.DataFrame([[i+1, trn, mx, my, mz] for i, (trn, (mx, my, mz)) in enumerate(transitions)])
    results_df.to_csv(f"M_default_{b_i}_{b_f}.csv", sep=" ")
219/53: qd1 = qbd.qd_results(qd_size, Vcb, me, me, "CB1")
219/54: qd1.e_levels
219/55: qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")
219/56: qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")
219/57: qd2.e_levels
219/58:
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
l = 0
m = 0
n = 0

env = ["L6pb", "L6pt", "L6mb", "L6mt"]
band = "CB1"
for env_i in env:
    qd_wavefunction = qbd.qd_results(qd_size, Vcb, me, me, band)
    XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env_i, l, m, n, Eg, P)
    x = np.arange(-sim_size, sim_size, lat_size)
    gridToVTK(f"Article_2_Results/band_{band}_envolute_{env_i}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")
219/59:
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
l = 0
m = 0
n = 0

env = ["L6pb", "L6pt", "L6mb", "L6mt"]
band = "CB1"
for env_i in env:
    qd_wavefunction = qbd.qd_results(qd_size, Vcb, me, me, band)
    XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env_i, l, m, n, Eg, (Pt, Pl))
    x = np.arange(-sim_size, sim_size, lat_size)
    gridToVTK(f"Article_2_Results/band_{band}_envolute_{env_i}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
    qd2 = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")
219/60:
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
l = 0
m = 0
n = 0

env = ["L6pb", "L6pt", "L6mb", "L6mt"]
band = "CB1"
x = np.arange(-sim_size, sim_size, lat_size)
qd_wavefunction = qbd.qd_results(qd_size, Vcb, me, me, band)
XX, YY, ZZ, WVFC = qd_wavefunction.norm_wavefunction(x, x, x, l, m, n)
gridToVTK(f"Article_2_Results/band_{band}_wavefunction_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(WVFC)**2})
for env_i in env:
    XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env_i, l, m, n, Eg, (Pt, Pl))
    gridToVTK(f"Article_2_Results/band_{band}_envolute_{env_i}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
219/61:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
angle = np.linspace(0, np.pi, 100)
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_element = np.sin(theta)**2*transitions[0][1][0] + np.sin(theta)**2*transitions[0][1][1] + np.cos(theta)**2*transitions[0][1][2]
    print(transitions)
219/62:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_element = np.sin(theta)**2*transitions[0][1][0] + np.sin(theta)**2*transitions[0][1][1] + np.cos(theta)**2*transitions[0][1][2]
    print(transitions)
219/63:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_element = np.sin(theta)**2*transitions[0][1][0] + np.sin(theta)**2*transitions[0][1][1] + np.cos(theta)**2*transitions[0][1][2]
    print(angular element)
219/64:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_element = np.sin(theta)**2*transitions[0][1][0] + np.sin(theta)**2*transitions[0][1][1] + np.cos(theta)**2*transitions[0][1][2]
    print(angular_element)
219/65:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[0][1][0] + np.sin(theta)**2*transitions[0][1][1] + np.cos(theta)**2*transitions[0][1][2])

plt.axes(projection="angular")
plt.polar(theta, angular_elements[0])
219/66:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[0][1][0] + np.sin(theta)**2*transitions[0][1][1] + np.cos(theta)**2*transitions[0][1][2])

plt.axes(projection="polar")
plt.polar(theta, angular_elements[0])
plt.show()
219/67: angular_elements
219/68: angular_elements[0]
219/69:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[0][1][0] + np.sin(theta)**2*transitions[0][1][1] + np.cos(theta)**2*transitions[0][1][2])


plt.axes(projection="polar")
for t_i, e_i, in zip(theta, angular_elements[0]):  
    plt.polar(t_i, e_i, 'g.')
plt.show()
219/70:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[0][1][0] + np.sin(theta)**2*transitions[0][1][1] + np.cos(theta)**2*transitions[0][1][2])


plt.axes(projection="polar")
for t_i, e_i, in zip(theta, angular_elements[0]):  
    plt.polar(e_i, t_i, 'g.')
plt.show()
219/71:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[0][1][0] + np.sin(theta)**2*transitions[0][1][1] + np.cos(theta)**2*transitions[0][1][2])


plt.axes(projection="polar")
plt.polar(theta, theta)
plt.show()
219/72:
plt.axes(projection="polar")
plt.polar(np.linspace(0, 2*np.pi, 100))
plt.show()
219/73:
plt.axes(projection="polar")
plt.polar(np.linspace(0, 2*np.pi, 100), 0.3)
plt.show()
219/74:
plt.axes(projection="polar")
plt.polar(np.linspace(0, 180, 100), 0.3)
plt.show()
219/75:
plt.axes(projection="polar")
plt.polar(np.linspace(0, 2*np.pi, 100), 0.3)
plt.show()
219/76:
angle = np.linspace(0, 2*np.pi, 100)
plt.axes(projection="polar")
plt.polar(angle, 0.3)
plt.show()
219/77:
angle = np.linspace(0, 2*np.pi, 100)
plt.axes(projection="polar")
plt.polar(angle, 0.3, 'g.')
plt.show()
219/78:
angle = np.linspace(0, 2*np.pi, 100)
ax = plt.subplot(figsize=(6,6), polar='True')
ax.plot(angle, 0.3, 'g.')
plt.show()
219/79:
angle = np.linspace(0, 2*np.pi, 100)
ax = plt.subplot(polar='True')
ax.plot(angle, 0.3, 'g.')
plt.show()
219/80:
angle = np.linspace(0, 2*np.pi, 100)
ax = plt.subplot(polar='True')
ax.plot(angle, angle, 'g.')
plt.show()
219/81:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[0][1][0] + np.sin(theta)**2*transitions[0][1][1] + np.cos(theta)**2*transitions[0][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0])
plt.show()
219/82:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[0][1][0] + np.sin(theta)**2*transitions[0][1][1] + np.cos(theta)**2*transitions[0][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3])
plt.show()
219/83:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[0][1][0] + np.sin(theta)**2*transitions[0][1][1] + np.cos(theta)**2*transitions[0][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3]/4)
plt.show()
219/84:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[0][1][0] + np.sin(theta)**2*transitions[0][1][1] + np.cos(theta)**2*transitions[0][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
219/85:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[0][0][0] + np.sin(theta)**2*transitions[0][0][1] + np.cos(theta)**2*transitions[0][0][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
219/86:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[1][1][0] + np.sin(theta)**2*transitions[1][1][1] + np.cos(theta)**2*transitions[1][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
219/87:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[2][1][0] + np.sin(theta)**2*transitions[2][1][1] + np.cos(theta)**2*transitions[2][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
219/88:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[3][1][0] + np.sin(theta)**2*transitions[3][1][1] + np.cos(theta)**2*transitions[3][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
219/89:


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.legend()
plt.show()
219/90:


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], label="VB1-CB1")
plt.plot(theta, angular_elements[1], label="VB1-CB2")
plt.plot(theta, angular_elements[2], label="VB2-CB1")
plt.plot(theta, angular_elements[3], label="VB2-CB2")
plt.plot(theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, label="Total")
plt.show()
219/91:


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], label="VB1-CB1")
plt.plot(theta, angular_elements[1], label="VB1-CB2")
plt.plot(theta, angular_elements[2], label="VB2-CB1")
plt.plot(theta, angular_elements[3], label="VB2-CB2")
plt.plot(theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, label="Total")
plt.legend()
plt.show()
219/92:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[3][1][0] + np.sin(theta)**2*transitions[3][1][1] + np.cos(theta)**2*transitions[3][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[1]+angular_elements[3])/4)
plt.show()
219/93:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
trn=3
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[trn][1][0] + np.sin(theta)**2*transitions[trn][1][1] + np.cos(theta)**2*transitions[trn][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[1]+angular_elements[3])/4)
plt.show()
219/94:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
trn=3
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[trn][1][0] + np.sin(theta)**2*transitions[trn][1][1] + np.cos(theta)**2*transitions[trn][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
219/95:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
trn=1
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[trn][1][0] + np.sin(theta)**2*transitions[trn][1][1] + np.cos(theta)**2*transitions[trn][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
219/96:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
trn=2
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[trn][1][0] + np.sin(theta)**2*transitions[trn][1][1] + np.cos(theta)**2*transitions[trn][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
220/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorp\tion as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
220/2:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
220/3:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
trn=2
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[trn][1][0] + np.sin(theta)**2*transitions[trn][1][1] + np.cos(theta)**2*transitions[trn][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
221/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
221/2:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
trn=2
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[trn][1][0] + np.sin(theta)**2*transitions[trn][1][1] + np.cos(theta)**2*transitions[trn][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
221/3:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
trn=2
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[trn][1][0] + np.sin(theta)**2*transitions[trn][1][1] + np.cos(theta)**2*transitions[trn][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
221/4:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
trn=0
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[trn][1][0] + np.sin(theta)**2*transitions[trn][1][1] + np.cos(theta)**2*transitions[trn][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
221/5:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pt, Pl))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
trn=0
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[trn][1][0] + np.sin(theta)**2*transitions[trn][1][1] + np.cos(theta)**2*transitions[trn][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
221/6:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
trn=0
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[trn][1][0] + np.sin(theta)**2*transitions[trn][1][1] + np.cos(theta)**2*transitions[trn][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
221/7:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
theta = np.linspace(0, np.pi, 100)
angular_elements = list()
trn=3
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    angular_elements.append(np.sin(theta)**2*transitions[trn][1][0] + np.sin(theta)**2*transitions[trn][1][1] + np.cos(theta)**2*transitions[trn][1][2])


plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
221/8:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    results_df = pd.DataFrame([[i+1, trn, mx, my, mz] for i, (trn, (mx, my, mz)) in enumerate(transitions)])
    results_df.to_csv(f"M_default_{b_i}_{b_f}.csv", sep=" ")
222/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
222/2:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
    print(transitions)
    results_df = pd.DataFrame([[i+1, trn, mx, my, mz] for i, (trn, (mx, my, mz)) in enumerate(transitions)])
    results_df.to_csv(f"M_default_{b_i}_{b_f}.csv", sep=" ")
222/3:
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
l = 0; m = 0; n = 0
env = ["L6pb", "L6pt", "L6mb", "L6mt"]
band = "CB1"
x = np.arange(-sim_size, sim_size, lat_size)
qd_wavefunction = qbd.qd_results(qd_size, Vcb, me, me, band)
XX, YY, ZZ, WVFC = qd_wavefunction.norm_wavefunction(x, x, x, l, m, n)
gridToVTK(f"Article_2_Results/band_{band}_wavefunction_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(WVFC)**2})
for env_i in env:
    XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, env_i, l, m, n, Eg, (Pl, Pt))
    gridToVTK(f"Article_2_Results/band_{band}_envolute_{env_i}_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
222/4:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
theta = np.linspace(0, np.pi, 100)
trn_list = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    trn_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties))
222/5:
angular_elements = list()
trn = 0
for trn_i in trn_list:
    angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0] + np.sin(theta)**2*trn_i[trn][1][1] + np.cos(theta)**2*tran_i[trn][1][2])

plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
222/6:
angular_elements = list()
trn = 0
for trn_i in trn_list:
    angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0] + np.sin(theta)**2*trn_i[trn][1][1] + np.cos(theta)**2*trn_i[trn][1][2])

plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
222/7:
angular_elements = list()
trn = 1
for trn_i in trn_list:
    angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0] + np.sin(theta)**2*trn_i[trn][1][1] + np.cos(theta)**2*trn_i[trn][1][2])

plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
222/8:
angular_elements = list()
trn = 2
for trn_i in trn_list:
    angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0] + np.sin(theta)**2*trn_i[trn][1][1] + np.cos(theta)**2*trn_i[trn][1][2])

plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
222/9:
angular_elements = list()
trn = 3
for trn_i in trn_list:
    angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0] + np.sin(theta)**2*trn_i[trn][1][1] + np.cos(theta)**2*trn_i[trn][1][2])

plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
222/10:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
trn_list = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    trn_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties))
222/11:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
for trn_i in trn_list:
    angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0] + np.sin(theta)**2*trn_i[trn][1][1] + np.cos(theta)**2*trn_i[trn][1][2])

plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
222/12:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
for trn_i in trn_list:
    angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0]**2 + np.sin(theta)**2*trn_i[trn][1][1]**2 + np.cos(theta)**2*trn_i[trn][1][2]**2)

plt.axes(projection="polar")
plt.plot(theta, angular_elements[0], theta, angular_elements[1], theta, angular_elements[2], theta, angular_elements[3], theta, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
222/13:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0]**2 + np.sin(theta)**2*trn_i[trn][1][1]**2 + np.cos(theta)**2*trn_i[trn][1][2]**2)
    plt.plot(theta+np.pi*t_i, angular_elements[0],
             theta+np.pi*t_i, angular_elements[1],
             theta+np.pi*t_i, angular_elements[2],
             theta+np.pi*t_i, angular_elements[3],
             theta+np.pi*t_i, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
222/14:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0]**2 + np.sin(theta)**2*trn_i[trn][1][1]**2 + np.cos(theta)**2*trn_i[trn][1][2]**2)
    plt.plot(theta+np.pi*t_i/2, angular_elements[0],
             theta+np.pi*t_i/2, angular_elements[1],
             theta+np.pi*t_i/2, angular_elements[2],
             theta+np.pi*t_i/2, angular_elements[3],
             theta+np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4)
plt.show()
222/15:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0]**2 + np.sin(theta)**2*trn_i[trn][1][1]**2 + np.cos(theta)**2*trn_i[trn][1][2]**2)
    plt.plot(theta+np.pi*t_i/2, angular_elements[0], 'r'
             theta+np.pi*t_i/2, angular_elements[1], 'b'
             theta+np.pi*t_i/2, angular_elements[2], 'g'
             theta+np.pi*t_i/2, angular_elements[3], 'o'
             theta+np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'y')
plt.show()
222/16:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0]**2 + np.sin(theta)**2*trn_i[trn][1][1]**2 + np.cos(theta)**2*trn_i[trn][1][2]**2)
    plt.plot(theta+np.pi*t_i/2, angular_elements[0], 'r',
             theta+np.pi*t_i/2, angular_elements[1], 'b',
             theta+np.pi*t_i/2, angular_elements[2], 'g',
             theta+np.pi*t_i/2, angular_elements[3], 'o',
             theta+np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'y')
plt.show()
222/17:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn-1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0]**2 + np.sin(theta)**2*trn_i[trn][1][1]**2 + np.cos(theta)**2*trn_i[trn][1][2]**2)
    plt.plot(theta+np.pi*t_i/2, angular_elements[0], 'r',
             theta+np.pi*t_i/2, angular_elements[1], 'b',
             theta+np.pi*t_i/2, angular_elements[2], 'g',
             theta+np.pi*t_i/2, angular_elements[3], 'o',
             theta+np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'y')
plt.show()
222/18:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn):
    print(t_i)
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0]**2 + np.sin(theta)**2*trn_i[trn][1][1]**2 + np.cos(theta)**2*trn_i[trn][1][2]**2)
    plt.plot(theta+np.pi*t_i/2, angular_elements[0], 'r',
             theta+np.pi*t_i/2, angular_elements[1], 'b',
             theta+np.pi*t_i/2, angular_elements[2], 'g',
             theta+np.pi*t_i/2, angular_elements[3], 'o',
             theta+np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'y')
plt.show()
222/19:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[trn][1][0]**2 + np.sin(theta)**2*trn_i[trn][1][1]**2 + np.cos(theta)**2*trn_i[trn][1][2]**2)
    plt.plot(theta+np.pi*t_i/2, angular_elements[0], 'r',
             theta+np.pi*t_i/2, angular_elements[1], 'b',
             theta+np.pi*t_i/2, angular_elements[2], 'g',
             theta+np.pi*t_i/2, angular_elements[3], 'o',
             theta+np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'y')
plt.show()
222/20:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    plt.plot(theta+np.pi*t_i/2, angular_elements[0], 'r',
             theta+np.pi*t_i/2, angular_elements[1], 'b',
             theta+np.pi*t_i/2, angular_elements[2], 'g',
             theta+np.pi*t_i/2, angular_elements[3], 'o',
             theta+np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'y')
plt.show()
222/21:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    plt.plot(theta+np.pi*t_i/2, angular_elements[0], 'r',
             theta+np.pi*t_i/2, angular_elements[1], 'b',
             theta+np.pi*t_i/2, angular_elements[2], 'g',
             theta+np.pi*t_i/2, angular_elements[3], 'b',
             theta+np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'y')
plt.show()
222/22:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    plt.plot(theta+np.pi*t_i/2, angular_elements[0], 'r',
             theta+np.pi*t_i/2, angular_elements[1], 'b',
             theta+np.pi*t_i/2, angular_elements[2], 'g',
             theta+np.pi*t_i/2, angular_elements[3], 'magenta',
             theta+np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'y')
plt.show()
222/23:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    plt.plot(theta+np.pi*t_i/2, angular_elements[0], 'red',
             theta+np.pi*t_i/2, angular_elements[1], 'blue',
             theta+np.pi*t_i/2, angular_elements[2], 'green',
             theta+np.pi*t_i/2, angular_elements[3], 'brown',
             theta+np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/24:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    plt.plot(theta+np.pi*t_i, angular_elements[0], 'red',
             theta+np.pi*t_i, angular_elements[1], 'blue',
             theta+np.pi*t_i, angular_elements[2], 'green',
             theta+np.pi*t_i, angular_elements[3], 'brown',
             theta+np.pi*t_i, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/25:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    plt.plot(theta-np.pi*t_i, angular_elements[0], 'red',
             theta-np.pi*t_i, angular_elements[1], 'blue',
             theta-np.pi*t_i, angular_elements[2], 'green',
             theta-np.pi*t_i, angular_elements[3], 'brown',
             theta-np.pi*t_i, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/26:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    plt.plot(theta-np.pi*t_i/2, angular_elements[0], 'red',
             theta-np.pi*t_i/2, angular_elements[1], 'blue',
             theta-np.pi*t_i/2, angular_elements[2], 'green',
             theta-np.pi*t_i/2, angular_elements[3], 'brown',
             theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/27:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    plt.plot(theta-np.pi*t_i/2, angular_elements[0], 'red',
             theta-np.pi*t_i/2, angular_elements[1], 'blue',
             theta-np.pi*t_i/2, angular_elements[2], 'green',
             theta-np.pi*t_i/2, angular_elements[3], 'green',
             theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/28:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.axes(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    plt.plot(theta-np.pi*t_i/2, angular_elements[0], 'red',
             theta-np.pi*t_i/2, angular_elements[1], 'blue',
             theta-np.pi*t_i/2, angular_elements[2], 'green',
             theta-np.pi*t_i/2, angular_elements[3], 'brown',
             theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/29:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
ax = plt.subplot(figsize=(5,5), projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    ax.plot(theta-np.pi*t_i/2, angular_elements[0], 'red',
             theta-np.pi*t_i/2, angular_elements[1], 'blue',
             theta-np.pi*t_i/2, angular_elements[2], 'green',
             theta-np.pi*t_i/2, angular_elements[3], 'brown',
             theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/30:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.figure(figsize=(6,6))
ax = plt.subplot(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    ax.plot(theta-np.pi*t_i/2, angular_elements[0], 'red',
             theta-np.pi*t_i/2, angular_elements[1], 'blue',
             theta-np.pi*t_i/2, angular_elements[2], 'green',
             theta-np.pi*t_i/2, angular_elements[3], 'brown',
             theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/31:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.figure(figsize=(10,10))
ax = plt.subplot(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    ax.plot(theta-np.pi*t_i/2, angular_elements[0], 'red',
             theta-np.pi*t_i/2, angular_elements[1], 'blue',
             theta-np.pi*t_i/2, angular_elements[2], 'green',
             theta-np.pi*t_i/2, angular_elements[3], 'brown',
             theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/32:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 0
plt.figure(figsize=(10,10))
ax = plt.subplot(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    ax.plot(theta-np.pi*t_i/2, angular_elements[0], 'red',
             theta-np.pi*t_i/2, angular_elements[1], 'blue',
             theta-np.pi*t_i/2, angular_elements[2], 'green',
             theta-np.pi*t_i/2, angular_elements[3], 'brown',
             theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/33:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 1
plt.figure(figsize=(10,10))
ax = plt.subplot(projection="polar")
for t_i in range(trn+1):
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    ax.plot(theta-np.pi*t_i/2, angular_elements[0], 'red',
             theta-np.pi*t_i/2, angular_elements[1], 'blue',
             theta-np.pi*t_i/2, angular_elements[2], 'green',
             theta-np.pi*t_i/2, angular_elements[3], 'brown',
             theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/34:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 1
plt.figure(figsize=(10,10))
ax = plt.subplot(projection="polar")
for t_i in range(trn+1):
    angular_elements = list()
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    ax.plot(theta-np.pi*t_i/2, angular_elements[0], 'red',
             theta-np.pi*t_i/2, angular_elements[1], 'blue',
             theta-np.pi*t_i/2, angular_elements[2], 'green',
             theta-np.pi*t_i/2, angular_elements[3], 'brown',
             theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/35:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.figure(figsize=(10,10))
ax = plt.subplot(projection="polar")
for t_i in range(trn+1):
    angular_elements = list()
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    ax.plot(theta-np.pi*t_i/2, angular_elements[0], 'red',
             theta-np.pi*t_i/2, angular_elements[1], 'blue',
             theta-np.pi*t_i/2, angular_elements[2], 'green',
             theta-np.pi*t_i/2, angular_elements[3], 'brown',
             theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/36:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 5; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
trn_list = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    trn_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties))
222/37:
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.figure(figsize=(10,10))
ax = plt.subplot(projection="polar")
for t_i in range(trn+1):
    angular_elements = list()
    for trn_i in trn_list:
        angular_elements.append(np.sin(theta)**2*trn_i[t_i][1][0]**2 + np.sin(theta)**2*trn_i[t_i][1][1]**2 + np.cos(theta)**2*trn_i[t_i][1][2]**2)
    ax.plot(theta-np.pi*t_i/2, angular_elements[0], 'red',
             theta-np.pi*t_i/2, angular_elements[1], 'blue',
             theta-np.pi*t_i/2, angular_elements[2], 'green',
             theta-np.pi*t_i/2, angular_elements[3], 'brown',
             theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta')
plt.show()
222/38:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 50; n_param = 5
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_SSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_SSize"), sep=" ")
222/39:
n_lat = 50; n_param = 5
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 25, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, 25)
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, 5), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(5, 25).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(5, 25).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(5, 25).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(5, 25).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, n_lat)
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
222/40:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
222/41:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 50; n_param = 5
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_SSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_SSize"), sep=" ")
223/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
223/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
223/3:
# Define the constant variables
# Default values
# me = 0.08
# mh = 0.08
# Pt = 4.7e-25
# Pl = 3.4e-25
# qd_size = 3
# Eg = 2.3
# Vcb = 0.4
# Vvb = 1.5
# sim_size = 10
# band_i = "VB1"
# band_f = "CB1"
# lat_size = np.linspace(0.4, 2, 2)
n_lat = 50; n_param = 5
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
lat_size = np.linspace(0.4, 2, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=lat_size).to_csv(export_name("Mx_LSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=lat_size).to_csv(export_name("My_LSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=lat_size).to_csv(export_name("Mz_LSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=lat_size).to_csv(export_name("ETime_LSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; sim_size = 10
run_i = 0
m_values = list()
param = np.round(np.linspace(10, 30, n_param), 1)
print("Running for SSize")
for sim_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for lat_size_i in lat_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size, lat_size_i, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=lat_size).to_csv(export_name("Mx_LSize_SSize"), sep=" ")
pd.DataFrame(My, columns=param, index=lat_size).to_csv(export_name("My_LSize_SSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=lat_size).to_csv(export_name("Mz_LSize_SSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=lat_size).to_csv(export_name("ETime_LSize_SSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=lat_size).to_csv(export_name("NTrn_LSize_SSize"), sep=" ")
223/4:
n_lat = 50; n_param = 5
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
Eg = 2.3
Vcb = 0.4;
Vvb = 1.5
band_i = "VB1"
band_f = "CB1"
transition = 0
sim_size = np.linspace(10, 25, n_lat)
export_name = lambda name: f"Article_2_Results/{name}_{band_i}_{band_f}.csv"

run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pl")
for Pl in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))

exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pl"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pl"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pl"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pl"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pl"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.linspace(1e-25, 1e-24, n_param)
column_vals = [f"{point:.2g}" for point in param]
print("Running for Pt")
for Pt in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)  
        sim_properties = (sim_size_i, lat_size, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=column_vals, index=sim_size).to_csv(export_name("Mx_SSize_Pt"), sep=" ")
pd.DataFrame(My, columns=column_vals, index=sim_size).to_csv(export_name("My_SSize_Pt"), sep=" ")
pd.DataFrame(Mz, columns=column_vals, index=sim_size).to_csv(export_name("Mz_SSize_Pt"), sep=" ")
pd.DataFrame(exec_time, columns=column_vals, index=sim_size).to_csv(export_name("ETime_SSize_Pt"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_Pt"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for me")
for me in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_me"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_me"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_me"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_me"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_me"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(0.05, 0.15, n_param), 2)
print("Running for mh")
for mh in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_mh"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_mh"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_mh"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_mh"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_mh"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
run_i = 0
m_values = list()
param = np.round(np.linspace(2, 10, n_param), 1)
print("Running for QSize")
for qd_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_QSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_QSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_QSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_QSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_QSize"), sep=" ")

me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8
sim_size = np.linspace(10, 25, n_lat)
run_i = 0
m_values = list()
param = np.round(np.linspace(0.4, 2, n_param), 1)
print("Running for LSize")
for lat_size in param:
    # Calculate the QD classes
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
    for sim_size_i in sim_size:
        run_i += 1
        update_step(run_i, n_param*n_lat)
        sim_properties = (sim_size_i, lat_size, Eg, (Pl, Pt))
        # Also determine the time to run a particular simulation
        start = timeit.default_timer()
        transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
        stop = timeit.default_timer()
        m_values.append((transitions, stop-start, len(transitions)))
    
exec_time = np.array([m_value[1] for m_value in m_values]).reshape(n_param, n_lat).T
Mx = np.array([m_value[0][transition][1][0] for m_value in m_values]).reshape(n_param, n_lat).T
My = np.array([m_value[0][transition][1][1] for m_value in m_values]).reshape(n_param, n_lat).T
Mz = np.array([m_value[0][transition][1][2] for m_value in m_values]).reshape(n_param, n_lat).T
n_trn = np.array([m_value[2] for m_value in m_values]).reshape(n_param, n_lat).T
# Export the results using a DataFrame
pd.DataFrame(Mx, columns=param, index=sim_size).to_csv(export_name("Mx_SSize_LSize"), sep=" ")
pd.DataFrame(My, columns=param, index=sim_size).to_csv(export_name("My_SSize_LSize"), sep=" ")
pd.DataFrame(Mz, columns=param, index=sim_size).to_csv(export_name("Mz_SSize_LSize"), sep=" ")
pd.DataFrame(exec_time, columns=param, index=sim_size).to_csv(export_name("ETime_SSize_LSize"), sep=" ")
pd.DataFrame(n_trn, columns=column_vals, index=sim_size).to_csv(export_name("NTrn_SSize_LSize"), sep=" ")
223/5:
def V_offset(Host_Eg, QD_Eg, offset_ratio):
    """ Return the adequately offseted Vcv/Vvb values """
    Vcb = (Host_Eg - QD_Eg)*offset_ratio
    Vvb = (Host_Eg - QD_Eg)*(1-offset_ratio)
    return Vcb, Vvb
223/6:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 100)
qd_size = np.linspace(2, 4, 10)
Vcb, Vvb = V_offset(Eg, 0.4, 1/2)
band_i = "VB1": band_f = "CB1"
results = [list() for i in qd_size]
for result_i, qd_size_i in zip(results, qd_size):
    for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
        run_i+=1
        update_step(run_i, 10*100)
        qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
        qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
        trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
        result_i.append(trn)
    result_i = np.array(result_i)
223/7:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 100)
qd_size = np.linspace(2, 4, 10)
Vcb, Vvb = V_offset(Eg, 0.4, 1/2)
band_i = "VB1"; band_f = "CB1"
results = [list() for i in qd_size]
for result_i, qd_size_i in zip(results, qd_size):
    for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
        run_i+=1
        update_step(run_i, 10*100)
        qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
        qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
        trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
        result_i.append(trn)
    result_i = np.array(result_i)
224/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
224/2:
def V_offset(Host_Eg, QD_Eg, offset_ratio):
    """ Return the adequately offseted Vcv/Vvb values """
    Vcb = (Host_Eg - QD_Eg)*offset_ratio
    Vvb = (Host_Eg - QD_Eg)*(1-offset_ratio)
    return Vcb, Vvb
224/3:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 100)
qd_size = np.linspace(2, 4, 10)
Vcb, Vvb = V_offset(Eg, 0.4, 1/2)
band_i = "VB1"; band_f = "CB1"
results = [list() for i in qd_size]
for result_i, qd_size_i in zip(results, qd_size):
    for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
        run_i+=1
        update_step(run_i, 10*100)
        qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
        qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
        trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
        result_i.append(trn)
    result_i = np.array(result_i)
224/4:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
224/5:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 100)
qd_size = np.linspace(2, 4, 10)
Vcb, Vvb = V_offset(Eg, 0.4, 1/2)
band_i = "VB1"; band_f = "CB1"
results = [list() for i in qd_size]
for result_i, qd_size_i in zip(results, qd_size):
    for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
        run_i+=1
        update_step(run_i, 10*100)
        qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
        qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
        trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
        result_i.append(trn)
    result_i = np.array(result_i)
224/6:
plt.figure(figsize=(10,7))
for i, qsize in enumerate(qd_size):
    plt.plot(Eg, results[i], label=f"QSize={qsize:0.3f}")
    
plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend()
224/7:
plt.figure(figsize=(10,7))
colors=['blue', 'light green', 'light red', 'purple', 'orange', 'light blue', 'dark blue', 'green', 'red']
for i, qsize in enumerate(qd_size):
    plt.plot(Eg, results[i], label=f"QSize={qsize:0.3f}")
    
plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend()
224/8:
plt.figure(figsize=(10,7))
colors=['blue', 'light green', 'light red', 'purple', 'orange', 'light blue', 'dark blue', 'green', 'red']
for i, qsize in enumerate(qd_size):
    plt.plot(Eg, results[i], colors[i], label=f"QSize={qsize:0.3f}")
    
plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend()
224/9:
plt.figure(figsize=(10,7))
colors=['blue', 'light green', 'light red', 'purple', 'orange', 'light blue', 'dark blue', 'green', 'red']
for i, qsize in enumerate(qd_size):
    plt.plot(Eg, results[i], 'blue', label=f"QSize={qsize:0.3f}")
    
plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend()
224/10:
plt.figure(figsize=(10,7))
colors=['blue', 'light green', 'light red', 'purple', 'orange', 'light blue', 'dark blue', 'green', 'red']
for i, qsize in enumerate(qd_size):
    plt.plot(Eg, results[i], 'light green', label=f"QSize={qsize:0.3f}")
    
plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend()
224/11:
plt.figure(figsize=(10,7))
colors=['blue', 'light green', 'light red', 'purple', 'orange', 'light blue', 'dark blue', 'green', 'red']
for i, qsize in enumerate(qd_size):
    plt.plot(Eg, results[i], 'lightgreen', label=f"QSize={qsize:0.3f}")
    
plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend()
224/12:
plt.figure(figsize=(10,7))
colors=['blue', 'lightgreen', 'lightred', 'purple', 'orange', 'lightblue', 'darkblue', 'green', 'red']
for i, qsize in enumerate(qd_size):
    plt.plot(Eg, results[i], colors[i], label=f"QSize={qsize:0.3f}")
    
plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend()
224/13:
plt.figure(figsize=(10,7))
colors=['blue', 'lightgreen', 'red', 'purple', 'orange', 'lightblue', 'darkblue', 'green', 'red']
for i, qsize in enumerate(qd_size):
    plt.plot(Eg, results[i], colors[i], label=f"QSize={qsize:0.3f}")
    
plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend()
224/14:
plt.figure(figsize=(10,7))
for i, qsize in enumerate(qd_size):
    plt.plot(Eg, results[i], label=f"QSize={qsize:0.3f}")
    
plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend()
224/15:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 100)
qd_size = np.linspace(2, 4, 10)
band_i = "VB1"; band_f = "CB1"
for offset in [1/2, 1/3, 1/4]:
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 3*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            result_i.append(trn)
        result_i = np.array(result_i)
    ## Plot
    plt.figure(figsize=(10,7))
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], label=f"QSize={qsize:0.3f}")

    plt.xlabel("Host BG (eV)")
    plt.ylabel("QD Bg (eV)")
    plt.legend()
224/16:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 100)
qd_size = np.linspace(2, 4, 10)
band_i = "VB1"; band_f = "CB1"
for offset in [0.5, 0.6, 0.7]:
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 3*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            result_i.append(trn)
        result_i = np.array(result_i)
    ## Plot
    plt.figure(figsize=(10,7))
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], label=f"QSize={qsize:0.3f}")

    plt.xlabel("Host BG (eV)")
    plt.ylabel("QD Bg (eV)")
    plt.legend()
224/17:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 3)
qd_size = np.linspace(2, 4, 3)
band_i = "VB1"; band_f = "CB1"
plt.figure(figsize=(10,7))
for offset in [0.5, 0.6, 0.7]:
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 3*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            result_i.append(trn)
        result_i = np.array(result_i)
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], label=f"{qsize:0.3f=}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left")
224/18:
asdfa="asdfa"
print(f"{asdfa=}")
224/19:
asdfa=13.33
print(f"{asdfa=}")
224/20:
asdfa=13.33
print(f"{asdfa:.1f=}")
224/21:
asdfa=13.33
print(f"{asdfa=:.1f}")
224/22:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 3)
qd_size = np.linspace(2, 4, 3)
band_i = "VB1"; band_f = "CB1"
plt.figure(figsize=(10,7))
for offset in [0.5, 0.6, 0.7]:
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 3*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            result_i.append(trn)
        result_i = np.array(result_i)
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left")
224/23:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 3)
qd_size = np.linspace(2, 4, 3)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.']
plt.figure(figsize=(10,7))
for lt, offset in enumerate([0.5, 0.6, 0.7]):
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 3*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            result_i.append(trn)
        result_i = np.array(result_i)
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], colors[i], linetype=lt_list[lt], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left")
224/24:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 3)
qd_size = np.linspace(2, 4, 3)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.']
plt.figure(figsize=(10,7))
for lt, offset in enumerate([0.5, 0.6, 0.7]):
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 3*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            result_i.append(trn)
        result_i = np.array(result_i)
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], colors[i], linestyle=lt_list[lt], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left")
224/25:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 100)
qd_size = np.linspace(2, 4, 10)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.']
plt.figure(figsize=(10,7))
for lt, offset in enumerate([0.5, 0.6, 0.7]):
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 3*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            result_i.append(trn)
        result_i = np.array(result_i)
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], colors[i], linestyle=lt_list[lt], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left")
224/26:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 100)
qd_size = np.linspace(2, 4, 10)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
for lt, offset in enumerate([0.5, 0.6, 0.7, 0.8]):
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 3*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            result_i.append(trn)
        result_i = np.array(result_i)
        df = pd.Dataframe(result_i, columns=["QD_Size"], index=Eg)
        df["QD_Size"] = qd_size_i; df["Offset"] = offset
        df.to_csv(f"QD_BG_{q_size:0.3f}_{offset}.csv", sep=" ")
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], colors[i], linestyle=lt_list[lt], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left", ncol=4)
224/27:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 3)
qd_size = np.linspace(2, 4, 3)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
for lt, offset in enumerate([0.5, 0.6, 0.7, 0.8]):
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 4*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            result_i.append(trn)
        result_i = np.array(result_i)
        df = pd.Dataframe(result_i, columns=["QD_Size"], index=Eg)
        df["QD_Size"] = qd_size_i; df["Offset"] = offset
        df.to_csv(f"QD_BG_{q_size:0.3f}_{offset}.csv", sep=" ")
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], colors[i], linestyle=lt_list[lt], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left", ncol=4)
224/28:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 3)
qd_size = np.linspace(2, 4, 3)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
for lt, offset in enumerate([0.5, 0.6, 0.7, 0.8]):
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 4*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            result_i.append(trn)
        result_i = np.array(result_i)
        df = pd.DataFrame(result_i, columns=["QD_Size"], index=Eg)
        df["QD_Size"] = qd_size_i; df["Offset"] = offset
        df.to_csv(f"QD_BG_{q_size:0.3f}_{offset}.csv", sep=" ")
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], colors[i], linestyle=lt_list[lt], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left", ncol=4)
224/29:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 3)
qd_size = np.linspace(2, 4, 3)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
for lt, offset in enumerate([0.5, 0.6, 0.7, 0.8]):
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 4*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            result_i.append(trn)
        result_i = np.array(result_i)
        df = pd.DataFrame(result_i, columns=["QD_Size"], index=Eg)
        df["QD_Size"] = qd_size_i; df["Offset"] = offset
        df.to_csv(f"QD_BG_{qd_size_i:0.3f}_{offset}.csv", sep=" ")
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], colors[i], linestyle=lt_list[lt], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left", ncol=4)
224/30:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 3)
qd_size = np.linspace(2, 4, 3)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
for lt, offset in enumerate([0.5, 0.6, 0.7, 0.8]):
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 4*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            try:
                trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            except IndexError:
                trn = np.nan
            result_i.append(trn)
        result_i = np.array(result_i)
        df = pd.DataFrame(result_i, columns=["QD_Size"], index=Eg)
        df["QD_Size"] = qd_size_i; df["Offset"] = offset
        df.to_csv(f"QD_BG_{qd_size_i:0.3f}_{offset}.csv", sep=" ")
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], colors[i], linestyle=lt_list[lt], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left", ncol=4)
224/31:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 3)
qd_size = np.linspace(2, 4, 3)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
for lt, offset in enumerate([0.5, 0.6, 0.7, 0.8]):
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 4*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            try:
                trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            except IndexError:
                trn = np.nan
            result_i.append(trn)
        result_i = np.array(result_i)
        df = pd.DataFrame(result_i, columns=["QD_BG"], index=Eg)
        df["QD_Size"] = qd_size_i; df["Offset"] = offset
        df.to_csv(f"QD_BG_{qd_size_i:0.3f}_{offset}.csv", sep=" ")
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], colors[i], linestyle=lt_list[lt], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left", ncol=4)
224/32:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 3)
qd_size = np.linspace(2, 4, 3)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
for lt, offset in enumerate([0.5, 0.6, 0.7, 0.8]):
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 4*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            try:
                trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            except IndexError:
                trn = np.nan
            result_i.append(trn)
        result_i = np.array(result_i)
        df = pd.DataFrame(result_i, columns=["QD_BG"], index=Eg)
        print(df)
        df["QD_Size"] = qd_size_i; df["Offset"] = offset
        df.to_csv(f"QD_BG_{qd_size_i:0.3f}_{offset}.csv", sep=" ")
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], colors[i], linestyle=lt_list[lt], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left", ncol=4)
224/33:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 3)
qd_size = np.linspace(2, 4, 3)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
for lt, offset in enumerate([0.5, 0.6, 0.7, 0.8]):
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 4*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            try:
                trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            except IndexError:
                trn = np.nan
            result_i.append(trn)
        result_i = np.array(result_i)
        df = pd.DataFrame(result_i, columns=["QD_BG"], index=Eg)
        print(df)
        df["QD_Size"] = qd_size_i; df["Offset"] = offset
        df.to_csv(f"QD_BG_{qd_size_i:0.3f}_{offset}.csv", sep=" ", na_rep="NaN")
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], colors[i], linestyle=lt_list[lt], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left", ncol=4)
224/34:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 100)
qd_size = np.linspace(1.5, 4, 10)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
for lt, offset in enumerate([0.5, 0.6, 0.7, 0.8]):
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 4*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            try:
                trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            except IndexError:
                trn = np.nan
            result_i.append(trn)
        result_i = np.array(result_i)
        df = pd.DataFrame(result_i, columns=["QD_BG"], index=Eg)
        df["QD_Size"] = qd_size_i; df["Offset"] = offset
        df.to_csv(f"QD_BG_{qd_size_i:0.3f}_{offset}.csv", sep=" ", na_rep="NaN")
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], colors[i], linestyle=lt_list[lt], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left", ncol=4)
224/35:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = np.linspace(1.5, 5, 100)
qd_size = np.linspace(1.5, 4, 10)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
for lt, offset in enumerate([0.5, 0.6, 0.7, 0.8]):
    results = [list() for i in qd_size]
    Vcb, Vvb = V_offset(Eg, 0.4, offset)
    for result_i, qd_size_i in zip(results, qd_size):
        for Eg_i, Vcb_i, Vvb_i in zip(Eg, Vcb, Vvb):
            ## Calculate
            run_i+=1
            update_step(run_i, 4*10*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb_i, mh, mh, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb_i, me, me, band_f)
            try:
                trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, Eg_i, (Pl, Pt)), count=1)[0][0]
            except IndexError:
                trn = np.nan
            result_i.append(trn)
        result_i = np.array(result_i)
        df = pd.DataFrame(result_i, columns=["QD_BG"], index=Eg)
        df["QD_Size"] = qd_size_i; df["Offset"] = offset
        df.to_csv(f"QD_BG_{qd_size_i:0.3f}_{offset}.csv", sep=" ", na_rep="NaN")
    ## Plot
    for i, qsize in enumerate(qd_size):
        plt.plot(Eg, results[i], colors[i], linestyle=lt_list[lt], label=f"{qsize=:0.3f}:{offset=}")

plt.xlabel("Host BG (eV)")
plt.ylabel("QD Bg (eV)")
plt.legend(bbox_to_anchor=(1,1), loc="upper left", ncol=4)
224/36:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 5; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
band_list = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties))
theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.figure(figsize=(10,10))
ax = plt.subplot(projection="polar")
for t_i in range(trn+1):
    angular_elements = list()
    for b_i in band_list:
        angular_elements.append(np.sin(theta)**2*b_i[t_i][1][0]**2 + np.sin(theta)**2*b_i[t_i][1][1]**2 + np.cos(theta)**2*b_i[t_i][1][2]**2)
    ax.plot(theta-np.pi*t_i/2, angular_elements[0], 'red', label="VB1-CB1")
    ax.plot(theta-np.pi*t_i/2, angular_elements[1], 'blue', label="VB1-CB2")
    ax.plot(theta-np.pi*t_i/2, angular_elements[2], 'green', label="VB2-CB1")
    ax.plot(theta-np.pi*t_i/2, angular_elements[3], 'brown', label="VB2-CB2")
    ax.plot(theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta', label="Total")
plt.show()
224/37:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 2; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
band_list = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties))

theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.figure(figsize=(10,10))
ax = plt.subplot(projection="polar")
for t_i in range(trn+1):
    angular_elements = list()
    for b_i in band_list:
        angular_elements.append(np.sin(theta)**2*b_i[t_i][1][0]**2 + np.sin(theta)**2*b_i[t_i][1][1]**2 + np.cos(theta)**2*b_i[t_i][1][2]**2)
    ax.plot(theta-np.pi*t_i/2, angular_elements[0], 'red', label="VB1-CB1")
    ax.plot(theta-np.pi*t_i/2, angular_elements[1], 'blue', label="VB1-CB2")
    ax.plot(theta-np.pi*t_i/2, angular_elements[2], 'green', label="VB2-CB1")
    ax.plot(theta-np.pi*t_i/2, angular_elements[3], 'brown', label="VB2-CB2")
    ax.plot(theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta', label="Total")
plt.show()
224/38:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
band_list = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties))

theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.figure(figsize=(10,10))
ax = plt.subplot(projection="polar")
for t_i in range(trn+1):
    angular_elements = list()
    for b_i in band_list:
        angular_elements.append(np.sin(theta)**2*b_i[t_i][1][0]**2 + np.sin(theta)**2*b_i[t_i][1][1]**2 + np.cos(theta)**2*b_i[t_i][1][2]**2)
    ax.plot(theta-np.pi*t_i/2, angular_elements[0], 'red', label="VB1-CB1")
    ax.plot(theta-np.pi*t_i/2, angular_elements[1], 'blue', label="VB1-CB2")
    ax.plot(theta-np.pi*t_i/2, angular_elements[2], 'green', label="VB2-CB1")
    ax.plot(theta-np.pi*t_i/2, angular_elements[3], 'brown', label="VB2-CB2")
    ax.plot(theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta', label="Total")
plt.show()
224/39:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
band_list = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties))

theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.figure(figsize=(10,10))
ax = plt.subplot(projection="polar")
for t_i in range(trn+1):
    angular_elements = list()
    for b_i in band_list:
        angular_elements.append(np.sin(theta)**2*b_i[t_i][1][0]**2 + np.sin(theta)**2*b_i[t_i][1][1]**2 + np.cos(theta)**2*b_i[t_i][1][2]**2)
    ax.plot(theta-np.pi*t_i/2, angular_elements[0], 'red', label="VB1-CB1")
    ax.plot(theta-np.pi*t_i/2, angular_elements[1], 'blue', label="VB1-CB2")
    ax.plot(theta-np.pi*t_i/2, angular_elements[2], 'green', label="VB2-CB1")
    ax.plot(theta-np.pi*t_i/2, angular_elements[3], 'brown', label="VB2-CB2")
    ax.plot(theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta', label="Total")

plt.legend()
plt.show()
224/40:
# Bands
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
# Default Values
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
band_list = list()
# Results
for b_i, b_f in product(bi, bf):
    print(b_i, b_f)
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
    band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties))

theta = np.linspace(0, np.pi/2, 100)
angular_elements = list()
trn = 3
plt.figure(figsize=(10,10))
ax = plt.subplot(projection="polar")
for t_i in range(trn+1):
    angular_elements = list()
    for b_i in band_list:
        angular_elements.append(np.sin(theta)**2*b_i[t_i][1][0]**2 + np.sin(theta)**2*b_i[t_i][1][1]**2 + np.cos(theta)**2*b_i[t_i][1][2]**2)
    ax.plot(theta-np.pi*t_i/2, angular_elements[0], 'red', label="VB1-CB1")
    ax.plot(theta-np.pi*t_i/2, angular_elements[1], 'blue', label="VB1-CB2")
    ax.plot(theta-np.pi*t_i/2, angular_elements[2], 'green', label="VB2-CB1")
    ax.plot(theta-np.pi*t_i/2, angular_elements[3], 'brown', label="VB2-CB2")
    ax.plot(theta-np.pi*t_i/2, (angular_elements[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4, 'magenta', label="Total")

plt.legend(bbox_to_anchor=(1,1), loc="upper left", ncol=4)
plt.show()
225/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
225/2: qd_wavefunction = qbd.qd_results(3, 1.9, 0.08, 0.08, "CB1")
225/3: qd_wavefunction.e_levels
226/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
226/2:
def V_offset(Host_Eg, QD_Eg, offset_ratio):
    """ Return the adequately offseted Vcv/Vvb values """
    Vcb = (Host_Eg - QD_Eg)*offset_ratio
    Vvb = (Host_Eg - QD_Eg)*(1-offset_ratio)
    return Vcb, Vvb
226/3:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = [2.3, 1.5, 1]
qd_size = np.linspace(1.5, 7, 100)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
res_df = pd.DataFrame()
res_df["QSize"] = qd_size
for eg_i in Eg:
    Vcb, Vvb = V_offset(eg_i, 0.4, 0.5)
    results = []
    for qd_size_i in qd_size:
        ## Calculate
        run_i+=1
        update_step(run_i, 4*10*100)
        qd1 = qbd.qd_results(qd_size_i, Vvb, mh, mh, band_i)
        qd2 = qbd.qd_results(qd_size_i, Vcb, me, me, band_f)
        try:
            trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, eg_i, (Pl, Pt)), count=1)[0][0]
        except IndexError:
            trn = np.nan
        results.append(trn)
    res_df[f"{eg_i=}"] = results
    plt.plot(qd_size, results, label=f"{eg_i}")
res_df.to_csv("QDEg_QSize.csv", sep=" ", index=False)
plt.plot(qd_size, 0.41+1/(0.0252*(2*qd_size)**2+0.283*(2*qd_size)), '-.', label="Empirical")
plt.legend()
plt.show()
226/4:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
226/5:
me=0.08; mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = [2.3, 1.5, 1]
qd_size = np.linspace(1.5, 7, 100)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
res_df = pd.DataFrame()
res_df["QSize"] = qd_size
for eg_i in Eg:
    Vcb, Vvb = V_offset(eg_i, 0.4, 0.5)
    results = []
    for qd_size_i in qd_size:
        ## Calculate
        run_i+=1
        update_step(run_i, 4*10*100)
        qd1 = qbd.qd_results(qd_size_i, Vvb, mh, mh, band_i)
        qd2 = qbd.qd_results(qd_size_i, Vcb, me, me, band_f)
        try:
            trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, eg_i, (Pl, Pt)), count=1)[0][0]
        except IndexError:
            trn = np.nan
        results.append(trn)
    res_df[f"{eg_i=}"] = results
    plt.plot(qd_size, results, label=f"{eg_i}")
res_df.to_csv("QDEg_QSize.csv", sep=" ", index=False)
plt.plot(qd_size, 0.41+1/(0.0252*(2*qd_size)**2+0.283*(2*qd_size)), '-.', label="Empirical")
plt.legend()
plt.show()
228/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
228/2: qd1 = qbd.qd_results(2.5, 1.5, 0.08, 0.08, "CB")
228/3: qd1 = qbd.qd_results(2.5, 1.5, 0.08, 0.08, "CB1")
228/4: qd1.e_levels
228/5: qd1.e_levels[0]
228/6: qd1.e_levels[0,0]
228/7: qd1.e_levels.loc[0]
228/8: qd1.e_levels.loc[0,0]
228/9: qd1.e_levels.iloc[0,0]
228/10:
e = list()
for V in np.linspace(1, 2,25):
    qd1 = qbd.qd_results(2.5, V, 0.08, 0.08, "CB1")
    e.append(qd1.e_levels.iloc[0, 0])
    
plt.plot(np.linspace(1, 2, 25), e)
228/11:
e = list()
for V in np.linspace(1, 2,25):
    qd1 = qbd.qd_results(2.5, V, 0.08, 0.08, "CB1")
    e.append(qd1.e_levels.iloc[0, 0])
    
plt.plot(np.linspace(1, 2, 25), np.linspace(1, 2, 25) - e)
228/12:
e = list()
for V in np.linspace(1, 2,25):
    qd1 = qbd.qd_results(2.5, V, 0.08, 0.08, "CB1")
    e.append(qd1.e_levels.iloc[0, 0])
    
plt.plot(np.linspace(1, 2, 25), e)
228/13:
e = list()
for V in np.linspace(1, 2,25):
    qd1 = qbd.qd_results(2.5, V, 0.08, 0.08, "CB1")
    e.append(qd1.e_levels.iloc[0, 0])
    
plt.plot(np.linspace(1, 2, 25), np.linspace(1, 2, 25) - e)
228/14:
trn = list()
for V in np.linspace(1, 2,25):
    for qsize_i in np.linspace(1.5, 4, 25):
        qd1 = qbd.qd_results(qsize_i, V, 0.08, 0.08, "CB1")
        trn.append(qd1.e_levels.iloc[0, 0])   
    plt.plot(np.linspace(1.5, 4, 25), V + trn)
228/15:
for V in np.linspace(1, 2,25):
    trn = list()
    for qsize_i in np.linspace(1.5, 4, 25):
        qd1 = qbd.qd_results(qsize_i, V, 0.08, 0.08, "CB1")
        trn.append(qd1.e_levels.iloc[0, 0])   
    plt.plot(np.linspace(1.5, 4, 25), V + trn)
228/16:
for V in np.linspace(1, 2,5):
    trn = list()
    for qsize_i in np.linspace(1.5, 4, 25):
        qd1 = qbd.qd_results(qsize_i, V, 0.08, 0.08, "CB1")
        trn.append(qd1.e_levels.iloc[0, 0])   
    plt.plot(np.linspace(1.5, 4, 25), 0.41 + V + trn)
plt.plot(0.41+1/(0.0252*(2*x)**2+0.283*(2*x)), '--')
228/17:
qsize = np.linspace(1.4, 7, 25)
for V in np.linspace(1, 2,5):
    trn = list()
    for qsize_i in qsize:
        qd1 = qbd.qd_results(qsize_i, V, 0.08, 0.08, "CB1")
        trn.append(qd1.e_levels.iloc[0, 0])   
    plt.plot(np.linspace(1.5, 4, 25), 0.41 + V + trn)
plt.plot(qsize, 0.41+1/(0.0252*(2*qsize)**2+0.283*(2*qsize)), '--')
228/18:
qsize = np.linspace(1.4, 7, 25)
for V in np.linspace(1, 2,5):
    trn = list()
    for qsize_i in qsize:
        qd1 = qbd.qd_results(qsize_i, V, 0.08, 0.08, "CB1")
        trn.append(qd1.e_levels.iloc[0, 0])   
    plt.plot(np.linspace(1.5, 4, 25), 0.41 + 2*(V + trn))
plt.plot(qsize, 0.41+1/(0.0252*(2*qsize)**2+0.283*(2*qsize)), '--')
228/19:
qsize = np.linspace(1.4, 7, 25)
for V in np.linspace(1, 2, 5):
    trn = list()
    for qsize_i in qsize:
        qd1 = qbd.qd_results(qsize_i, V, 0.08, 0.08, "CB1")
        trn.append(qd1.e_levels.iloc[0, 0])   
    plt.plot(qsize, 0.41 + 2*(V + trn))
plt.plot(qsize, 0.41+1/(0.0252*(2*qsize)**2+0.283*(2*qsize)), '--')
228/20:
qsize = np.linspace(1.4, 7, 25)
for V in np.linspace(1, 2, 5):
    trn = list()
    for qsize_i in qsize:
        qd1 = qbd.qd_results(qsize_i, V, 0.08, 0.08, "CB1")
        trn.append(qd1.e_levels.iloc[0, 0])   
    plt.plot(qsize, 0.41 + 2*(V + trn), label=f"{V=}")
plt.plot(qsize, 0.41+1/(0.0252*(2*qsize)**2+0.283*(2*qsize)), '--')
228/21:
qsize = np.linspace(1.4, 7, 25)
for V in np.linspace(1, 2, 5):
    trn = list()
    for qsize_i in qsize:
        qd1 = qbd.qd_results(qsize_i, V, 0.08, 0.08, "CB1")
        trn.append(qd1.e_levels.iloc[0, 0])   
    plt.plot(qsize, 0.41 + 2*(V + trn), label=f"{V=}")
plt.plot(qsize, 0.41+1/(0.0252*(2*qsize)**2+0.283*(2*qsize)), '--')
plt.legend()
228/22:
qsize = np.linspace(1.4, 7, 25)
for V in np.linspace(1, 2, 5):
    trn = list()
    qd1 = qbd.qd_results(2.5, V, 0.08, 0.08, "CB1")
    trn.append(qd1.e_levels.iloc[0, 0])   
plt.plot(np.linspace(1, 2, 5), np.linspace(1, 2, 5) + trn)
228/23: trn
228/24:
qsize = np.linspace(1.4, 7, 25)
trn = list()
for V in np.linspace(1, 2, 5):
    qd1 = qbd.qd_results(2.5, V, 0.08, 0.08, "CB1")
    trn.append(qd1.e_levels.iloc[0, 0])   
plt.plot(np.linspace(1, 2, 5), np.linspace(1, 2, 5) + trn)
228/25: trn
228/26:
pot = np.linspace(1, 100, 100)
trn = list()
for V in pot:
    qd1 = qbd.qd_results(2.5, V, 0.08, 0.08, "CB1")
    trn.append(qd1.e_levels.iloc[0, 0])   
plt.plot(pot, pot + trn)
228/27:
pot = np.linspace(1, 100, 100)
trn = list()
for V in pot:
    qd1 = qbd.qd_results(2.5, V, 0.08, 0.08, "CB1")
    trn.append(qd1.e_levels.iloc[0, 0])   
plt.plot(pot, pot + trn)
plt.plot(3.17/(26.26*0.08*2.5**2))
228/28:
pot = np.linspace(1, 100, 100)
trn = list()
for V in pot:
    qd1 = qbd.qd_results(2.5, V, 0.08, 0.08, "CB1")
    trn.append(qd1.e_levels.iloc[0, 0])   
plt.plot(pot, pot + trn)
plt.plot(pot, 3.17/(26.26*0.08*2.5**2), '--')
228/29:
pot = np.linspace(1, 100, 100)
trn = list()
for V in pot:
    qd1 = qbd.qd_results(2.5, V, 0.08, 0.08, "CB1")
    trn.append(qd1.e_levels.iloc[0, 0])   
plt.plot(pot, pot + trn)
plt.plot(pot, [3.17/(26.26*0.08*2.5**2)]*len(pot), '--')
232/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
232/2:
def V_offset(Host_Eg, QD_Eg, offset_ratio):
    """ Return the adequately offseted Vcv/Vvb values """
    Vcb = (Host_Eg - QD_Eg)*offset_ratio
    Vvb = (Host_Eg - QD_Eg)*(1-offset_ratio)
    return Vcb, Vvb
232/3:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
232/4:
me=np.linspace(0.05, 0.20, 5); mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = [2.3, 1.5, 1]
qd_size = np.linspace(1.5, 7, 100)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
# res_df = pd.DataFrame()
# res_df["QSize"] = qd_size
for index_i, eg_i in enumerate(Eg):
    Vcb, Vvb = V_offset(eg_i, 0.4, 0.5)
    results = []
    for index, me_i in enumerate(me):
        for qd_size_i in qd_size:
            ## Calculate
            run_i+=1
            update_step(run_i, 3*5*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb, me_i, me_i, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb, me_i, me_i, band_f)
            try:
                trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, eg_i, (Pl, Pt)), count=1)[0][0]
            except IndexError:
                trn = np.nan
            results.append(trn)
        # res_df[f"{eg_i=}"] = results
        plt.plot(qd_size, results, colors[i], linestyle=lt_list[index], label=f"{eg_i}/{me_i}")
# res_df.to_csv("QDEg_QSize.csv", sep=" ", index=False)
plt.plot(qd_size, 0.41+1/(0.0252*(2*qd_size)**2+0.283*(2*qd_size)), '-.', label="Empirical")
plt.legend(bbox_to_anchor=(1,1), loc="upper left")
plt.show()
232/5:
me=np.linspace(0.05, 0.20, 5); mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = [2.3, 1.5, 1]
qd_size = np.linspace(1.5, 7, 100)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
# res_df = pd.DataFrame()
# res_df["QSize"] = qd_size
for index_i, eg_i in enumerate(Eg):
    Vcb, Vvb = V_offset(eg_i, 0.4, 0.5)
    results = []
    for index, me_i in enumerate(me):
        for qd_size_i in qd_size:
            ## Calculate
            run_i+=1
            update_step(run_i, 3*5*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb, me_i, me_i, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb, me_i, me_i, band_f)
            try:
                trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, eg_i, (Pl, Pt)), count=1)[0][0]
            except IndexError:
                trn = np.nan
            results.append(trn)
        # res_df[f"{eg_i=}"] = results
        plt.plot(qd_size, results, colors[index_i], linestyle=lt_list[index], label=f"{eg_i}/{me_i}")
# res_df.to_csv("QDEg_QSize.csv", sep=" ", index=False)
plt.plot(qd_size, 0.41+1/(0.0252*(2*qd_size)**2+0.283*(2*qd_size)), '-.', label="Empirical")
plt.legend(bbox_to_anchor=(1,1), loc="upper left")
plt.show()
232/6:
me=np.linspace(0.05, 0.20, 5); mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = [2.3, 1.5, 1]
qd_size = np.linspace(1.5, 7, 100)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
# res_df = pd.DataFrame()
# res_df["QSize"] = qd_size
for index_i, eg_i in enumerate(Eg):
    Vcb, Vvb = V_offset(eg_i, 0.4, 0.5)
    for index, me_i in enumerate(me):
        results=[]
        for qd_size_i in qd_size:
            ## Calculate
            run_i+=1
            update_step(run_i, 3*5*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb, me_i, me_i, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb, me_i, me_i, band_f)
            try:
                trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, eg_i, (Pl, Pt)), count=1)[0][0]
            except IndexError:
                trn = np.nan
            results.append(trn)
        # res_df[f"{eg_i=}"] = results
        plt.plot(qd_size, results, colors[index_i], linestyle=lt_list[index], label=f"{eg_i}/{me_i}")
# res_df.to_csv("QDEg_QSize.csv", sep=" ", index=False)
plt.plot(qd_size, 0.41+1/(0.0252*(2*qd_size)**2+0.283*(2*qd_size)), '-.', label="Empirical")
plt.legend(bbox_to_anchor=(1,1), loc="upper left")
plt.show()
232/7:
me=np.linspace(0.05, 0.20, 5); mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = [2.3, 1.5, 1]
qd_size = np.linspace(1.5, 7, 100)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
# res_df = pd.DataFrame()
# res_df["QSize"] = qd_size
for index_i, eg_i in enumerate(Eg):
    Vcb, Vvb = V_offset(eg_i, 0.4, 0.5)
    for index, me_i in enumerate(me):
        results=[]
        for qd_size_i in qd_size:
            ## Calculate
            run_i+=1
            update_step(run_i, 3*5*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb, me_i, me_i, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb, me_i, me_i, band_f)
            try:
                trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, eg_i, (Pl, Pt)), count=1)[0][0]
            except IndexError:
                trn = np.nan
            results.append(trn)
        # res_df[f"{eg_i=}"] = results
        plt.plot(qd_size, results, colors[index], linestyle=lt_list[index_i], label=f"{eg_i}/{me_i}")
# res_df.to_csv("QDEg_QSize.csv", sep=" ", index=False)
plt.plot(qd_size, 0.41+1/(0.0252*(2*qd_size)**2+0.283*(2*qd_size)), '-.', label="Empirical")
plt.legend(bbox_to_anchor=(1,1), loc="upper left")
plt.show()
232/8:
me=np.linspace(0.05, 0.20, 3); mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = [2.3, 1.5, 1]
qd_size = np.linspace(1.5, 7, 100)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
# res_df = pd.DataFrame()
# res_df["QSize"] = qd_size
for index_i, eg_i in enumerate(Eg):
    Vcb, Vvb = V_offset(eg_i, 0.4, 0.5)
    for index, me_i in enumerate(me):
        results=[]
        for qd_size_i in qd_size:
            ## Calculate
            run_i+=1
            update_step(run_i, 3*5*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb, me_i, me_i, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb, me_i, me_i, band_f)
            try:
                trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, eg_i, (Pl, Pt)), count=1)[0][0]
            except IndexError:
                trn = np.nan
            results.append(trn)
        # res_df[f"{eg_i=}"] = results
        plt.plot(qd_size, results, colors[index_i], linestyle=lt_list[index], label=f"{eg_i}/{me_i}")
# res_df.to_csv("QDEg_QSize.csv", sep=" ", index=False)
plt.plot(qd_size, 0.41+1/(0.0252*(2*qd_size)**2+0.283*(2*qd_size)), '-.', label="Empirical")
plt.legend(bbox_to_anchor=(1,1), loc="upper left")
plt.show()
232/9:
me=np.linspace(0.05, 0.15, 3); mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = [2.3, 1.5, 1]
qd_size = np.linspace(1.5, 7, 100)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
# res_df = pd.DataFrame()
# res_df["QSize"] = qd_size
for index_i, eg_i in enumerate(Eg):
    Vcb, Vvb = V_offset(eg_i, 0.4, 0.5)
    for index, me_i in enumerate(me):
        results=[]
        for qd_size_i in qd_size:
            ## Calculate
            run_i+=1
            update_step(run_i, 3*5*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb, me_i, me_i, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb, me_i, me_i, band_f)
            try:
                trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, eg_i, (Pl, Pt)), count=1)[0][0]
            except IndexError:
                trn = np.nan
            results.append(trn)
        # res_df[f"{eg_i=}"] = results
        plt.plot(qd_size, results, colors[index_i], linestyle=lt_list[index], label=f"{eg_i}/{me_i}")
# res_df.to_csv("QDEg_QSize.csv", sep=" ", index=False)
plt.plot(qd_size, 0.41+1/(0.0252*(2*qd_size)**2+0.283*(2*qd_size)), '-.', label="Empirical")
plt.legend(bbox_to_anchor=(1,1), loc="upper left")
plt.show()
232/10:
me=np.linspace(0.05, 0.15, 3); mh=0.08; Pt=4.7e-25; Pl=3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
run_i = 0
Eg = [2.3, 1.5, 1]
qd_size = np.linspace(1.5, 7, 100)
band_i = "VB1"; band_f = "CB1"
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.figure(figsize=(10,7))
res_df = pd.DataFrame()
res_df["QSize"] = qd_size
for index_i, eg_i in enumerate(Eg):
    Vcb, Vvb = V_offset(eg_i, 0.4, 0.5)
    for index, me_i in enumerate(me):
        results=[]
        for qd_size_i in qd_size:
            ## Calculate
            run_i+=1
            update_step(run_i, 3*5*100)
            qd1 = qbd.qd_results(qd_size_i, Vvb, me_i, me_i, band_i)
            qd2 = qbd.qd_results(qd_size_i, Vcb, me_i, me_i, band_f)
            try:
                trn = ab.interband_transition_elements(qd1, qd2, (sim_size, lat_size, eg_i, (Pl, Pt)), count=1)[0][0]
            except IndexError:
                trn = np.nan
            results.append(trn)
        res_df[f"{eg_i=}_{me_i=}"] = results
        plt.plot(qd_size, results, colors[index_i], linestyle=lt_list[index], label=f"{eg_i}/{me_i}")
res_df.to_csv("QDEg_QSize.csv", sep=" ", index=False)
plt.plot(qd_size, 0.41+1/(0.0252*(2*qd_size)**2+0.283*(2*qd_size)), '-.', label="Empirical")
plt.legend(bbox_to_anchor=(1,1), loc="upper left")
plt.show()
232/11: res_df
232/12: res_df.to_csv("QDEg_QSize.csv", sep=" ", index=False, na_rep="NaN")
234/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
234/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
234/3:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
234/4:
logging.basicConfig()
logging.getLogger().setLevel(logging.DEBUG)
234/5:
# Function to determine the transition element for a particular set of QD_Properties
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    qd2_size, Vvb, mh, mh = qd2_prop
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.DEBUG(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.DEBUG(band_list)
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.DEBUG(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/6:
# Function to determine the transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    qd2_size, Vvb, mh, mh = qd2_prop
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.DEBUG(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.DEBUG(band_list)
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.DEBUG(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/7:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    qd2_size, Vvb, mh, mh = qd2_prop
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.DEBUG(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.DEBUG(band_list)
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.DEBUG(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/8:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt))
234/9:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/10:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    qd2_size, Vvb, mh, mh = qd2_prop
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.DEBUG(b_i, b_f)
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.DEBUG(band_list)
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.DEBUG(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/11:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/12:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    qd2_size, Vvb, mh, mh = qd2_prop
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.DEBUG(b_i)
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.DEBUG(band_list)
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.DEBUG(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/13:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/14:
me = np.linspace(0.05, 0.15, 100)
for me_i in me:
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
234/15:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    qd2_size, Vvb, mh, mh = qd2_prop
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        print(b_i)
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.DEBUG(band_list)
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.DEBUG(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/16:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/17:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    qd2_size, Vvb, mh, mh = qd2_prop
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.DEBUG(f"b_i={b_i}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.DEBUG(band_list)
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.DEBUG(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/18:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/19:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""
    logging.DEBUG("Starting...")
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    qd2_size, Vvb, mh, mh = qd2_prop
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.DEBUG(f"b_i={b_i}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.DEBUG(band_list)
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.DEBUG(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/20:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/21:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    qd2_size, Vvb, mh, mh = qd2_prop
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"b_i={b_i}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.debug(band_list)
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.debug(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/22:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/23:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug("{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug("{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"b_i={b_i}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.debug(band_list)
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.debug(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/24:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/25:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"b_i={b_i}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.debug(band_list)
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.debug(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/26:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/27:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.debug(band_list)
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.debug(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/28:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/29:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.debug(f"{band_list=}")
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.debug(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/30:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/31:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    logging.debug(f"{band_list=}\n length: {len(band_list)}")
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.debug(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/32:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/33:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        logging.debug(f"{band=}")
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*b_i[trn][1][1]**2 + np.pi/2*b_i[trn][1][2]**2
        band_element.append(band_trn)
    logging.debug(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/34:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/35:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        logging.debug(f"{band=}")
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*band[trn][1][1]**2 + np.pi/2*band[trn][1][2]**2
        band_element.append(band_trn)
    logging.debug(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/36:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/37:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_list = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        band_list.append(ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1))
    # Determine the overall avg_trn
    band_element = []
    for band in band_list:
        logging.debug(f"{band=}")
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*band[trn][1][1]**2 + np.pi/2*band[trn][1][2]**2
        band_element.append(band_trn)
    logging.debug(band_element)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_element = np.array(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    return band_list
234/38:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_element = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1)
        logging.debug(f"{transition=}")
        band_trn = np.pi/4*band[trn][1][0]**2 + np.pi/4*band[trn][1][1]**2 + np.pi/2*band[trn][1][2]**2
        band_element.append(band_trn)
    logging.debug(band_element)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_element = np.array(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    band_element_zeros = band_element < 10e-5
    # Check if the mask does not sum to 0 and determine the average
    if False in band_element_zeros:
        avg_trn_final = np.average(avg_trn, weights=mx_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
234/39:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/40:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_element = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1)
        logging.debug(f"{transition=}")
        band_trn = np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
        band_element.append(band_trn)
    logging.debug(band_element)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_element = np.array(band_element)
    avg_trn = (band_trn[0]+angular_elements[1]+angular_elements[2]+angular_elements[3])/4
    band_element_zeros = band_element < 10e-5
    # Check if the mask does not sum to 0 and determine the average
    if False in band_element_zeros:
        avg_trn_final = np.average(avg_trn, weights=mx_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
234/41:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/42:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_element = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
        band_element.append(band_trn)
    logging.debug(band_element)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_element = np.array(band_element)
    band_element_zeros = band_element < 1e-5
    # Check if the mask does not sum to 0 and determine the average
    if False in band_element_zeros:
        avg_trn_final = np.average(avg_trn, weights=mx_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
234/43:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/44:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_element = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
        band_element.append(band_trn)
    logging.debug(band_element)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_element = np.array(band_element)
    band_element_zeros = band_element < 1e-5
    # Check if the mask does not sum to 0 and determine the average
    if False in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
234/45:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/46:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
        band_elements.append(band_trn)
    logging.debug(band_element)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_element < 1e-5
    # Check if the mask does not sum to 0 and determine the average
    if False in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
234/47:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/48:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
        band_elements.append(band_trn)
    logging.debug(band_elements)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements < 1e-5
    # Check if the mask does not sum to 0 and determine the average
    if False in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
234/49:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/50:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
        band_elements.append(band_trn)
    logging.debug(band_elements)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements < 1e-5
    logging.debug(f"{band_element_zeros=}")
    # Check if the mask does not sum to 0 and determine the average
    if False in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
234/51:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/52:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
        band_elements.append(band_trn)
    logging.debug(band_elements)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements > 1e-5
    logging.debug(f"{band_element_zeros=}")
    # Check if the mask does not sum to 0 and determine the average
    if True in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
234/53:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/54:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
        band_elements.append(band_trn)
    logging.debug(band_elements)
    band_elements=[1e-5, 1e-6, 1e-7, 1e-8]
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements > 10e-5
    logging.debug(f"{band_element_zeros=}")
    # Check if the mask does not sum to 0 and determine the average
    if True in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
234/55:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/56:
me = np.linspace(0.05, 0.15, 100)
for me_i in me:
    qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, b_i)
    qd2 = qbd.qd_results(qd_size, Vcb, me, me, b_f)
234/57:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
        band_elements.append(band_trn)
    logging.debug(band_elements)
    band_elements=[1e-5, 1e-6, 1e-7, 1e-8, 10e-5]
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements > 10e-5
    logging.debug(f"{band_element_zeros=}")
    # Check if the mask does not sum to 0 and determine the average
    if True in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
234/58:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/59: print(10e-5)
234/60:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
        band_elements.append(band_trn)
    logging.debug(band_elements)
    band_elements=[1e-3, 1e-5, 1e-6, 1e-7, 1e-8, 10e-5]
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements > 10e-5
    logging.debug(f"{band_element_zeros=}")
    # Check if the mask does not sum to 0 and determine the average
    if True in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
234/61:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/62:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """Calculate stuff"""    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
        band_elements.append(band_trn)
    logging.debug(band_elements)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements > 10e-5
    logging.debug(f"{band_element_zeros=}")
    # Check if the mask does not sum to 0 and determine the average
    if True in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
234/63:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
trn_element_averaged((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
234/64:
# Function to determine the averaged transition element for a particular set of QD_Properties
def trn_element_averaged(qd1_prop, qd2_prop, sim_properties, trn=1):
    """
    Function to determine the averaged transition element for a particular set
    of QD Properties
    """    
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties, count=trn+1)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
        band_elements.append(band_trn)
    logging.debug(band_elements)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements > 10e-5
    logging.debug(f"{band_element_zeros=}")
    # Check if the mask does not sum to 0 and determine the average
    if True in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
234/65:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
237/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
237/2:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
237/3:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
238/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
238/2:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
238/3:
logging.basicConfig()
logging.getLogger().setLevel(logging.DEBUG)
238/4:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
tea((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
238/5:
Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15; Eg = 2.3;
ate((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
238/6:
# Global properties
bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
238/7:
# Example usage of the avg_trn_elements script
ate((3, 1, 0.08, 0.08), (3, 1, 0.08, 0.08), (sim_size, lat_size, Eg, (Pl, Pt)))
238/8:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
238/9:
me = np.linspace(0.05, 0.15, 100)
me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = []
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    result = ate(qd1_prop, qd2_prop, sim_properties)
    final.append(results)
print(final)
238/10:
me = np.linspace(0.05, 0.15, 100)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = []
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    result = ate(qd1_prop, qd2_prop, sim_properties)
    final.append(results)
print(final)
238/11:
me = np.linspace(0.05, 0.15, 100)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = []
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    result = ate(qd1_prop, qd2_prop, sim_properties)
    final.append(result)
print(final)
238/12:
logging.basicConfig()
logging.getLogger().setLevel(logging.INFO)
238/13:
me = np.linspace(0.05, 0.15, 100)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = []
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    result = ate(qd1_prop, qd2_prop, sim_properties)
    final.append(result)
print(final)
238/14:
# me
# me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
# Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
# export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
# m_values = list()
# param = np.linspace(0.05, 0.15, n_param)

# for me in param:
#     run_i += 1
#     update_step(run_i, n_param)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     # Calculate the QD classes
#     qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
#     qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
#     # Also determine the time to run a particular simulation
#     start = timeit.default_timer()
#     transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
#     stop = timeit.default_timer()
#     m_values.append((transitions, stop-start, len(transitions)))
                    
# exec_time = np.array([m_value[1] for m_value in m_values])
# Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
# My = np.array([m_value[0][transition][1][1] for m_value in m_values])
# Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
# n_trn = np.array([m_value[2] for m_value in m_values])
# # Export the results using a DataFrame
# pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_me"), sep=" ")
# pd.DataFrame(My, index=param).to_csv(export_name("My_me"), sep=" ")
# pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_me"), sep=" ")
# pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_me"), sep=" ")
# pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_me"), sep=" ")
238/15:
# # mh
# me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
# Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
# export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
# m_values = list()
# param = np.linspace(0.05, 0.15, n_param)

# for mh in param:
#     run_i += 1
#     update_step(run_i, n_param)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     # Calculate the QD classes
#     qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
#     qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
#     # Also determine the time to run a particular simulation
#     start = timeit.default_timer()
#     transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
#     stop = timeit.default_timer()
#     m_values.append((transitions, stop-start, len(transitions)))
                    
# exec_time = np.array([m_value[1] for m_value in m_values])
# Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
# My = np.array([m_value[0][transition][1][1] for m_value in m_values])
# Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
# n_trn = np.array([m_value[2] for m_value in m_values])
# # Export the results using a DataFrame
# pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_mh"), sep=" ")
# pd.DataFrame(My, index=param).to_csv(export_name("My_mh"), sep=" ")
# pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_mh"), sep=" ")
# pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_mh"), sep=" ")
# pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_mh"), sep=" ")
238/16:
# Pt
# me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
# Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
# export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
# m_values = list()
# param = np.linspace(1e-25, 1e-24, n_param)

# for Pt in param:
#     run_i += 1
#     update_step(run_i, n_param)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     # Calculate the QD classes
#     qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
#     qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
#     # Also determine the time to run a particular simulation
#     start = timeit.default_timer()
#     transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
#     stop = timeit.default_timer()
#     m_values.append((transitions, stop-start, len(transitions)))
                    
# exec_time = np.array([m_value[1] for m_value in m_values])
# Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
# My = np.array([m_value[0][transition][1][1] for m_value in m_values])
# Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
# n_trn = np.array([m_value[2] for m_value in m_values])
# # Export the results using a DataFrame
# pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_Pt"), sep=" ")
# pd.DataFrame(My, index=param).to_csv(export_name("My_Pt"), sep=" ")
# pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_Pt"), sep=" ")
# pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_Pt"), sep=" ")
# pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_Pt"), sep=" ")
238/17:
# # Pl
# me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
# Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
# export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
# m_values = list()
# param = np.linspace(1e-25, 1e-24, n_param)

# for Pl in param:
#     run_i += 1
#     update_step(run_i, n_param)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     # Calculate the QD classes
#     qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
#     qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
#     # Also determine the time to run a particular simulation
#     start = timeit.default_timer()
#     transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
#     stop = timeit.default_timer()
#     m_values.append((transitions, stop-start, len(transitions)))
                    
# exec_time = np.array([m_value[1] for m_value in m_values])
# Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
# My = np.array([m_value[0][transition][1][1] for m_value in m_values])
# Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
# n_trn = np.array([m_value[2] for m_value in m_values])
# # Export the results using a DataFrame
# pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_Pl"), sep=" ")
# pd.DataFrame(My, index=param).to_csv(export_name("My_Pl"), sep=" ")
# pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_Pl"), sep=" ")
# pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_Pl"), sep=" ")
# pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_Pl"), sep=" ")
238/18:
# #Qsize
# me = 0.08; mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
# Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
# export_name = lambda name: f"Article_2_Results/{name}_t{transition}_{band_i}_{band_f}.csv"
# m_values = list()
# param = np.linspace(2, 7, n_param)

# for qd_size in param:
#     run_i += 1
#     update_step(run_i, n_param)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     # Calculate the QD classes
#     qd1 = qbd.qd_results(qd_size, Vvb, mh, mh, band_i)
#     qd2 = qbd.qd_results(qd_size, Vcb, me, me, band_f)
#     # Also determine the time to run a particular simulation
#     start = timeit.default_timer()
#     transitions = ab.interband_transition_elements(qd1, qd2, sim_properties)
#     stop = timeit.default_timer()
#     m_values.append((transitions, stop-start, len(transitions)))
                    
# exec_time = np.array([m_value[1] for m_value in m_values])
# Mx = np.array([m_value[0][transition][1][0] for m_value in m_values])
# My = np.array([m_value[0][transition][1][1] for m_value in m_values])
# Mz = np.array([m_value[0][transition][1][2] for m_value in m_values])
# n_trn = np.array([m_value[2] for m_value in m_values])
# # Export the results using a DataFrame
# pd.DataFrame(Mx, index=param).to_csv(export_name("Mx_QSize"), sep=" ")
# pd.DataFrame(My, index=param).to_csv(export_name("My_QSize"), sep=" ")
# pd.DataFrame(Mz, index=param).to_csv(export_name("Mz_QSize"), sep=" ")
# pd.DataFrame(exec_time, index=param).to_csv(export_name("ETime_QSize"), sep=" ")
# pd.DataFrame(n_trn, index=param).to_csv(export_name("NTrn_QSize"), sep=" ")
238/19: plt.plot(me, final)
239/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
239/2:
logging.basicConfig()
logging.getLogger().setLevel(logging.INFO)
239/3:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
239/4:
me = np.linspace(0.05, 0.15, 100)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = []
individual_trn = [[], [], [], []]
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    result, band_trn = ate(qd1_prop, qd2_prop, sim_properties)
    final.append(result)
    individual_trn[0].append(band_trn[0])
    individual_trn[1].append(band_trn[1])
    individual_trn[2].append(band_trn[2])
    individual_trn[3].append(band_trn[3])
plt.plot(me, final)
plt.plot(me, individual_trn[0], '-r')
plt.plot(me, individual_trn[1], '-g')
plt.plot(me, individual_trn[2], '-lightcoral')
plt.plot(me, individual_trn[3], '-gold')
239/5:
me = np.linspace(0.05, 0.15, 3)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = []
individual_trn = [[], [], [], []]
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    result, band_trn = ate(qd1_prop, qd2_prop, sim_properties)
    final.append(result)
    individual_trn[0].append(band_trn[0])
    individual_trn[1].append(band_trn[1])
    individual_trn[2].append(band_trn[2])
    individual_trn[3].append(band_trn[3])
plt.plot(me, final)
plt.plot(me, individual_trn[0], '-r')
plt.plot(me, individual_trn[1], '-g')
plt.plot(me, individual_trn[2], '-lightcoral')
plt.plot(me, individual_trn[3], '-gold')
239/6:
me = np.linspace(0.05, 0.15, 3)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = []
individual_trn = [[], [], [], []]
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    result, band_trn = ate(qd1_prop, qd2_prop, sim_properties)
    final.append(result)
    individual_trn[0].append(band_trn[0])
    individual_trn[1].append(band_trn[1])
    individual_trn[2].append(band_trn[2])
    individual_trn[3].append(band_trn[3])
plt.plot(me, final)
plt.plot(me, individual_trn[0], '--r')
plt.plot(me, individual_trn[1], '--g')
plt.plot(me, individual_trn[2], 'lightcoral', linestyle='--')
plt.plot(me, individual_trn[3], 'gold', linestyle='--')
239/7:
me = np.linspace(0.05, 0.15, 100)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = []
individual_trn = [[], [], [], []]
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    result, band_trn = ate(qd1_prop, qd2_prop, sim_properties)
    final.append(result)
    individual_trn[0].append(band_trn[0])
    individual_trn[1].append(band_trn[1])
    individual_trn[2].append(band_trn[2])
    individual_trn[3].append(band_trn[3])
plt.plot(me, final)
plt.plot(me, individual_trn[0], '--r')
plt.plot(me, individual_trn[1], '--g')
plt.plot(me, individual_trn[2], 'lightcoral', linestyle='--')
plt.plot(me, individual_trn[3], 'gold', linestyle='--')
239/8:
me = np.linspace(0.05, 0.15, 100)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = []
individual_trn = [[], [], [], []]
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    result, band_trn = ate(qd1_prop, qd2_prop, sim_properties)
    final.append(result)
    individual_trn[0].append(band_trn[0])
    individual_trn[1].append(band_trn[1])
    individual_trn[2].append(band_trn[2])
    individual_trn[3].append(band_trn[3]+0.01)
plt.plot(me, final)
plt.plot(me, individual_trn[0], '--r')
plt.plot(me, individual_trn[1], '--g')
plt.plot(me, individual_trn[2], 'lightcoral', linestyle='--')
plt.plot(me, individual_trn[3], 'gold', linestyle='--')
240/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
240/2:
logging.basicConfig()
logging.getLogger().setLevel(logging.INFO)
240/3:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
240/4: np.ones(shape=(1, 4, 3))
240/5:
a = np.ones(shape=(1, 4, 3))
a[0]
a[0][0]
240/6:
a = np.ones(shape=(1, 4, 3))
a[0]
240/7:
a = np.ones(shape=(4, 3))
a[0]
240/8:
a = np.ones(shape=(4, 3))
a[0][0]
240/9: np.ones(shape=(100,4))
240/10: np.ones(shape=(100,4))[0]
240/11:
n_points=3
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_elements[i] = np.array(avg_trn)

plt.plot(me, final)
plt.plot(me, individual_trn[0], '--r')
plt.plot(me, individual_trn[1], '--g')
plt.plot(me, individual_trn[2], 'lightcoral', linestyle='--')
plt.plot(me, individual_trn[3], 'gold', linestyle='--')
240/12: np.ones(shape=(100,4))[0]
240/13: np.ones(shape=(100,4))[0] = np.array([1, 2, 3, 4])
240/14:
a = np.ones(shape=(100,4))[0]
a[0] = np.array([1, 2, 3, 4])
a
240/15:
a = np.ones(shape=(100,4))[0]
a[0]
a
240/16:
a = np.ones(shape=(100,4))[0]
a[0] = np.array([1, 2, 3, 4])
a
240/17:
a = np.ones(shape=(100,4))[0]
a[0] = [1, 2, 3, 4]
a
240/18:
a = np.ones(shape=(100,4))[0]
a[0:] = np.array([1, 2, 3, 4])
a
240/19:
a = np.ones(shape=(100,4))[0]
a[0] = np.array([1, 2, 3, 4])
a
240/20:
a = np.ones(shape=(100,4))[0]
a[0] = np.array([1, 2, 3, 4])[:, np.newaxis]
a
240/21:
a = np.ones(shape=(100,4))[0]
print(a[0])
a[0] = np.array([1, 2, 3, 4])[:, np.newaxis]
a
240/22:
a = np.ones(shape=(100,4))
print(a)
a[0] = np.array([1, 2, 3, 4])[:, np.newaxis]
a
240/23:
a = np.ones(shape=(100,4))
a[0] = np.array([1, 2, 3, 4])
a
240/24:
n_points=3
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)

plt.plot(me, final)
plt.plot(me, individual_trn[0], '--r')
plt.plot(me, individual_trn[1], '--g')
plt.plot(me, individual_trn[2], 'lightcoral', linestyle='--')
plt.plot(me, individual_trn[3], 'gold', linestyle='--')
240/25:
n_points=3
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,3))
individual_elements = np.ones(shape=(n_points, 4, 2))
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)

plt.plot(me, final)
plt.plot(me, individual_trn[0], '--r')
plt.plot(me, individual_trn[1], '--g')
plt.plot(me, individual_trn[2], 'lightcoral', linestyle='--')
plt.plot(me, individual_trn[3], 'gold', linestyle='--')
240/26:
n_points=3
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    print(trn_elements)

plt.plot(me, final)
plt.plot(me, individual_trn[0], '--r')
plt.plot(me, individual_trn[1], '--g')
plt.plot(me, individual_trn[2], 'lightcoral', linestyle='--')
plt.plot(me, individual_trn[3], 'gold', linestyle='--')
240/27:
n_points=3
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)

plt.plot(me, final)
plt.plot(me, individual_trn[0], '--r')
plt.plot(me, individual_trn[1], '--g')
plt.plot(me, individual_trn[2], 'lightcoral', linestyle='--')
plt.plot(me, individual_trn[3], 'gold', linestyle='--')
240/28:
n_points=3
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)

print(final)
print(individual_trn)
print(individual_elements)
240/29:
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[i], linestyle='--')
plt.plot(me, individual_trn[0], '--r')
plt.plot(me, individual_trn[1], '--g')
plt.plot(me, individual_trn[2], 'lightcoral', linestyle='--')
plt.plot(me, individual_trn[3], 'gold', linestyle='--')
240/30:
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], linestyle='--')
plt.plot(me, individual_trn[0], '--r')
plt.plot(me, individual_trn[1], '--g')
plt.plot(me, individual_trn[2], 'lightcoral', linestyle='--')
plt.plot(me, individual_trn[3], 'gold', linestyle='--')
240/31:
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], linestyle='--')
240/32:
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], linestyle='--')
    for j in range(3):
        plt.plot(me, individual_elements[i, :, j])
240/33: individual_elements.shape
240/34:
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], linestyle='--')
    for j in range(3):
        plt.plot(me, individual_elements[:, i, j])
240/35:
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['-', '--', '-.', ':']
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], colors[i], linestyle='--')
    for j in range(3):
        plt.plot(me, individual_elements[:, i, j], colors[i], linestyle=lt_list[j])
240/36:
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['--', '-.', ':']
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], colors[i], linestyle='-')
    for j in range(3):
        plt.plot(me, individual_elements[:, i, j], colors[i], linestyle=lt_list[j])
240/37:
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['--', '-.', ':']
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], colors[i], linestyle='-')
    for j in range(3):
        plt.plot(me, individual_elements[:, i, j], colors[i], linestyle=lt_list[j])
plt.yscale('log')
plt.show()
240/38:
n_points=100
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))
for i, me_i in enumerate(me):
    update_step(i, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
240/39:
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['--', '-.', ':']
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], colors[i], linestyle='-')
    for j in range(3):
        plt.plot(me, individual_elements[:, i, j], colors[i], linestyle=lt_list[j])
plt.yscale('log')
plt.show()
240/40:
plt.figure(figsize=(7,7))
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['--', '-.', ':']
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], colors[i], linestyle='-')
    for j in range(3):
        plt.plot(me, individual_elements[:, i, j], colors[i], linestyle=lt_list[j])
plt.yscale('log')
plt.show()
240/41:
plt.figure(figsize=(10,7))
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['--', '-.', ':']
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], colors[i], linestyle='-')
    for j in range(3):
        plt.plot(me, individual_elements[:, i, j], colors[i], linestyle=lt_list[j])
plt.yscale('log')
plt.show()
240/42:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0
# Arrays to store the final results
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, 100)
    logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(2, 10, n_param), 1)):
    update_step(i+1, 100)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
240/43:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0
# Arrays to store the final results
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(2, 10, n_param), 1)):
    update_step(i+1, 100)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
240/44: a = np.zeros(shape=(2, 4, 10))
240/45:
a = np.zeros(shape=(2, 4, 10))
a
240/46:
a = np.zeros(shape=(2, 4, 10))
a[0] = np.NaN
240/47:
a = np.zeros(shape=(2, 4, 10))
a[0] = np.NaN
a
240/48:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
print()
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(2, 10, n_param), 1)):
    update_step(i+1, 100)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
240/49:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
print()
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(2, 10, n_param), 1)):
    update_step(i+1, 100)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
240/50:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
print()
logging.info(f"{total_avg=}")
logging.info(f"{individual_trn=}")
logging.info(f"{individual_elements=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
print()
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
print()
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(2, 10, n_param), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
240/51:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
print()
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    print(avg_trn)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
print()
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
print()
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(2, 10, n_param), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
240/52:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
print()
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
print()
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
print()
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
print()
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(2, 10, n_param), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
240/53:
logging.basicConfig()
logging.getLogger().setLevel(logging.DEBUG)
240/54:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(2, 10, n_param), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
240/55:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
logging.info(f"{me=} {mh=} {Vcb=} {Vvb=} {qd_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(2, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
240/56:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
241/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
241/2:
logging.basicConfig()
logging.getLogger().setLevel(logging.DEBUG)
241/3:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
241/4:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
241/5:
n_points=100
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))
for i, me_i in enumerate(me):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
241/6:
plt.figure(figsize=(10,7))
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['--', '-.', ':']
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], colors[i], linestyle='-')
    for j in range(3):
        plt.plot(me, individual_elements[:, i, j], colors[i], linestyle=lt_list[j])
plt.yscale('log')
plt.show()
242/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
242/2:
logging.basicConfig()
logging.getLogger('band_model').setLevel(logging.DEBUG)
242/3:
n_points=100
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))
for i, me_i in enumerate(me):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
242/4:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
242/5:
n_points=100
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))
for i, me_i in enumerate(me):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
242/6:
loger = logging.getLogger("__name__")
loger.setLevel(logging.DEBUG)
logging.getLogger('band_model').setLevel(logging.DEBUG)
242/7:
n_points=100
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))
for i, me_i in enumerate(me):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
242/8: logging.getLogger().setLevel(logging.WARNING)
242/9:
n_points=100
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))
for i, me_i in enumerate(me):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
242/10:
plt.figure(figsize=(10,7))
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['--', '-.', ':']
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], colors[i], linestyle='-')
    for j in range(3):
        plt.plot(me, individual_elements[:, i, j], colors[i], linestyle=lt_list[j])
plt.yscale('log')
plt.show()
242/11: logging.getLogger().setLevel(logging.INFO)
242/12:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
242/13:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
242/14:
plt.figure(figsize=(10,7))
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['--', '-.', ':']
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], colors[i], linestyle='-')
    for j in range(3):
        plt.plot(me, individual_elements[:, i, j], colors[i], linestyle=lt_list[j])
plt.yscale('log')
plt.show()
242/15:
n_points=100
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))
for i, me_i in enumerate(me):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
242/16:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
242/17:
n_points=100
me = np.linspace(0.05, 0.15, n_points)
mh = 0.08; Pt = 4.7e-25; Pl = 3.4e-25; qd_size = 3; lat_size = 0.8; sim_size = 15
Eg = 2.3; Vcb = 0.4; Vvb = 1.5; run_i = 0
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
final = np.zeros_like(me)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))
for i, me_i in enumerate(me):
    update_step(i+1, 100)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    final[i], avg_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    individual_trn[i] = np.array(avg_trn)
    individual_elements[i] = np.array(trn_elements)
242/18:
plt.figure(figsize=(10,7))
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold', 'darkviolet', 'royalblue', 'lime', 'chocolate', 'azure', 'orchid']
lt_list = ['--', '-.', ':']
plt.plot(me, final)
for i in range(4):
    plt.plot(me, individual_trn[:, i], colors[i], linestyle='-')
    for j in range(3):
        plt.plot(me, individual_elements[:, i, j], colors[i], linestyle=lt_list[j])
plt.yscale('log')
plt.show()
242/19:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
242/20:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concactenate((np.linspace(1e-25, 1e-24, n_points).T, total_avg.T, individual_trn, individual_elements))
logging.debud(f"{export_data=}
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
242/21:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concactenate((np.linspace(1e-25, 1e-24, n_points).T, total_avg.T, individual_trn, individual_elements))
logging.debud(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
242/22:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate((np.linspace(1e-25, 1e-24, n_points).T, total_avg.T, individual_trn, individual_elements))
logging.debud(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
242/23:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
print(np.linspace(1e-25, 1e-24, n_points).T.shape, total_avg.T.shape, individual_trn.shape, individual_elements.shape)
export_data = np.concatenate((np.linspace(1e-25, 1e-24, n_points).T, total_avg.T, individual_trn, individual_elements). axis=1)
logging.debud(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
242/24:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
print(np.linspace(1e-25, 1e-24, n_points).T.shape, total_avg.T.shape, individual_trn.shape, individual_elements.shape)
export_data = np.concatenate((np.linspace(1e-25, 1e-24, n_points).T, total_avg.T, individual_trn, individual_elements), axis=1)
logging.debud(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
242/25:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
print(np.linspace(1e-25, 1e-24, n_points)[:, np.newaxiz], total_avg.T[:, np.newaxis], individual_trn.shape, individual_elements.shape)
export_data = np.concatenate((np.linspace(1e-25, 1e-24, n_points)[:, np.newaxiz], total_avg.T[:, np.newaxis], individual_trn, individual_elements), axis=1)
logging.debud(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
242/26:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
print(np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis], total_avg.T[:, np.newaxis], individual_trn.shape, individual_elements.shape)
export_data = np.concatenate((np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis], total_avg.T[:, np.newaxis], individual_trn, individual_elements), axis=1)
logging.debud(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
242/27:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis], total_avg.T[:, np.newaxis], individual_trn),
    axis=1)
logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
242/28:
n_points=5 # Number of points to calculate for each element
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis], total_avg.T[:, np.newaxis], individual_trn, individual_elements.reshape(n_points, 4*3)),
    axis=1)
logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
242/29:
n_points=5 # Number of points to calculate for each element
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN   
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt("asdfad.csv", export_data, header=header)
logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN  
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
242/30:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.WARNING)
logging.getLogger("matplotlib").setLevel(logging.INFO)
242/31:
n_points=5 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, level=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, level=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, level=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, level=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, level=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
242/32:
n_points=5 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
242/33:
n_points=100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
242/34:
n_points=100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
242/35:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.WARNING)
logging.getLogger("matplotlib").setLevel(logging.INFO)
243/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.WARNING)
logging.getLogger("matplotlib").setLevel(logging.INFO)
243/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
243/3:
n_points=100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
243/4:
n_points=100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
243/5:
n_points=100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_trn)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
243/6:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
243/7:
n_points=100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_trn)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
244/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
244/2:
n_points=100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_trn)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
244/3:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
244/4:
n_points=100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_trn)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
244/5:
n_points=100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_trn)
    # if avg_trn.any():
    #     total_avg[i] = avg_trn
    #     individual_trn[i] = np.array(avg_ang_trn)
    #     individual_elements[i] = np.array(trn_elements)
    # else:
    #     total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
245/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
245/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
245/3:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_trn)
    # if avg_trn.any():
    #     total_avg[i] = avg_trn
    #     individual_trn[i] = np.array(avg_ang_trn)
    #     individual_elements[i] = np.array(trn_elements)
    # else:
    #     total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
245/4:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, 0.05, 0.05)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_trn)
    # if avg_trn.any():
    #     total_avg[i] = avg_trn
    #     individual_trn[i] = np.array(avg_ang_trn)
    #     individual_elements[i] = np.array(trn_elements)
    # else:
    #     total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
246/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
246/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
246/3:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_trn)
    # if avg_trn.any():
    #     total_avg[i] = avg_trn
    #     individual_trn[i] = np.array(avg_ang_trn)
    #     individual_elements[i] = np.array(trn_elements)
    # else:
    #     total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
246/4:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_trn)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
246/5:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
246/6:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
246/7:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_trn)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
246/8:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     print(avg_trn)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
246/9:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     print(avg_trn)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_trn)
    # if avg_trn.any():
    #     total_avg[i] = avg_trn
    #     individual_trn[i] = np.array(avg_ang_trn)
    #     individual_elements[i] = np.array(trn_elements)
    # else:
    #     total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
246/10:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     print(avg_trn)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn == 0:
        total_avg[i] = 0
        individual_trn[i] = 0
        individual_elements[i] = 0
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
246/11:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     print(avg_trn)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn == 0:
        total_avg[i] = 0
        individual_trn[i] = 0
        individual_elements[i] = 0
        break
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
246/12:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     print(avg_trn)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn == 0:
        total_avg[i] = 0
        individual_trn[i] = 0
        individual_elements[i] = 0
        continue
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
246/13:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     print(avg_trn)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_ang_trn)
    if avg_trn == 0:
        total_avg[i] = 0
        individual_trn[i] = 0
        individual_elements[i] = 0
        continue
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
246/14:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     print(avg_trn)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_ang_trn)
    if avg_ang_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
246/15: np.array([np.nan, np.nan, np.nan])
246/16:
a = np.array([np.nan, np.nan, np.nan])
a.any()
246/17:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
247/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
247/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
247/3:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     print(avg_trn)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_ang_trn)
    if avg_ang_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
248/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
248/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
248/3:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     print(avg_trn)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_ang_trn)
    if avg_ang_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
248/4:
n_points=5# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     print(avg_trn)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_ang_trn)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
248/5:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.WARNING)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
248/6:
n_points = 100# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     print(avg_trn)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_ang_trn)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
248/7:
n_points = 100# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     print(avg_trn)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# # Calculate for changing mh
# logging.info("Changing mh")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh_i, mh_i)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn.any():
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
248/8:
n_points = 100# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 2  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    print(avg_trn)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
248/9:
n_points = 100# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 2  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
249/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.WARNING)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
249/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
249/3:
n_points = 100# Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 2  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
249/4:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points),
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points),
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.round(np.linspace(1.5, 10, n_points), 1)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.round(np.linspace(1.5, 10, n_points), 1),
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
249/5:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points),
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points),
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points),
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
249/6:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
249/7:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
249/8:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 2  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn.any():
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
249/9:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 2  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
249/10:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
249/11:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels)
for mh_i in np.linspace(0.05, 0.15, 100):
    qd_vb = qbd.qd_results(qd_size, Vvb, mh_i, mh_i, "VB1")
    print(qd_vb.e_levels)
249/12:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels)
for mh_i in np.linspace(0.05, 0.15, 100):
    qd_vb = qbd.qd_results(qd_size, Vvb, mh_i, mh_i, "VB1")
    print(qd_vb.e_levels.values.flatten)
249/13:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels)
for mh_i in np.linspace(0.05, 0.15, 100):
    qd_vb = qbd.qd_results(qd_size, Vvb, mh_i, mh_i, "VB1")
    print(qd_vb.e_levels.values.flatten())
249/14:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for mh_i in np.linspace(0.05, 0.15, 100):
    qd_vb = qbd.qd_results(qd_size, Vvb, mh_i, mh_i, "VB1")
    print("mh_i ",mh_i,"E_Levels", qd_vb.e_levels.values.flatten())
249/15:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for mh_i in np.linspace(0.05, 0.15, 100):
    
    print("mh_i ",mh_i,"E_Levels", qd_vb.e_levels.values.flatten())
249/16:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties)
print(res)
249/17:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for mh_i in np.linspace(0.05, 0.15, 100):
    qd_vb = qbd.qd_results(qd_size, Vvb, mh_i, mh_i, "VB1")
    print("mh_i ",mh_i,"E_Levels", qd_vb.e_levels.values.flatten().sort())
249/18:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for mh_i in np.linspace(0.05, 0.15, 100):
    qd_vb = qbd.qd_results(qd_size, Vvb, mh_i, mh_i, "VB1")
    print("mh_i ",mh_i,"E_Levels", qd_vb.e_levels.values.flatten().sort)
249/19:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for mh_i in np.linspace(0.05, 0.15, 100):
    qd_vb = qbd.qd_results(qd_size, Vvb, mh_i, mh_i, "VB1")
    print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
249/20:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 4)
dtype = [("e_trn": float, "trn_element": tuple)]
res = np.array(res, dtype=dtype)
print(res)
249/21:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 4)
dtype = [("e_trn", float), ("trn_element", tuple)]
res = np.array(res, dtype=dtype)
print(res)
249/22:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 4)
dtype = [("e_trn", float), ("trn_element", tuple)]
res = np.array(res, dtype=dtype)
np.sort(res, order="e_trn")
print(res)
249/23:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 4)
dtype = [("e_trn", float), ("trn_element", tuple)]
res = np.array(res, dtype=dtype)
#np.sort(res, order="e_trn")
print(res)
249/24:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 5)
dtype = [("e_trn", float), ("trn_element", tuple)]
res = np.array(res, dtype=dtype)
#np.sort(res, order="e_trn")
print(res)
249/25:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 5)
dtype = [("e_trn", float), ("trn_element", tuple)]
res = np.array(res, dtype=dtype)
np.sort(res, order="e_trn")
print(res)
249/26:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 5)
dtype = [("e_trn", float), ("trn_element", tuple)]
res = np.array(res, dtype=dtype)
res = np.sort(res, order="e_trn")
print(res)
249/27:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 5)
dtype = [("e_trn", float), ("trn_element", ("mx": float, "my": float, "mz": float))]
res = np.array(res, dtype=dtype)
res = np.sort(res, order="e_trn")
print(res)
249/28:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 5)
dtype = [("e_trn", float), ("trn_element", (("mx", float), ("my", float), ("mz": float)))]
res = np.array(res, dtype=dtype)
res = np.sort(res, order="e_trn")
print(res)
249/29:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 5)
dtype = [("e_trn", float), ("trn_element", (("mx", float), ("my", float), ("mz", float)))]
res = np.array(res, dtype=dtype)
res = np.sort(res, order="e_trn")
print(res)
249/30:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 5)
dtype = [("e_trn", float), ("mx", float), ("my", float), ("mz", float)]
res = np.array(res, dtype=dtype)
res = np.sort(res, order="e_trn")
print(res)
249/31:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 5)
dtype = [("e_trn", float), ("trn_element", tuple)]
res = np.array(res, dtype=dtype)
res = np.sort(res, order="e_trn")
print(res)
250/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.WARNING)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
250/2:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 5)
print(res)
251/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.WARNING)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
251/2:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, 0.1, 0.1, "VB1")
res = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count = 5)
print(res)
251/3:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for mh_i in np.linspace(0.05, 0.15, 100):
    qd_vb = qbd.qd_results(qd_size, Vvb, mh_i, mh_i, "VB1")
    print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
251/4:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for mh_i in np.linspace(0.05, 0.15, 20):
    qd_vb = qbd.qd_results(qd_size, Vvb, mh_i, mh_i, "VB1")
    print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
251/5:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
251/6:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
251/7:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
251/8:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
251/9:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 2  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
251/10:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
251/11:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.WARNING)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
251/12:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
251/13:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
251/14:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
251/15:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
251/16:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
251/17:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for mh_i in np.linspace(0.05, 0.15, 20):
    qd_vb = qbd.qd_results(qd_size, Vvb, mh_i, mh_i, "VB1")
    print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qc_cb, sim_properties))
251/18:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for mh_i in np.linspace(0.05, 0.15, 20):
    qd_vb = qbd.qd_results(qd_size, Vvb, mh_i, mh_i, "VB1")
    print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
251/19:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for mh_i in np.linspace(0.05, 0.15, 20):
    qd_vb = qbd.qd_results(qd_size, Vvb, mh_i, mh_i, "VB1")
    print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
251/20:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for mh_i in np.linspace(0.05, 0.15, 20):
    qd_vb = qbd.qd_results(qd_size, Vvb, mh_i, mh_i, "VB1")
    print(f"\n {mh_i=}")
    print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
251/21:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
251/22:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
252/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.getLogger().setLevel(logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
252/2:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
252/3:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing QSize
# logging.info("Changing QSize")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size_i, Vvb, mh, mh)
#     qd2_prop = (qd_size_i, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1.5, 10, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
252/4:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing QSize
# logging.info("Changing QSize")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size_i, Vvb, mh, mh)
#     qd2_prop = (qd_size_i, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1.5, 10, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
252/5:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcname)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
252/6:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing QSize
# logging.info("Changing QSize")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size_i, Vvb, mh, mh)
#     qd2_prop = (qd_size_i, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1.5, 10, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
253/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcname)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
253/2:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing QSize
# logging.info("Changing QSize")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size_i, Vvb, mh, mh)
#     qd2_prop = (qd_size_i, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1.5, 10, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
253/3:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
253/4:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing QSize
# logging.info("Changing QSize")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size_i, Vvb, mh, mh)
#     qd2_prop = (qd_size_i, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1.5, 10, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
253/5:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
253/6:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing QSize
# logging.info("Changing QSize")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size_i, Vvb, mh, mh)
#     qd2_prop = (qd_size_i, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1.5, 10, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
254/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
254/2:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing QSize
# logging.info("Changing QSize")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size_i, Vvb, mh, mh)
#     qd2_prop = (qd_size_i, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1.5, 10, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
254/3:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
254/4:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
# logging.info("Changing me")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me_i, me_i)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pl
# logging.info("Changing Pl")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing Pt
# logging.info("Changing Pt")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size, Vvb, mh, mh)
#     qd2_prop = (qd_size, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# # Calculate for changing QSize
# logging.info("Changing QSize")
# logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
# for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
#     update_step(i+1, n_points)
#     qd1_prop = (qd_size_i, Vvb, mh, mh)
#     qd2_prop = (qd_size_i, Vcb, me, me)
#     sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
#     avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
#     if avg_trn > 0:
#         total_avg[i] = avg_trn
#         individual_trn[i] = np.array(avg_ang_trn)
#         individual_elements[i] = np.array(trn_elements)
#     else:
#         total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

# logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
# export_data = np.concatenate(
#     (np.linspace(1.5, 10, n_points)[:, np.newaxis],
#      total_avg.T[:, np.newaxis],
#      individual_trn,
#      individual_elements.reshape(n_points, 4*3)),
#     axis=1)
# np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
254/5:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 10, 20):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    print(f"\n {qd_size_i=}")
    print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
255/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
255/2:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
255/3:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
255/4:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
256/1:
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
256/2:
%load_ext autoreload
%autoreload 2
256/3:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 10, 20):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    print(f"\n {qd_size_i=}")
    print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
256/4:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 10, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
256/5:
%load_ext autoreload
%autoreload 1
from band_model %aimport qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
256/6:
%load_ext autoreload
%autoreload 1
%aimport from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
256/7:
%aimport band_model
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
256/8:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
256/9:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 10, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
256/10:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 10, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
257/1:
%load_ext autoreload
%autoreload 1
257/2:
%aimport band_model
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
257/3:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 10, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
257/4:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
257/5:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
257/6:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
257/7:
%aimport band_model.utils.absorption as ab
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
257/8:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
258/1:
%load_ext autoreload
%autoreload 1
258/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
258/3:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/4:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/5:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/6:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/7:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/8:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/9:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/10:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/11:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/12:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/13:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/14:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/15:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/16:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/17:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/18:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/19:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
print(qd_cb.e_levels.values.flatten())
for qd_size_i in np.linspace(1.5, 4, 2):
    qd_vb = qbd.qd_results(qd_size_i, Vvb, mh, mh, "VB1")
    # print(f"\n {qd_size_i=}")
    # print(qd_vb.e_levels)
    # print("mh_i ",mh_i,"E_Levels", np.sort(qd_vb.e_levels.values.flatten()))
    print(ab.interband_transition_elements(qd_vb, qd_cb, sim_properties))
258/20:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
258/21:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
258/22:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
258/23:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
259/1:
%load_ext autoreload
%autoreload 1
259/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
259/3:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
259/4:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
259/5:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
259/6:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
259/7:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
259/8:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
259/9:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 2  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
259/10:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.6; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 2  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
259/11:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.6; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
259/12:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.6; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
259/13:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.7; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
259/14:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.7; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
259/15:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.7; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 2  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
260/1:
%load_ext autoreload
%autoreload 1
260/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
260/3:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.7; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
260/4:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
260/5:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.7; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/1:
%load_ext autoreload
%autoreload 1
261/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
261/3:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
261/4:
n_points = 100 # Number of points to calculate for each element
# Header to export the data
header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
         " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
# Default values
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.7; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3  # Level to calculate the properties
run_i = 0

# Arrays to store the final results
total_avg = np.zeros(n_points)
individual_trn = np.ones(shape=(n_points,4))
individual_elements = np.ones(shape=(n_points, 4, 3))

# Calculate for changing me
logging.info("Changing me")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me_i, me_i)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN
        
logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"me_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# logging.debug(f"{export_data=}")
# Calculate for changing mh
logging.info("Changing mh")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh_i, mh_i)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"mh_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pl
logging.info("Changing Pl")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pl_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing Pt
logging.info("Changing Pt")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size, Vvb, mh, mh)
    qd2_prop = (qd_size, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"Pt_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 10, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/5:
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/6:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/7:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/8:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/9:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/10:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 2  # Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/11:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.7; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 2  # Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/12:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.7; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/13:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.7; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/14:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0  # Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/15:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1  # Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/16:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 2
# Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/17:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3
# Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/18:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 3
# Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/19:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 2
# Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/20:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 0
# Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/21:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
level = 1
# Level to calculate the properties
# Calculate for changing QSize
logging.info("Changing QSize")
logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
for i, qd_size_i in enumerate(np.linspace(1.5, 5, n_points)):
    update_step(i+1, n_points)
    qd1_prop = (qd_size_i, Vvb, mh, mh)
    qd2_prop = (qd_size_i, Vcb, me, me)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
    if avg_trn > 0:
        total_avg[i] = avg_trn
        individual_trn[i] = np.array(avg_ang_trn)
        individual_elements[i] = np.array(trn_elements)
    else:
        total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
export_data = np.concatenate(
    (np.linspace(1.5, 5, n_points)[:, np.newaxis],
     total_avg.T[:, np.newaxis],
     individual_trn,
     individual_elements.reshape(n_points, 4*3)),
    axis=1)
np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
261/22:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
for me_i in np.linspace(0.05, 0.15, 100):
    qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
    qd_cb.e_levels
261/23:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
for me_i in np.linspace(0.05, 0.15, 100):
    qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
    print(qd_cb.e_levels)
261/24:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
for me_i in np.linspace(0.05, 0.15, 100):
    qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
    print(me_i, qd_cb.e_levels)
261/25:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
for me_i in np.linspace(0.05, 0.15, 100):
    qd_cb = qbd.qd_results(qd_size, Vcb, 0.08, 0.08, "CB1")
    print(me_i, qd_cb.e_levels.values.flatten())
261/26:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
for me_i in np.linspace(0.05, 0.15, 100):
    qd_cb = qbd.qd_results(qd_size, Vcb, me_i, me_i, "CB1")
    print(me_i, qd_cb.e_levels.values.flatten())
261/27:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
level = 3  # Level to calculate the properties
for me_i in np.linspace(0.05, 0.15, 100):
    qd_cb = qbd.qd_results(qd_size, Vcb, me_i, me_i, "CB1")
    qd_vb = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")
    print(f"{me_i = }::{mh = }::{qd_cb.e_levels.values.flatten()}::{qd_vb.e_levels.values.flatten()}")
261/28:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
qd_vb = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")
print(qd_vb.e_levels)
level = 3  # Level to calculate the properties
for me_i in np.linspace(0.05, 0.15, 100):
    qd_cb = qbd.qd_results(qd_size, Vcb, me_i, me_i, "CB1")
    print(f"{me_i = }::{qd_cb.e_levels.values.flatten()}")
261/29:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
qd_vb = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")
print(qd_vb.e_levels)
level = 3  # Level to calculate the properties
for me_i in np.linspace(0.05, 0.15, 50):
    qd_cb = qbd.qd_results(qd_size, Vcb, me_i, me_i, "CB1")
    trn = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count=4)
    print(f"{me_i = }::{qd_cb.e_levels.values.flatten()}")
    print(f"Trn Energy: {trn[0]}\n Trn Elements: {trn[1]}")
261/30:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
qd_vb = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")
print(qd_vb.e_levels)
level = 3  # Level to calculate the properties
for me_i in np.linspace(0.05, 0.15, 50):
    qd_cb = qbd.qd_results(qd_size, Vcb, me_i, me_i, "CB1")
    trn = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count=4)
    print(f"{me_i = }::{qd_cb.e_levels.values.flatten()}")
    print(f"Trn Elements: {trn}")
261/31:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
qd_vb = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")
print(qd_vb.e_levels)
level = 3  # Level to calculate the properties
for me_i in np.linspace(0.05, 0.15, 50):
    qd_cb = qbd.qd_results(qd_size, Vcb, me_i, me_i, "CB1")
    trn = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count=4)
    print(f"{me_i = }::{qd_cb.e_levels.values.flatten()}")
    print(f"Trn Elements: {trn}\n\n")
262/1:
%load_ext autoreload
%autoreload 1
262/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
262/3:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
qd_vb = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")
print(qd_vb.e_levels)
level = 3  # Level to calculate the properties
for me_i in np.linspace(0.05, 0.15, 50):
    qd_cb = qbd.qd_results(qd_size, Vcb, me_i, me_i, "CB1")
    trn = ab.interband_transition_elements(qd_vb, qd_cb, sim_properties, count=4)
    print(f"{me_i = }::{qd_cb.e_levels.values.flatten()}")
    print(f"Trn Elements: {trn}\n\n")
262/4: sleep(3)
262/5:
import time
time.sleep(3)
262/6:
import time
a = 10
time.sleep(3)
print(a)
262/7:
import time
a = 5
time.sleep(3)
print(a)
262/8:
import time
a = 6
time.sleep(3)
print(a)
262/9:
def calculate_props(level, l_size, s_size):
    n_points = 100 # Number of points to calculate for each element
    # Header to export the data
    header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
             " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
    # Default values
    Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = l_size; sim_size = s_size
    me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
        # Arrays to store the final results
    total_avg = np.zeros(n_points)
    individual_trn = np.ones(shape=(n_points,4))
    individual_elements = np.ones(shape=(n_points, 4, 3))

    # Calculate for changing me
    logging.info("Changing me")
    logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
    for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
        update_step(i+1, n_points)
        qd1_prop = (qd_size, Vvb, mh, mh)
        qd2_prop = (qd_size, Vcb, me_i, me_i)
        sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
        avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
        if avg_trn > 0:
            total_avg[i] = avg_trn
            individual_trn[i] = np.array(avg_ang_trn)
            individual_elements[i] = np.array(trn_elements)
        else:
            total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

    logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
    export_data = np.concatenate(
        (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
         total_avg.T[:, np.newaxis],
         individual_trn,
         individual_elements.reshape(n_points, 4*3)),
        axis=1)
    np.savetxt(f"me_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

    # logging.debug(f"{export_data=}")
    # Calculate for changing mh
    logging.info("Changing mh")
    logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
    for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
        update_step(i+1, n_points)
        qd1_prop = (qd_size, Vvb, mh_i, mh_i)
        qd2_prop = (qd_size, Vcb, me, me)
        sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
        avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
        if avg_trn > 0:
            total_avg[i] = avg_trn
            individual_trn[i] = np.array(avg_ang_trn)
            individual_elements[i] = np.array(trn_elements)
        else:
            total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

    logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
    export_data = np.concatenate(
        (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
         total_avg.T[:, np.newaxis],
         individual_trn,
         individual_elements.reshape(n_points, 4*3)),
        axis=1)
    np.savetxt(f"mh_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

    # Calculate for changing Pl
    logging.info("Changing Pl")
    logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
    for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
        update_step(i+1, n_points)
        qd1_prop = (qd_size, Vvb, mh, mh)
        qd2_prop = (qd_size, Vcb, me, me)
        sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
        avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
        if avg_trn > 0:
            total_avg[i] = avg_trn
            individual_trn[i] = np.array(avg_ang_trn)
            individual_elements[i] = np.array(trn_elements)
        else:
            total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

    logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
    export_data = np.concatenate(
        (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
         total_avg.T[:, np.newaxis],
         individual_trn,
         individual_elements.reshape(n_points, 4*3)),
        axis=1)
    np.savetxt(f"Pl_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

    # Calculate for changing Pt
    logging.info("Changing Pt")
    logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
    for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
        update_step(i+1, n_points)
        qd1_prop = (qd_size, Vvb, mh, mh)
        qd2_prop = (qd_size, Vcb, me, me)
        sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
        avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
        if avg_trn > 0:
            total_avg[i] = avg_trn
            individual_trn[i] = np.array(avg_ang_trn)
            individual_elements[i] = np.array(trn_elements)
        else:
            total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

    logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
    export_data = np.concatenate(
        (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
         total_avg.T[:, np.newaxis],
         individual_trn,
         individual_elements.reshape(n_points, 4*3)),
        axis=1)
    np.savetxt(f"Pt_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

    # Calculate for changing QSize
    logging.info("Changing QSize")
    logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
    for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
        update_step(i+1, n_points)
        qd1_prop = (qd_size_i, Vvb, mh, mh)
        qd2_prop = (qd_size_i, Vcb, me, me)
        sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
        avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
        if avg_trn > 0:
            total_avg[i] = avg_trn
            individual_trn[i] = np.array(avg_ang_trn)
            individual_elements[i] = np.array(trn_elements)
        else:
            total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

    logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
    export_data = np.concatenate(
        (np.linspace(1.5, 10, n_points)[:, np.newaxis],
         total_avg.T[:, np.newaxis],
         individual_trn,
         individual_elements.reshape(n_points, 4*3)),
        axis=1)
    np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
262/10:
level = 3  # Level to calculate the properties
l_size = 0.8
s_size = 25
product([0, 1, 2, 3],  [0.7, 0.8], [15, 25])
262/11:
level = 3  # Level to calculate the properties
l_size = 0.8
s_size = 25
data = product([0, 1, 2, 3],  [0.7, 0.8], [15, 25])
print(data)
262/12:
level = 3  # Level to calculate the properties
l_size = 0.8
s_size = 25
data = product([0, 1, 2, 3],  [0.7, 0.8], [15, 25])
print(list(data))
262/13:
level = [0, 1, 2, 3]  # Level to calculate the properties
l_size = [0.7, 0.8]
s_size = [15, 25]
for level_i, l_size_i, s_size_i in product(level, l_size, s_size):
    calculate_props(level_i, l_size_i, s_size_i)
262/14:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
262/15:
level = [0, 1, 2, 3]  # Level to calculate the properties
l_size = [0.7, 0.8]
s_size = [15, 25]
for level_i, l_size_i, s_size_i in product(level, l_size, s_size):
    calculate_props(level_i, l_size_i, s_size_i)
262/16:
level = [0, 1, 2, 3]  # Level to calculate the properties
l_size = [0.7, 0.8]
s_size = [15, 25]
for level_i, l_size_i, s_size_i in product(level, l_size, s_size):
    logging.info(f"Running for: {level_i = }|{l_size_i = }|{s_size_i = }")
    calculate_props(level_i, l_size_i, s_size_i)
263/1:
%load_ext autoreload
%autoreload 1
263/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
263/3:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
263/4:
def calculate_props(level, l_size, s_size):
    n_points = 100 # Number of points to calculate for each element
    # Header to export the data
    header = "Variable TAvg AAvg_VB1_CB1 AAvg_VB1_CB2 AAvgVB2_CB1 AAvgVB2_CB2 Mx_VB1_CB1 My_VB1_CB1 Mz_VB1_CB1"+\
             " Mx_VB1_CB2 My_VB1_CB2 Mz_VB1_CB2 Mx_VB2_CB1 My_VB2_CB1 Mz_VB2_CB1 Mx_VB2_CB2 My_VB2_CB2 Mz_VB2_CB2"
    # Default values
    Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = l_size; sim_size = s_size
    me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
        # Arrays to store the final results
    total_avg = np.zeros(n_points)
    individual_trn = np.ones(shape=(n_points,4))
    individual_elements = np.ones(shape=(n_points, 4, 3))

    # Calculate for changing me
    logging.info("Changing me")
    logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
    for i, me_i in enumerate(np.linspace(0.05, 0.15, n_points)):
        update_step(i+1, n_points)
        qd1_prop = (qd_size, Vvb, mh, mh)
        qd2_prop = (qd_size, Vcb, me_i, me_i)
        sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
        avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
        if avg_trn > 0:
            total_avg[i] = avg_trn
            individual_trn[i] = np.array(avg_ang_trn)
            individual_elements[i] = np.array(trn_elements)
        else:
            total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

    logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
    export_data = np.concatenate(
        (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
         total_avg.T[:, np.newaxis],
         individual_trn,
         individual_elements.reshape(n_points, 4*3)),
        axis=1)
    np.savetxt(f"me_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

    # logging.debug(f"{export_data=}")
    # Calculate for changing mh
    logging.info("Changing mh")
    logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
    for i, mh_i in enumerate(np.linspace(0.05, 0.15, n_points)):
        update_step(i+1, n_points)
        qd1_prop = (qd_size, Vvb, mh_i, mh_i)
        qd2_prop = (qd_size, Vcb, me, me)
        sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
        avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
        if avg_trn > 0:
            total_avg[i] = avg_trn
            individual_trn[i] = np.array(avg_ang_trn)
            individual_elements[i] = np.array(trn_elements)
        else:
            total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

    logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
    export_data = np.concatenate(
        (np.linspace(0.05, 0.15, n_points)[:, np.newaxis],
         total_avg.T[:, np.newaxis],
         individual_trn,
         individual_elements.reshape(n_points, 4*3)),
        axis=1)
    np.savetxt(f"mh_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

    # Calculate for changing Pl
    logging.info("Changing Pl")
    logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
    for i, Pl_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
        update_step(i+1, n_points)
        qd1_prop = (qd_size, Vvb, mh, mh)
        qd2_prop = (qd_size, Vcb, me, me)
        sim_properties = (sim_size, lat_size, Eg, (Pl_i, Pt))
        avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
        if avg_trn > 0:
            total_avg[i] = avg_trn
            individual_trn[i] = np.array(avg_ang_trn)
            individual_elements[i] = np.array(trn_elements)
        else:
            total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

    logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
    export_data = np.concatenate(
        (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
         total_avg.T[:, np.newaxis],
         individual_trn,
         individual_elements.reshape(n_points, 4*3)),
        axis=1)
    np.savetxt(f"Pl_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

    # Calculate for changing Pt
    logging.info("Changing Pt")
    logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
    for i, Pt_i in enumerate(np.linspace(1e-25, 1e-24, n_points)):
        update_step(i+1, n_points)
        qd1_prop = (qd_size, Vvb, mh, mh)
        qd2_prop = (qd_size, Vcb, me, me)
        sim_properties = (sim_size, lat_size, Eg, (Pl, Pt_i))
        avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
        if avg_trn > 0:
            total_avg[i] = avg_trn
            individual_trn[i] = np.array(avg_ang_trn)
            individual_elements[i] = np.array(trn_elements)
        else:
            total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

    logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
    export_data = np.concatenate(
        (np.linspace(1e-25, 1e-24, n_points)[:, np.newaxis],
         total_avg.T[:, np.newaxis],
         individual_trn,
         individual_elements.reshape(n_points, 4*3)),
        axis=1)
    np.savetxt(f"Pt_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)

    # Calculate for changing QSize
    logging.info("Changing QSize")
    logging.info(f"{Eg=} {Pt=} {Pl=} {lat_size=} {sim_size=}")
    for i, qd_size_i in enumerate(np.linspace(1.5, 10, n_points)):
        update_step(i+1, n_points)
        qd1_prop = (qd_size_i, Vvb, mh, mh)
        qd2_prop = (qd_size_i, Vcb, me, me)
        sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
        avg_trn, avg_ang_trn, trn_elements = ate(qd1_prop, qd2_prop, sim_properties, trn=level)
        if avg_trn > 0:
            total_avg[i] = avg_trn
            individual_trn[i] = np.array(avg_ang_trn)
            individual_elements[i] = np.array(trn_elements)
        else:
            total_avg[i] = np.NaN; individual_trn[i] = np.NaN; individual_elements[i] = np.NaN

    logging.debug(f"{total_avg=}\n{individual_trn=}\n{individual_elements=}")
    export_data = np.concatenate(
        (np.linspace(1.5, 10, n_points)[:, np.newaxis],
         total_avg.T[:, np.newaxis],
         individual_trn,
         individual_elements.reshape(n_points, 4*3)),
        axis=1)
    np.savetxt(f"QSize_L{level}_LSize_{lat_size}_SSize_{sim_size}_TAvg_AAvg_Mx_My_Mz.csv", export_data, header=header)
263/5:
level = [0, 1, 2, 3]  # Level to calculate the properties
l_size = [0.65, 0.8]
s_size = [15, 25]
for level_i, l_size_i, s_size_i in product(level, l_size, s_size):
    if level_i = 0.65 && size_i = 15:
        continue
    logging.info(f"Running for: {level_i = }|{l_size_i = }|{s_size_i = }")
    calculate_props(level_i, l_size_i, s_size_i)
263/6:
level = [0, 1, 2, 3]  # Level to calculate the properties
l_size = [0.65, 0.8]
s_size = [15, 25]
for level_i, l_size_i, s_size_i in product(level, l_size, s_size):
    if level_i == 0.65 && size_i == 15:
        continue
    logging.info(f"Running for: {level_i = }|{l_size_i = }|{s_size_i = }")
    calculate_props(level_i, l_size_i, s_size_i)
263/7:
level = [0, 1, 2, 3]  # Level to calculate the properties
l_size = [0.65, 0.8]
s_size = [15, 25]
for level_i, l_size_i, s_size_i in product(level, l_size, s_size):
    if (level_i == 0.65) && (size_i == 15):
        continue
    logging.info(f"Running for: {level_i = }|{l_size_i = }|{s_size_i = }")
    calculate_props(level_i, l_size_i, s_size_i)
263/8:
level = [0, 1, 2, 3]  # Level to calculate the properties
l_size = [0.65, 0.8]
s_size = [15, 25]
for level_i, l_size_i, s_size_i in product(level, l_size, s_size):
    if (level_i == 0.65) and (size_i == 15):
        continue
    logging.info(f"Running for: {level_i = }|{l_size_i = }|{s_size_i = }")
    calculate_props(level_i, l_size_i, s_size_i)
263/9:
level = [0, 1, 2, 3]  # Level to calculate the properties
l_size = [0.65, 0.8]
s_size = [15, 25]
for level_i, l_size_i, s_size_i in product(level, l_size, s_size):
    if (l_size_i == 0.65) and (s_size_i == 15):
        continue
    logging.info(f"Running for: {level_i = }|{l_size_i = }|{s_size_i = }")
    calculate_props(level_i, l_size_i, s_size_i)
264/1:
%load_ext autoreload
%autoreload 1
264/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
264/3:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
qd_cb = qbd.qd_results(qd_size, Vcb, me, me, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")
print(qd_cb.e_levels)
print(qd_vb.e_levels)
results = ab.interband_transition_elements(qd_cb, qd_vb, sim_properties)
print(results)
264/4:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.025):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions """
    transitions = ab.interband_transition_elements(qd_cb, qd_vb, sim_properties)
    magnitude = ate(qd_cb, qd_vb, sim_properties)
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * energy) /
                         (n_index * c * h * e0))
    for (e_i, _), (mag_i, _, _) in zip(transitions, magnitude):
        logging.debug(f"Transition: {e_i = } and {mag_i = }")
264/5:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
qd_cb = qbd.qd_results(qd_size, Vcb, me, me, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")
interband_absorption(np.linspace(0, 1, 100), qd_cb, qd_vb, sim_properties)
264/6:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.025):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions """
    transitions = ab.interband_transition_elements(qd_cb, qd_vb, sim_properties)
    magnitude, _, _ = ate(qd_cb, qd_vb, sim_properties)
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * energy) /
                         (n_index * c * h * e0))
    for (e_i, _), mag_i in zip(transitions, magnitude):
        logging.debug(f"Transition: {e_i = } and {mag_i = }")
264/7:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
qd_cb = qbd.qd_results(qd_size, Vcb, me, me, "CB1")
qd_vb = qbd.qd_results(qd_size, Vvb, mh, mh, "VB1")
interband_absorption(np.linspace(0, 1, 100), qd_cb, qd_vb, sim_properties)
264/8:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = ab.avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
264/9:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = ab.avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
print(data)
264/10:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = ab.avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties, 10000)
print(data)
264/11:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = ab.avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties, 3)
print(data)
264/12:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = ab.avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties, 3)
print(data)
264/13:
def all_avg_trn_elements(qd1_prop, qd2_prop, sim_properties):
    """
    Function to determine all the avg transition elements for 2 qds
    """    
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        # List with all the transitions
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = [ np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
                   for trn in transition]
        band_elements.append(band_trn)
    logging.debug(band_elements)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements > 10e-5
    logging.debug(f"{band_element_zeros=}")
    # Check if the mask does not sum to 0 and determine the average
    if True in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
264/14:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
all_avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
264/15:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
264/16:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
all_avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/1:
%load_ext autoreload
%autoreload 1
265/2:
%aimport band_model.utils.absorption
%aimport logging
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
265/3:
def all_avg_trn_elements(qd1_prop, qd2_prop, sim_properties):
    """
    Function to determine all the avg transition elements for 2 qds
    """    
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        # List with all the transitions
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = [ np.pi/4*transition[trn][1][0]**2 + np.pi/4*transition[trn][1][1]**2 + np.pi/2*transition[trn][1][2]**2
                   for trn in transition]
        band_elements.append(band_trn)
    logging.debug(band_elements)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements > 10e-5
    logging.debug(f"{band_element_zeros=}")
    # Check if the mask does not sum to 0 and determine the average
    if True in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
265/4:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
all_avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/5:
def all_avg_trn_elements(qd1_prop, qd2_prop, sim_properties):
    """
    Function to determine all the avg transition elements for 2 qds
    """    
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        # List with all the transitions
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = [ np.pi/4*trn[1][0]**2 + np.pi/4*trn[1][1]**2 + np.pi/2*trn[1][2]**2
                   for trn in transition]
        band_elements.append(band_trn)
    logging.debug(band_elements)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements > 10e-5
    logging.debug(f"{band_element_zeros=}")
    # Check if the mask does not sum to 0 and determine the average
    if True in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros)
    else:
        avg_trn_final = 0
    return avg_trn_final
265/6:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
all_avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/7:
def all_avg_trn_elements(qd1_prop, qd2_prop, sim_properties):
    """
    Function to determine all the avg transition elements for 2 qds
    """    
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        # List with all the transitions
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = [ np.pi/4*trn[1][0]**2 + np.pi/4*trn[1][1]**2 + np.pi/2*trn[1][2]**2
                   for trn in transition]
        band_elements.append(band_trn)
    logging.debug(band_elements)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements > 10e-5
    logging.debug(f"{band_element_zeros=}")
    # Check if the mask does not sum to 0 and determine the average
    if True in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros, axis=1)
    else:
        avg_trn_final = 0
    return avg_trn_final
265/8:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
all_avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/9:
def all_avg_trn_elements(qd1_prop, qd2_prop, sim_properties):
    """
    Function to determine all the avg transition elements for 2 qds
    """    
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        # List with all the transitions
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = [ np.pi/4*trn[1][0]**2 + np.pi/4*trn[1][1]**2 + np.pi/2*trn[1][2]**2
                   for trn in transition]
        band_elements.append(band_trn)
    logging.debug(band_elements)
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements > 10e-5
    logging.debug(f"{band_element_zeros=}")
    # Check if the mask does not sum to 0 and determine the average
    if True in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros, axis=0)
    else:
        avg_trn_final = 0
    return avg_trn_final
265/10:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
all_avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/11:
def all_avg_trn_elements(qd1_prop, qd2_prop, sim_properties):
    """
    Function to determine all the avg transition elements for 2 qds
    """    
    # Unpack parameters for each QD
    qd1_size, Vvb, mh, mh = qd1_prop
    logging.debug(f"{qd1_size=}\t{Vvb=}\t{mh=}\t{mh=}")
    qd2_size, Vcb, me, me = qd2_prop
    logging.debug(f"{qd2_size=}\t{Vcb=}\t{me=}\t{me=}")
    bi = ["VB1", "VB2"]; bf = ["CB1", "CB2"]
    band_elements = []
    # Create a list with the transition elements for each band transition
    for b_i, b_f in product(bi, bf):
        logging.debug(f"{b_i=} {b_f=}")
        qd1 = qbd.qd_results(qd1_size, Vvb, mh, mh, b_i)
        qd2 = qbd.qd_results(qd2_size, Vcb, me, me, b_f)
        # List with all the transitions
        transition = ab.interband_transition_elements(qd1, qd2, sim_properties)
        logging.debug(f"{transition=}")
        # Average the results of each band transition
        band_trn = [ np.pi/4*trn[1][0]**2 + np.pi/4*trn[1][1]**2 + np.pi/2*trn[1][2]**2
                   for trn in transition]
        band_elements.append(band_trn)
    logging.debug(band_elements)
    e_trn = [ trn[0] for trn in transition ]
    logging.debug(f"{e_trn = }")
    # Convert band_element to a numpy array and do a weighted average, considering a threshold of 1e-5
    band_elements = np.array(band_elements)
    band_element_zeros = band_elements > 10e-5
    logging.debug(f"{band_element_zeros=}")
    # Check if the mask does not sum to 0 and determine the average
    if True in band_element_zeros:
        avg_trn_final = np.average(band_elements, weights=band_element_zeros, axis=0)
    else:
        avg_trn_final = 0
    return e_trn, avg_trn_final
265/12:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
all_avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/13:
# Check if the all_avg_trn_elements calculates everything properly
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.6; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
all_avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/14:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.025):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions
    Args:
        e_array (array): x-array with the energy values
        qd_cb/qd_vb (tuple): (q_size, V, m, m)
        sim_properties (tuple): (Ssize, LSize, Eg, (Pl, Pt))
        n_index (float/array): Array with the refractive index values
        peak_dispersion (float): Dispersion of the absorption peal
    Returns:
        absorption_per_density: final total absorption coefficient per density
        absorption_per_peak: array with absorption coefficient for each peak
    
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * energy) /
                         (n_index * c * h * e0))
    trn_energies, trn_elements = all_avg_trn_elements(qd_cb, qd_vb, sim_properties)
    
    for trn_energie, trn_element in zip(trn_energies, trn_elements):
        logging.debug(f"Transition: {trn_energie = } and {trn_element = }")
265/15:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = ab.avg_trn_elements((qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties, 3)
print(data)
265/16:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0, 1, 100), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
print(data)
265/17:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.025):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions
    Args:
        e_array (array): x-array with the energy values
        qd_cb/qd_vb (tuple): (q_size, V, m, m)
        sim_properties (tuple): (Ssize, LSize, Eg, (Pl, Pt))
        n_index (float/array): Array with the refractive index values
        peak_dispersion (float): Dispersion of the absorption peal
    Returns:
        absorption_per_density: final total absorption coefficient per density
        absorption_per_peak: array with absorption coefficient for each peak
    
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * e_array) /
                         (n_index * c * h * e0))
    trn_energies, trn_elements = all_avg_trn_elements(qd_cb, qd_vb, sim_properties)
    
    for trn_energie, trn_element in zip(trn_energies, trn_elements):
        logging.debug(f"Transition: {trn_energie = } and {trn_element = }")
265/18:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0, 1, 100), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
print(data)
265/19: a = pd.DataFrame()
265/20:
a = pd.DataFrame()
a["asdlkfjalsd"] = np.lisnpace(0, 100, 100)
a
265/21:
a = pd.DataFrame()
a["asdlkfjalsd"] = np.linspace(0, 100, 100)
a
265/22:
a = pd.DataFrame()
a["asdlkfjalsd"] = np.linspace(0, 100, 100)
a["alsdfjla"] = np.linspace(0, 100, 100)
a
265/23:
a = pd.DataFrame()
a["asdlkfjalsd"] = np.linspace(0, 100, 100)
a["alsdfjla"] = np.linspace(0, 100, 100)
a["alsjla"] = np.linspace(0, 200, 100)
a
265/24:
a = pd.DataFrame()
a["asdlkfjalsd"] = np.linspace(0, 100, 100)
a["alsdfjla"] = np.linspace(0, 100, 100)
a["alsjla"] = np.linspace(0, 200, 100)
a="çlasdkjf"
print(f"{a_=_}")
265/25:
a = pd.DataFrame()
a["asdlkfjalsd"] = np.linspace(0, 100, 100)
a["alsdfjla"] = np.linspace(0, 100, 100)
a["alsjla"] = np.linspace(0, 200, 100)
a="çlasdkjf"
print(f"{a =}")
265/26:
a = pd.DataFrame()
a["asdlkfjalsd"] = np.linspace(0, 100, 100)
a["alsdfjla"] = np.linspace(0, 100, 100)
a["alsjla"] = np.linspace(0, 200, 100)
a="çlasdkjf"
print(f"{a=}")
265/27:
a = pd.DataFrame()
a["asdlkfjalsd"] = np.linspace(0, 100, 100)
a["alsdfjla"] = np.linspace(0, 100, 100)
a["alsjla"] = np.linspace(0, 200, 100)
a="çlasdkjf"
print(f"{a}")
265/28:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.025):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions
    Args:
        e_array (array): x-array with the energy values
        qd_cb/qd_vb (tuple): (q_size, V, m, m)
        sim_properties (tuple): (Ssize, LSize, Eg, (Pl, Pt))
        n_index (float/array): Array with the refractive index values
        peak_dispersion (float): Dispersion of the absorption peal
    Returns:
        absorption_per_density: final total absorption coefficient per density
        absorption_per_peak: array with absorption coefficient for each peak
    
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * e_array) /
                         (n_index * c * h * e0))
    trn_energies, trn_elements = all_avg_trn_elements(qd_cb, qd_vb, sim_properties)
    results = pd.DataFrame()
    absoprtion = np.zeros_like(e_array)
    for (index, trn_energy), trn_element in zip(enumerate(trn_energies), trn_elements):
        logging.debug(f"Transition: {trn_energy = } and {trn_element = }")
        # Determine the gaussian approximation of the delta peak
        delta_peak = (1 / (np.sqrt(np.pi) * gauss_dispersion)) * np.exp(-((energy - trn_energy) / gauss_dispersion)** 2)
        results[f"T{index}({trn_energy})"] = delta_peak
        # Absorption (the 1e7 term moves the units to nm3cm-1)
        absorption += 2 * trn_element * constant_fraction * delta * 1e7
    results["Total"] = absorption
    return results
265/29:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.025):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions
    Args:
        e_array (array): x-array with the energy values
        qd_cb/qd_vb (tuple): (q_size, V, m, m)
        sim_properties (tuple): (Ssize, LSize, Eg, (Pl, Pt))
        n_index (float/array): Array with the refractive index values
        peak_dispersion (float): Dispersion of the absorption peal
    Returns:
        absorption_per_density: final total absorption coefficient per density
        absorption_per_peak: array with absorption coefficient for each peak
    
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * e_array) /
                         (n_index * c * h * e0))
    trn_energies, trn_elements = all_avg_trn_elements(qd_cb, qd_vb, sim_properties)
    results = pd.DataFrame()
    absoprtion = np.zeros_like(e_array)
    for (index, trn_energy), trn_element in zip(enumerate(trn_energies), trn_elements):
        logging.debug(f"Transition: {trn_energy = } and {trn_element = }")
        # Determine the gaussian approximation of the delta peak
        delta_peak = (1 / (np.sqrt(np.pi) * gauss_dispersion)) * np.exp(-((energy - trn_energy) / gauss_dispersion)** 2)
        results[f"T{index}({trn_energy})"] = delta_peak
        # Absorption (the 1e7 term moves the units to nm3cm-1)
        absorption += 2 * trn_element * constant_fraction * delta * 1e7
    results["Total"] = absorption
    return results
265/30:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0, 1, 100), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
print(data)
265/31:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.025):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions
    Args:
        e_array (array): x-array with the energy values
        qd_cb/qd_vb (tuple): (q_size, V, m, m)
        sim_properties (tuple): (Ssize, LSize, Eg, (Pl, Pt))
        n_index (float/array): Array with the refractive index values
        peak_dispersion (float): Dispersion of the absorption peal
    Returns:
        absorption_per_density: final total absorption coefficient per density
        absorption_per_peak: array with absorption coefficient for each peak
    
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * e_array) /
                         (n_index * c * h * e0))
    trn_energies, trn_elements = all_avg_trn_elements(qd_cb, qd_vb, sim_properties)
    results = pd.DataFrame()
    absoprtion = np.zeros_like(e_array)
    for (index, trn_energy), trn_element in zip(enumerate(trn_energies), trn_elements):
        logging.debug(f"Transition: {trn_energy = } and {trn_element = }")
        # Determine the gaussian approximation of the delta peak
        delta_peak = (1 / (np.sqrt(np.pi) * peak_dispersion)) * np.exp(-((energy - trn_energy) / peak_dispersion)** 2)
        results[f"T{index}({trn_energy})"] = delta_peak
        # Absorption (the 1e7 term moves the units to nm3cm-1)
        absorption += 2 * trn_element * constant_fraction * delta * 1e7
    results["Total"] = absorption
    return results
265/32:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0, 1, 100), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
print(data)
265/33:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.025):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions
    Args:
        e_array (array): x-array with the energy values
        qd_cb/qd_vb (tuple): (q_size, V, m, m)
        sim_properties (tuple): (Ssize, LSize, Eg, (Pl, Pt))
        n_index (float/array): Array with the refractive index values
        peak_dispersion (float): Dispersion of the absorption peal
    Returns:
        absorption_per_density: final total absorption coefficient per density
        absorption_per_peak: array with absorption coefficient for each peak
    
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * e_array) /
                         (n_index * c * h * e0))
    trn_energies, trn_elements = all_avg_trn_elements(qd_cb, qd_vb, sim_properties)
    results = pd.DataFrame()
    results["Total"] = np.zeros_like(e_array)
    for (index, trn_energy), trn_element in zip(enumerate(trn_energies), trn_elements):
        logging.debug(f"Transition: {trn_energy = } and {trn_element = }")
        # Determine the gaussian approximation of the delta peak
        delta_peak = (1 / (np.sqrt(np.pi) * peak_dispersion)) * np.exp(-((e_array - trn_energy) / peak_dispersion)** 2)
        results[f"T{index}({trn_energy})"] = delta_peak
        # Absorption (the 1e7 term moves the units to nm3cm-1)
        results["Total"] += 2 * trn_element * constant_fraction * delta * 1e7
    return results
265/34:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0, 1, 100), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
print(data)
265/35:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.025):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions
    Args:
        e_array (array): x-array with the energy values
        qd_cb/qd_vb (tuple): (q_size, V, m, m)
        sim_properties (tuple): (Ssize, LSize, Eg, (Pl, Pt))
        n_index (float/array): Array with the refractive index values
        peak_dispersion (float): Dispersion of the absorption peal
    Returns:
        absorption_per_density: final total absorption coefficient per density
        absorption_per_peak: array with absorption coefficient for each peak
    
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * e_array) /
                         (n_index * c * h * e0))
    trn_energies, trn_elements = all_avg_trn_elements(qd_cb, qd_vb, sim_properties)
    results = pd.DataFrame()
    results["Total"] = np.zeros_like(e_array)
    for (index, trn_energy), trn_element in zip(enumerate(trn_energies), trn_elements):
        logging.debug(f"Transition: {trn_energy = } and {trn_element = }")
        # Determine the gaussian approximation of the delta peak
        delta_peak = (1 / (np.sqrt(np.pi) * peak_dispersion)) * np.exp(-((e_array - trn_energy) / peak_dispersion)** 2)
        results[f"T{index}({trn_energy})"] = delta_peak
        # Absorption (the 1e7 term moves the units to nm3cm-1)
        results["Total"] += 2 * trn_element * constant_fraction * delta_peak * 1e7
    return results
265/36:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0, 1, 100), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
print(data)
265/37:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.025):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions
    Args:
        e_array (array): x-array with the energy values
        qd_cb/qd_vb (tuple): (q_size, V, m, m)
        sim_properties (tuple): (Ssize, LSize, Eg, (Pl, Pt))
        n_index (float/array): Array with the refractive index values
        peak_dispersion (float): Dispersion of the absorption peal
    Returns:
        absorption_per_density: final total absorption coefficient per density
        absorption_per_peak: array with absorption coefficient for each peak
    
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * e_array) /
                         (n_index * c * h * e0))
    trn_energies, trn_elements = all_avg_trn_elements(qd_cb, qd_vb, sim_properties)
    results = pd.DataFrame()
    results["Total"] = np.zeros_like(e_array)
    for (index, trn_energy), trn_element in zip(enumerate(trn_energies), trn_elements):
        logging.debug(f"Transition: {trn_energy = } and {trn_element = }")
        # Determine the gaussian approximation of the delta peak
        delta_peak = (1 / (np.sqrt(np.pi) * peak_dispersion)) * np.exp(-((e_array - trn_energy) / peak_dispersion)** 2)
        results[f"T{index}({trn_energy:.3f})"] = delta_peak
        # Absorption (the 1e7 term moves the units to nm3cm-1)
        results["Total"] += 2 * trn_element * constant_fraction * delta_peak * 1e7
    return results
265/38:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0, 1, 100), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
print(data)
265/39:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0, 1, 100), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
plt.plot(data)
265/40:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.025):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions
    Args:
        e_array (array): x-array with the energy values
        qd_cb/qd_vb (tuple): (q_size, V, m, m)
        sim_properties (tuple): (Ssize, LSize, Eg, (Pl, Pt))
        n_index (float/array): Array with the refractive index values
        peak_dispersion (float): Dispersion of the absorption peal
    Returns:
        absorption_per_density: final total absorption coefficient per density
        absorption_per_peak: array with absorption coefficient for each peak
    
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * e_array) /
                         (n_index * c * h * e0))
    trn_energies, trn_elements = all_avg_trn_elements(qd_cb, qd_vb, sim_properties)
    results = pd.DataFrame()
    results["Energy"] = e_array
    results["Total"] = np.zeros_like(e_array)
    for (index, trn_energy), trn_element in zip(enumerate(trn_energies), trn_elements):
        logging.debug(f"Transition: {trn_energy = } and {trn_element = }")
        # Determine the gaussian approximation of the delta peak
        delta_peak = (1 / (np.sqrt(np.pi) * peak_dispersion)) * np.exp(-((e_array - trn_energy) / peak_dispersion)** 2)
        results[f"T{index}({trn_energy:.3f})"] = delta_peak
        # Absorption (the 1e7 term moves the units to nm3cm-1)
        results["Total"] += 2 * trn_element * constant_fraction * delta_peak * 1e7
    return results
265/41:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0, 1, 100), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
plt.plot(data["e_array"], data["Total"])
265/42:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0, 1, 100), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/43: plt.plot(data["Energy"], data["Total"])
265/44:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0, 5, 100), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/45: plt.plot(data["Energy"], data["Total"])
265/46:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0, 2.5, 200), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/47: plt.plot(data["Energy"], data["Total"])
265/48:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.1):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions
    Args:
        e_array (array): x-array with the energy values
        qd_cb/qd_vb (tuple): (q_size, V, m, m)
        sim_properties (tuple): (Ssize, LSize, Eg, (Pl, Pt))
        n_index (float/array): Array with the refractive index values
        peak_dispersion (float): Dispersion of the absorption peal
    Returns:
        absorption_per_density: final total absorption coefficient per density
        absorption_per_peak: array with absorption coefficient for each peak
    
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * e_array) /
                         (n_index * c * h * e0))
    trn_energies, trn_elements = all_avg_trn_elements(qd_cb, qd_vb, sim_properties)
    results = pd.DataFrame()
    results["Energy"] = e_array
    results["Total"] = np.zeros_like(e_array)
    for (index, trn_energy), trn_element in zip(enumerate(trn_energies), trn_elements):
        logging.debug(f"Transition: {trn_energy = } and {trn_element = }")
        # Determine the gaussian approximation of the delta peak
        delta_peak = (1 / (np.sqrt(np.pi) * peak_dispersion)) * np.exp(-((e_array - trn_energy) / peak_dispersion)** 2)
        results[f"T{index}({trn_energy:.3f})"] = delta_peak
        # Absorption (the 1e7 term moves the units to nm3cm-1)
        results["Total"] += 2 * trn_element * constant_fraction * delta_peak * 1e7
    return results
265/49:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0, 2.5, 200), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/50: plt.plot(data["Energy"], data["Total"])
265/51:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.05):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions
    Args:
        e_array (array): x-array with the energy values
        qd_cb/qd_vb (tuple): (q_size, V, m, m)
        sim_properties (tuple): (Ssize, LSize, Eg, (Pl, Pt))
        n_index (float/array): Array with the refractive index values
        peak_dispersion (float): Dispersion of the absorption peal
    Returns:
        absorption_per_density: final total absorption coefficient per density
        absorption_per_peak: array with absorption coefficient for each peak
    
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * e_array) /
                         (n_index * c * h * e0))
    trn_energies, trn_elements = all_avg_trn_elements(qd_cb, qd_vb, sim_properties)
    results = pd.DataFrame()
    results["Energy"] = e_array
    results["Total"] = np.zeros_like(e_array)
    for (index, trn_energy), trn_element in zip(enumerate(trn_energies), trn_elements):
        logging.debug(f"Transition: {trn_energy = } and {trn_element = }")
        # Determine the gaussian approximation of the delta peak
        delta_peak = (1 / (np.sqrt(np.pi) * peak_dispersion)) * np.exp(-((e_array - trn_energy) / peak_dispersion)** 2)
        results[f"T{index}({trn_energy:.3f})"] = delta_peak
        # Absorption (the 1e7 term moves the units to nm3cm-1)
        results["Total"] += 2 * trn_element * constant_fraction * delta_peak * 1e7
    return results
265/52:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0.5, 2.5, 200), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/53: plt.plot(data["Energy"], data["Total"])
265/54:
def interband_absorption(e_array, qd_cb, qd_vb, sim_properties, n_index=2.5, peak_dispersion=0.025):
    """ Calculate the interdand absorption given 2 qds and the simulation conditions
    Args:
        e_array (array): x-array with the energy values
        qd_cb/qd_vb (tuple): (q_size, V, m, m)
        sim_properties (tuple): (Ssize, LSize, Eg, (Pl, Pt))
        n_index (float/array): Array with the refractive index values
        peak_dispersion (float): Dispersion of the absorption peal
    Returns:
        absorption_per_density: final total absorption coefficient per density
        absorption_per_peak: array with absorption coefficient for each peak
    
    """
    # Initialize necessary constants
    # C, J.s, m/s, C^2/(N.m^2) the powers cut in the fraction
    q, h, c, e0 = 1.6022, 6.626, 2.9979, 8.8542
    # Calculate the fraction responsible for the units
    constant_fraction = ((2 * np.pi**2 * q**2 * e_array) /
                         (n_index * c * h * e0))
    trn_energies, trn_elements = all_avg_trn_elements(qd_cb, qd_vb, sim_properties)
    results = pd.DataFrame()
    results["Energy"] = e_array
    results["Total"] = np.zeros_like(e_array)
    for (index, trn_energy), trn_element in zip(enumerate(trn_energies), trn_elements):
        logging.debug(f"Transition: {trn_energy = } and {trn_element = }")
        # Determine the gaussian approximation of the delta peak
        delta_peak = (1 / (np.sqrt(np.pi) * peak_dispersion)) * np.exp(-((e_array - trn_energy) / peak_dispersion)** 2)
        results[f"T{index}({trn_energy:.3f})"] = delta_peak
        # Absorption (the 1e7 term moves the units to nm3cm-1)
        results["Total"] += 2 * trn_element * constant_fraction * delta_peak * 1e7
    return results
265/55:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = interband_absorption(np.linspace(0.5, 2.5, 200), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/56: plt.plot(data["Energy"], data["Total"])
265/57:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = ab.interband_absorption(np.linspace(0.5, 2.5, 200), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/58: plt.plot(data["Energy"], data["Total"])
265/59: data
265/60: data[!"Energy"]
265/61: data["Energy"]
265/62: !data["Energy"]
265/63: data["Energy"]
265/64: data[!data["Energy"]]
265/65: data[data.columns != "Energy"]
265/66: data.loc[data.columns != "Energy"]
265/67: data.loc[:, data.columns != "Energy"]
265/68: plt.plot(data.loc[:, data.columns != "Energy"])
265/69: data.size
265/70: data.shape
265/71:
for i in range(data.shape - 2):
    print(i)
265/72:
for i in range(data.shape[1] - 2):
    print(i)
265/73: data
265/74:
for i in range(data.shape[1] - 2):
    plt.plot(data["Energy"], data.iloc[:, i+2])
265/75: data.max
265/76: data.max()
265/77:
# Check if everything is ok
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
data = ab.interband_absorption(np.linspace(0.5, 2.5, 200), (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/78: plt.plot(data["Energy"], data["Total"])
265/79:
for i in range(data.shape[1] - 2):
    plt.plot(data["Energy"], data.iloc[:, i+2])
265/80: data.max()
265/81: data * 10
265/82: data.loc[:, data.columns != "Energy"]
265/83:
data.loc[:, data.columns != "Energy"]*10
data
265/84:
print(data)
data.loc[:, data.columns != "Energy"]*10
data
265/85:
print(data)
data.loc[:, data.columns != "Energy"] *= 10
data
265/86:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
energy = np.linspace(0.5, 3, 200)

for qd_size_i in np.linspace(1.5, 5, 30):
    data = ab.interband_absorption(energy, (qd_size_i, Vcb, me, me), (qd_size_i, Vvb, mh, mh), sim_properties)
    plt.plot(data["Energy"], data["Total"], label=f"QSize = {qd_size_i}")
plt.legend(bbox_to_anchor = (1.05, 1), ncol=3)
265/87:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
energy = np.linspace(0.5, 3, 200)

for qd_size_i in np.linspace(2, 5, 30):
    data = ab.interband_absorption(energy, (qd_size_i, Vcb, me, me), (qd_size_i, Vvb, mh, mh), sim_properties)
    plt.plot(data["Energy"], data["Total"], label=f"QSize = {qd_size_i}")
plt.legend(bbox_to_anchor = (1.05, 1), ncol=3)
265/88:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
energy = np.linspace(0.5, 3, 200)
data = ab.interband_absorption(energy, (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/89: data
265/90:
%aimport band_model.utils.absorption
%aimport logging
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
265/91: print(data)
265/92:
print(data)
sci.trapz(data["Total"], data["Energy"])
265/93: scc.h*scc.c/data["Energy"]
265/94: scc.h*scc.c*scc.e/data["Energy"]
265/95: scc.h*scc.c/data["Energy"]
265/96: scc.h*scc.c/(data["Energy"]*scc.e)
265/97: scc.h*scc.c/(data["Energy"]*scc.e)*1e2
265/98:
print(data)
sci.trapz(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
265/99: scc.h*scc.c/(data["Energy"]*scc.e)
265/100:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;
sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
energy = np.linspace(1.35, 4, 200)
data = ab.interband_absorption(energy, (qd_size, Vcb, me, me), (qd_size, Vvb, mh, mh), sim_properties)
265/101:
print(data)
sci.trapz(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
265/102: scc.h*scc.c/(data["Energy"]*scc.e)
265/103:
print(data)
sci.trapezoid(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
265/104:
print(data)
sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
265/105:
print(data)
sci.trapezoidal(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
265/106:
print(data)
sci.trapezoid(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
265/107:
print(data)
plt.plot((scc.h*scc.c)/(data["Energy"]*scc.e)*1e2, data["Total"])
sci.trapezoid(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
265/108:
print(data)
plt.plot((scc.h*scc.c)/(data["Energy"]*scc.e), data["Total"])
sci.trapezoid(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
265/109:
print(data)
plt.plot((scc.h*scc.c)/(data["Energy"]*scc.e), data["Total"])
sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
265/110: np.random.uniform(0.5, 0.15)
265/111: np.random.uniform(0.5, 0.15, size=(10))
265/112:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

me = np.random.uniform(0.5, 0.15, size=(10))
mh = np.random.uniform(0.5, 0.15, size=(10))
qd_size = np.random.uniform(1.5, 5, size=(10))
energy = np.linspace(1.35, 4, 200)

integration = []

for me_i, mh_i, qd_size_i in zip(me, mh, qd_size):
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    data = ab.interband_absorption(energy, (qd_size_i, Vcb, me_i, me_i), (qd_size, Vvb, mh_i, mh_i), sim_properties)
    integration_i = sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    integration.append(integration_i)
265/113:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

me = np.random.uniform(0.5, 0.15, size=(10))
mh = np.random.uniform(0.5, 0.15, size=(10))
qd_size = np.random.uniform(1.5, 5, size=(10))
energy = np.linspace(1.35, 4, 200)

integration = []

for me_i, mh_i, qd_size_i in zip(me, mh, qd_size):
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    data = ab.interband_absorption(energy, (qd_size_i, Vcb, me_i, me_i), (qd_size_i, Vvb, mh_i, mh_i), sim_properties)
    integration_i = sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    integration.append(integration_i)
265/114:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

me = np.random.uniform(0.05, 0.15, size=(5))
mh = np.random.uniform(0.05, 0.15, size=(5))
qd_size = np.random.uniform(1.5, 5, size=(5))
energy = np.linspace(1.35, 4, 200)

integration = []

for me_i, mh_i, qd_size_i in zip(me, mh, qd_size):
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    data = ab.interband_absorption(energy, (qd_size_i, Vcb, me_i, me_i), (qd_size_i, Vvb, mh_i, mh_i), sim_properties)
    integration_i = sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    integration.append(integration_i)
265/115: plt.scatter(integration_i)
265/116:
point = np.arange(len(me))
plt.scatter(point, integration_i)
265/117: len(me)
265/118: np.arange(len(me))
265/119:
np.arange(len(me))
integration_i
265/120:
point = np.arange(len(me))
plt.scatter(point, integration)
265/121:
# Scatter plot all the simulated points
point = np.arange(len(me))
plt.scatter(point, integration, 3)
265/122:
# Scatter plot all the simulated points
point = np.arange(len(me))
plt.scatter(point, integration, s=3)
265/123:
# Scatter plot all the simulated points
point = np.arange(len(me))
plt.scatter(point, integration, s=10)
265/124:
# Scatter plot all the simulated points
point = np.arange(len(me))
plt.scatter(point, integration, s=100)
265/125:
# Scatter plot all the simulated points
plt.figure(figsize=(10,10))
point = np.arange(len(me))
plt.scatter(point, integration, s=100)
265/126:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
point = np.arange(len(me))
plt.scatter(point, integration, s=100)
265/127:
Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

me = np.random.uniform(0.05, 0.15, size=(2))
mh = np.random.uniform(0.05, 0.15, size=(2))
qd_size = np.random.uniform(1.5, 5, size=(2))
energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh})
integration = []

for me_i, mh_i, qd_size_i in zip(me, mh, qd_size):
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    data = ab.interband_absorption(energy, (qd_size_i, Vcb, me_i, me_i), (qd_size_i, Vvb, mh_i, mh_i), sim_properties)
    integration_i = sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    integration.append(-integration_i)
rnd_results["Integrate"] = integration
265/128:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
rnd_results.plot.scatter(y="Integrate", use_index=True)
265/129:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
rnd_results.plot(y="Integrate", use_index=True)
265/130: rnd_results
265/131:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
rnd_results.plot(x = rnd_results.index, y="Integrate", use_index=True)
265/132: rnd_results.index
265/133: rnd_results.index()
265/134: rnd_results.index
265/135:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
rnd_results["Integrate"].plot()
265/136:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
rnd_results["Integrate"].scatter()
265/137:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
rnd_results["Integrate"].plot.scatter()
265/138:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
rnd_results["Integrate"].plot('o')
265/139: np.aranage(rnd_results.index)
265/140: range(rnd_results.index)
265/141: rnd_results.index
265/142:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
rnd_results].plot(x = df.index, y = "Integrate")
265/143:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
rnd_results.plot(x = df.index, y = "Integrate")
265/144:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
rnd_results.plot(y = "Integrate")
265/145:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
rnd_results.plot(y = "Integrate", linestyle='o')
265/146: rnd_results["index"]
265/147: rnd_results.index
265/148: rnd_results.index.index_tolist
265/149: rnd_results.index.to_list()
265/150:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
plt.scatter(rnd_results.index.to_list(), rnd_results["Integrate"])
265/151:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
plt.scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
265/152:
%aimport band_model.utils.absorption
%aimport logging
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import warnings
%matplotlib inline
warnings.filterwarnings('ignore')
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
265/153:
dir_prefix = "Article_2_Results"
def update_step(it_num, total_it):
    """Helper function to print the iteration number
    in a for loop"""
    if it_num == total_it:
        print(f"\rIteration {it_num:04d}/{total_it:04d}")
    else:
        print(f"\rIteration {it_num:04d}/{total_it:04d}", end="")
    pass
265/154:
n_rnd = 20

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 25
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1.5, 5, size=(n_rnd))
energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh})
integration = []

for me_i, mh_i, (index, qd_size_i) in zip(me, mh, enumerate(qd_size)):
    update_step(index+1,n_rnd)
    sim_properties = (sim_size, lat_size, Eg, (Pl, Pt))
    data = ab.interband_absorption(energy, (qd_size_i, Vcb, me_i, me_i), (qd_size_i, Vvb, mh_i, mh_i), sim_properties)
    integration_i = sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    integration.append(-integration_i)
rnd_results["Integrate"] = integration
265/155:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
plt.scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
265/156: rnd_results
265/157:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
plt.scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/rnd_results["qd_size"], s=100)
265/158:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
plt.scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/rnd_results["qd_size"]**3, s=100)
265/159:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
plt.scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
265/160:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
plt.scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
plt.scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
265/161:
# Scatter plot all the simulated points
plt.figure(figsize=(10,7))
plt.scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
plt.show()
plt.scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
265/162:
# Scatter plot all the simulated points
ax, fig = plt.subplots(2, 1, figsize=(10, 7))
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
ax[1].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
265/163:
# Scatter plot all the simulated points
ax, fig = plt.subplots(¹, 2, figsize=(10, 7))
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
ax[1].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
265/164:
# Scatter plot all the simulated points
fig, ax = plt.subplots(¹, 2, figsize=(10, 7))
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
ax[1].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
265/165:
# Scatter plot all the simulated points
fig, ax = plt.subplots(1, 2, figsize=(10, 7))
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
ax[1].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
265/166:
# Scatter plot all the simulated points
fig, ax = plt.subplots(1, 2, figsize=(10, 14))
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
ax[1].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
265/167:
# Scatter plot all the simulated points
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
ax[1].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
265/168:
# Scatter plot all the simulated points
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[1].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
266/1:
%aimport band_model.utils.absorption
%aimport logging
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import time
%matplotlib inline
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
266/2:
%load_ext autoreload
%autoreload 1
266/3:
%aimport band_model.utils.absorption
%aimport logging
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import time
%matplotlib inline
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
266/4: a = pd.DataFrame({"as": [1, 2, 3, 4], "ad": [1, 2, 34, 4]})
266/5: a
266/6: a["new"] = 1
266/7:
a["new"] = 1
a
266/8:
a["new"][2] = 1
a
266/9:
a["new"][2] = 2
a
266/10: a = pd.DataFrame({"as": [1, 2, 3, 4], "ad": [1, 2, 34, 4]})
266/11:
a = pd.DataFrame({"as": [1, 2, 3, 4], "ad": [1, 2, 34, 4]})
a
266/12: a["new"][2] = 3
266/13:
n_rnd = 2

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1.5, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size=}  {me=}  {mh=}  {Pl=}  {Pt=}  {Eg=}  {offset=}  {Vcb_i=}  {Vvb_i=}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb, me_i, me_i), (qd_size_i, Vvb, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results["Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results["RunTime"] = end - start
266/14:
n_rnd = 2

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1.5, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=}  {me_i=}  {mh_i=}  {Pl_i=}  {Pt_i=}  {Eg_i=}  {offset_i=}  {Vcb_i=}  {Vvb_i=}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results["Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results["RunTime"] = end - start
266/15:
n_rnd = 2

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1.5, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=.2f}  {me_i=.2f}  {mh_i=.2f}  {Pl_i=.2f}  {Pt_i=.2f}  {Eg_i=.2f}  {offset_i=.2f}  {Vcb_i=.2f}  {Vvb_i=.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results["Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results["RunTime"] = end - start
266/16:
n_rnd = 2

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1.5, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i:.2f=}  {me_i:.2f=}  {mh_i_-2f=}  {Pl_i_.2f=}  {Pt_i:.2f=}  {Eg_i:.2f=}  {offset_i:.2f=}  {Vcb_i:.2f=}  {Vvb_i:.2f=}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results["Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results["RunTime"] = end - start
266/17:
n_rnd = 2

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1.5, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i:.2f=}  {me_i:.2f=}  {mh_i:-2f=}  {Pl_i:.2f=}  {Pt_i:.2f=}  {Eg_i:.2f=}  {offset_i:.2f=}  {Vcb_i:.2f=}  {Vvb_i:.2f=}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results["Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results["RunTime"] = end - start
266/18:
n_rnd = 2

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1.5, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i:.2f=}  {me_i:.2f=}  {mh_i:.2f=}  {Pl_i:.2f=}  {Pt_i:.2f=}  {Eg_i:.2f=}  {offset_i:.2f=}  {Vcb_i:.2f=}  {Vvb_i:.2f=}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results["Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results["RunTime"] = end - start
266/19:
a = 10.1123894710923740
print(f"{a}")
266/20:
a = 10.1123894710923740
print(f"{a=}")
266/21:
a = 10.1123894710923740
print(f"{a:.2f=}")
266/22:
a = 10.1123894710923740
print(f"{a=:.2f}")
266/23:
n_rnd = 2

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1.5, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2f}  {Pt_i=:.2f}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results["Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results["RunTime"] = end - start
266/24: a = np.array([])
266/25:
a = np.array([])
a
266/26: a.shape
266/27: a.shape < (1)
266/28: a.shape < (1,)
266/29:
a = np.array([100])
a
266/30: a.shape < (1,)
266/31:
n_rnd = 2

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1.5, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2f}  {Pt_i=:.2f}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results["Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results["RunTime"] = end - start
266/32:
# Scatter plot all the simulated points
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[1].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
266/33: rnd_results
266/34:
n_rnd = 2

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1.5, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2f}  {Pt_i=:.2f}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results["Integrate"][index] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results["RunTime"][index] = end - start
266/35:
# Scatter plot all the simulated points
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[1].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
266/36: rnd_results
266/37:
n_rnd = 2

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1.5, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2f}  {Pt_i=:.2f}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results.loc[index, "Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results.loc[index, "RunTime"] = end - start
266/38:
# Scatter plot all the simulated points
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[1].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
266/39: rnd_results
266/40:
n_rnd = 2

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1.5, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2f}  {Pt_i=:.2g}  {Eg_i=:.2g}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results.loc[index, "Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results.loc[index, "RunTime"] = end - start
266/41:
n_rnd = 2

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1.5, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results.loc[index, "Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results.loc[index, "RunTime"] = end - start
266/42: rnd_results
266/43:
n_rnd = 200

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results.loc[index, "Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results.loc[index, "RunTime"] = end - start
266/44:
%aimport band_model.utils.absorption
%aimport logging
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import time
%matplotlib inline
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
267/1:
%aimport band_model.utils.absorption
%aimport logging
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import time
%matplotlib inline
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
267/2:
%load_ext autoreload
%autoreload 1
267/3:
%aimport band_model.utils.absorption
%aimport logging
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import time
%matplotlib inline
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
267/4:
n_rnd = 200

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results.loc[index, "Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results.loc[index, "RunTime"] = end - start
267/5:
a = np.array([[],[],[]])
a
267/6: a.shap
267/7: a.shape
267/8: a.shape < (_, 1)
267/9: a.shape < (2, 1)
267/10: a.shape < (np.nan, 1)
267/11: a.shape < (4, 1)
267/12: a.shape[2] < 1
267/13: a.shape[1] < 1
267/14:
n_rnd = 200

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0, 1, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results.loc[index, "Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results.loc[index, "RunTime"] = end - start
267/15:
n_rnd = 200

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results.loc[index, "Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results.loc[index, "RunTime"] = end - start
268/1:
%load_ext autoreload
%autoreload 1
268/2:
%aimport band_model.utils.absorption
%aimport logging
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import time
%matplotlib inline
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
268/3:
n_rnd = 200

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results.loc[index, "Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results.loc[index, "RunTime"] = end - start
268/4:
qd_size_i=1.07  me_i=0.09  mh_i=0.06  Pl_i=6.8e-25  Pt_i=7.2e-25  Eg_i=2.46  offset_i=0.74  Vcb_i=1.51  Vvb_i=0.94
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
268/5:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
269/1:
%load_ext autoreload
%autoreload 1
269/2:
%aimport band_model.utils.absorption as ab
%aimport logging
from band_model import qd_base_data as qbd
# from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import time
%matplotlib inline
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
269/3:
%aimport band_model.utils.absorption
%aimport logging
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import time
%matplotlib inline
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
269/4:
%aimport band_model.utils.absorption
%aimport logging
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import time
%matplotlib inline
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
269/5:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
269/6:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
269/7:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
269/8:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
270/1:
%aimport band_model.utils.absorption
%aimport logging
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import time
%matplotlib inline
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
270/2:
%load_ext autoreload
%autoreload 1
270/3:
%aimport band_model.utils.absorption
%aimport logging
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import math
import numpy as np
import pandas as pd
import h5py
import importlib
import timeit
from itertools import product
from pyevtk.hl import gridToVTK
import time
%matplotlib inline
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
270/4:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
270/5:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
271/1:
%load_ext autoreload
%autoreload 1
%matplotlib inline
271/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
271/3:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
271/4:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
271/5:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
271/6:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
271/7:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
271/8:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
271/9:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
271/10: data
271/11:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
271/12: energy.n_dim
271/13: energy.ndim
271/14: energy.mdim
271/15: len(energy)
271/16:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
271/17: data
271/18:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
271/19: data
271/20:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
rnd_results.loc[index, "Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
rnd_results.loc[index, "RunTime"] = end - start
271/21:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
rnd_results=pd.DataFrame()
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
rnd_results.loc[index, "Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
rnd_results.loc[index, "RunTime"] = end - start
271/22:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
rnd_results=pd.DataFrame()
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
rnd_results.loc["Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
271/23:
qd_size_i=1.07;me_i=0.09;mh_i=0.06;Pl_i=6.8e-25;Pt_i=7.2e-25;Eg_i=2.46;offset_i=0.74;Vcb_i=1.51;Vvb_i=0.94
energy = np.linspace(1.35, 4, 200)
sim_properties = (25, 0.08, Eg_i, (Pl_i, Pt_i))
Vcb_i = (Eg_i - 0.4)*offset_i
Vvb_i = Eg_i - Vcb_i
rnd_results=pd.DataFrame()
data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
rnd_results["Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
271/24: data
271/25: rnd_results
271/26: -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
272/1:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
272/2:
%load_ext autoreload
%autoreload 1
%matplotlib inline
272/3:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
272/4:
n_rnd = 200

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results.loc[index, "Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results.loc[index, "RunTime"] = end - start
272/5: energy.any()
272/6: np.isnan(energy.any())
272/7: np.isnan(energy.all())
272/8: energy.all(np.nan)
272/9:
n_rnd = 200

Eg = 2.3; Pt = 4.7e-25; Pl = 3.4e-25; lat_size = 0.8; sim_size = 15
me = 0.08; mh = 0.08; Vcb = 0.4; Vvb = 1.5; qd_size = 3;

# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

energy = np.linspace(1.35, 4, 200)
rnd_results = pd.DataFrame({"qd_size": qd_size, "me": me, "mh": mh, "Pl": Pl, "Pt": Pt, "Eg": Eg, "offset": offset})
rnd_results["Integrate"] = 0
# Save the time it takes to run each iteration
rnd_results["RunTime"] = 0

for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    Vcb_i = (Eg_i - 0.4)*offset_i
    Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation ({index}):{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    start = time.time()
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    end = time.time()
    rnd_results.loc[index, "Integrate"] = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    rnd_results.loc[index, "RunTime"] = end - start
272/10:
# Scatter plot all the simulated points
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[1].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
272/11: rnd_results
272/12: print(rnd_results)
272/13: rnd_results.to_csv("Random_data.csv", sep=" ", index=False)
272/14: %matplotlib qt5
272/15:
# Scatter plot all the simulated points
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[1].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(2*rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
272/16:
# Scatter plot all the simulated points
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[1].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
272/17: %matplotlib inline
272/18:
# Scatter plot all the simulated points
rnd_results = rnd_results.sort_data("Integrate")
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
272/19:
# Scatter plot all the simulated points
rnd_results = rnd_results.sort_values("Integrate")
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
272/20: rnd_results.sort_values("Integrate")
272/21: rnd_results.sort_values("Integrate", ascending=False)
272/22:
# Scatter plot all the simulated points
rnd_results = rnd_results.sort_values("Integrate", ascending=False)
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
272/23:
# Scatter plot all the simulated points
rnd_results.sort_values("Integrate", ascending=False)
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
272/24:
# Scatter plot all the simulated points
rnd_results = rnd_results.sort_values("Integrate", ascending=False)
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
272/25: rnd_results
272/26:
# Scatter plot all the simulated points
rnd_results = rnd_results.sort_values("Integrate", ascending=False, ignore_index=True)
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
272/27:
# Scatter plot all the simulated points
fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"]/(rnd_results["qd_size"])**3, s=100)
ax[0].scatter(rnd_results.index.to_list(), rnd_results["Integrate"], s=100)
272/28: rnd_results.to_csv("Random_results.csv", sep=" ")
272/29: from band_model.pso import particle_swarm
272/30: from band_model.pso import particle_swarm
272/31: from band_model.pso import particle_swarm
272/32: from band_model.pso import particle_swarm
272/33: from band_model.pso.pso import particle_swarm
272/34:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    integration_res = []
    for me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i, (index, qd_size_i) in zip(me, mh, Pl, Pt, Eg, offset, enumerate(qd_size)):
        sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
        Vcb_i = (Eg_i - 0.4)*offset_i
        Vvb_i = Eg_i - Vcb_i
        data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
        integration_res.append(-sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2))
    return np.array(integration_res)
272/35:
from band_model.pso.pso import particle_swarm
import multiprocessing
272/36:
def single_calc(qd_size_i, Vcb_i, Vvi_i, me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i):
    """ Calculate the FoM for a single combination of parameters """
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    # Vcb_i = (Eg_i - 0.4)*offset_i
    # Vvb_i = Eg_i - Vcb_i
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    FoM = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    return FoM
272/37: single_calc(1, 1, 1, 0.05, 0.05, 1e-25, 1e-25, 2, 0.5)
272/38: single_calc(2, 1, 1, 0.05, 0.05, 1e-25, 1e-25, 2, 0.5)
272/39:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    integration_res = []
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    with Pool(4) as p:
        res = p.map(single_FoM, qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset)
    print(res)
    return res
272/40:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/41:
from band_model.pso.pso import particle_swarm
from multiprocessing import Pool
272/42:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    integration_res = []
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    with Pool(4) as p:
        res = p.map(single_FoM, qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset)
    print(res)
    return res
272/43:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/44:
def single_FoM(qd_size_i, Vcb_i, Vvi_i, me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i):
    """ Calculate the FoM for a single combination of parameters """
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    # Vcb_i = (Eg_i - 0.4)*offset_i
    # Vvb_i = Eg_i - Vcb_i
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    FoM = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    return FoM
272/45:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/46:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    integration_res = []
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    with Pool(4) as p:
        res = p.starmap(single_FoM, [tuple(qd_size), tuple(Vcb), tuple(Vvi), tuple(me), tuple(mh), tuple(Pl), tuple(Pt), tuple(Eg), tuple(offset)])
    print(res)
    return res
272/47:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/48:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    integration_res = []
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    with Pool(4) as p:
        res = p.starmap(single_FoM, zip(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset)
    print(res)
    return res
272/49:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/50:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    integration_res = []
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    with Pool(4) as p:
        res = p.starmap(single_FoM, zip(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset))
    print(res)
    return res
272/51:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/52:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    print(f"Random calculation:{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    with Pool(4) as p:
        res = p.starmap(single_FoM, zip(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset))
    print(res)
    return res
272/53:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/54:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/55:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    print(f"Random calculation:{qd_size=:.2f}  {me:.2f}  {mh=:.2f}  {Pl=:.2g}  {Pt=:.2g}  {Eg=:.2f}  {offset=:.2f}  {Vcb=:.2f}  {Vvb=:.2f}")
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    with Pool(4) as p:
        res = p.starmap(single_FoM, zip(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset))
    print(res)
    return res
272/56:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/57:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    print(f"Random calculation:{qd_size}\n{me}\n{mh}\n{Pl}\n{Pt}\n{Eg}\n{offset}\n{Vcb}\n{Vvb}")
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    with Pool(4) as p:
        res = p.starmap(single_FoM, zip(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset))
    print(res)
    return res
272/58:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/59:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    print(f"Random calculation:{qd_size}\n{me}\n{mh}\n{Pl}\n{Pt}\n{Eg}\n{offset}\n{Vcb}\n{Vvb}")
    with Pool(4) as p:
        res = p.starmap(single_FoM, zip(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset))
    print(res)
    return res
272/60:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/61:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
print(list(zip(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset)))
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/62:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    print(f"Random calculation:{qd_size}\n{me}\n{mh}\n{Pl}\n{Pt}\n{Eg}\n{offset}\n{Vcb}\n{Vvb}")
    with Pool(4) as p:
        res = p.starmap(single_FoM, zip(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset))
    print(res)
    return res
272/63:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/64:
def single_FoM(qd_size_i, Vcb_i, Vvi_i, me_i, mh_i, Pl_i, Pt_i, Eg_i, offset_i):
    """ Calculate the FoM for a single combination of parameters """
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    # Vcb_i = (Eg_i - 0.4)*offset_i
    # Vvb_i = Eg_i - Vcb_i
    logging.info(f"Random calculation:{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}")
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i), (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    FoM = -sci.simpson(data["Total"], (scc.h*scc.c)/(data["Energy"]*scc.e)*1e2)
    return FoM
272/65:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    print(f"Random calculation:{qd_size}\n{me}\n{mh}\n{Pl}\n{Pt}\n{Eg}\n{offset}\n{Vcb}\n{Vvb}")
    with Pool(4) as p:
        res = p.starmap(single_FoM, zip(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset))
    print(res)
    return res
272/66:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    with Pool(4) as p:
        res = p.starmap(single_FoM, zip(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset))
    print(res)
    return res
272/67:
n_rnd = 10
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/68:
n_rnd = 30
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/69:
from band_model.pso.pso import particle_swarm
from multiprocessing import Pool
import multiprocessing
272/70:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    with Pool(multiprocessing.cpu_count() - 2) as p:
        res = p.starmap(single_FoM, zip(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset))
    print(res)
    return res
272/71:
n_rnd = 30
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/72:
n_rnd = 30
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 5, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
272/73:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
272/74:
def func(data, **kwargs):
    print(data)
    data.update(**kwargs)
    print(data)
272/75: func({"a":1, "b":2})
272/76: func({"a":1, "b":2},**{"c":3, "d":4})
272/77:
def opt_function(qd_size, Vcb, Vvi, me, mh, Pl, Pt, Eg, offset):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    logging.info("Starting Optimization")
    Vcb = (Eg - 0.4)*offset
    Vvb = Eg - Vcb
    with Pool(multiprocessing.cpu_count() - 2) as p:
        res = p.starmap(single_FoM, zip(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset))
    print(res)
    return res
272/78:
from band_model.pso.pso import particle_swarm
from multiprocessing import Pool
import multiprocessing
from functools import partial
272/79:
def _single_FoM(qd_size_i,
                Vcb_i,
                Vvb_i,
                me_i,
                mh_i,
                Pl_i,
                Pt_i,
                Eg_i,
                offset_i,
                energy=np.linspace(2, 3, 200),
                lat_size=0.8,
                sim_size=25):
    """ Calculate the FoM for a single combination of parameters """
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    # Assuming the energy variation
    logging.info(
        f"Random calculation:{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}"
    )
    data = interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i),
                                (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    # The 1e2 serves to convert the wavelength from m to cm
    FoM = -sci.simpson(data, (scc.h * scc.c) / (data * scc.e) * 1e2)
    return FoM
272/80: single_calc(2, 1, 1, 0.05, 0.05, 1e-25, 1e-25, 2, 0.5)
272/81:
def opt_function(qd_size,
                 Vcb,
                 Vvi,
                 me,
                 mh,
                 Pl,
                 Pt,
                 Eg,
                 offset,
                 energy=np.linspace(2, 3, 200),
                 lat_size=0.8,
                 sim_size=25):
    """
    Optimization function for the particle swarm algorithm
    The input parameters are an array with the properties, and the output is the
    array with the results
    """
    logging.info("Starting Optimization....")
    Vcb = (Eg - 0.4) * offset
    Vvb = Eg - Vcb
    # Create a partial funcion with some parameters constant
    __single_FoM = partial(_single_FoM,
                           energy=energy,
                           lat_size=lat_size,
                           sim_size=sim_size)
    with Pool(multiprocessing.cpu_count() - 2) as p:
        res = p.starmap(__single_FoM,
                        zip(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset))
    return res
272/82:
n_rnd = 5
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
273/1:
%load_ext autoreload
%autoreload 1
%matplotlib inline
273/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
273/3:
from band_model.pso.pso import particle_swarm
from multiprocessing import Pool
import multiprocessing
from functools import partial
273/4:
def _single_FoM(qd_size_i,
                Vcb_i,
                Vvb_i,
                me_i,
                mh_i,
                Pl_i,
                Pt_i,
                Eg_i,
                offset_i,
                energy=np.linspace(2, 3, 200),
                lat_size=0.8,
                sim_size=25):
    """ Calculate the FoM for a single combination of parameters """
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    # Assuming the energy variation
    logging.info(
        f"Random calculation:{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}"
    )
    data = interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i),
                                (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    # The 1e2 serves to convert the wavelength from m to cm
    FoM = -sci.simpson(data, (scc.h * scc.c) / (data * scc.e) * 1e2)
    return FoM
273/5: single_calc(2, 1, 1, 0.05, 0.05, 1e-25, 1e-25, 2, 0.5)
273/6: single_FoM(2, 1, 1, 0.05, 0.05, 1e-25, 1e-25, 2, 0.5)
273/7:
def _single_FoM(qd_size_i,
                Vcb_i,
                Vvb_i,
                me_i,
                mh_i,
                Pl_i,
                Pt_i,
                Eg_i,
                offset_i,
                energy=np.linspace(2, 3, 200),
                lat_size=0.8,
                sim_size=25):
    """ Calculate the FoM for a single combination of parameters """
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    # Assuming the energy variation
    logging.info(
        f"Random calculation:{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}"
    )
    data = interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i),
                                (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    # The 1e2 serves to convert the wavelength from m to cm
    FoM = -sci.simpson(data, (scc.h * scc.c) / (data * scc.e) * 1e2)
    return FoM
273/8: _single_FoM(2, 1, 1, 0.05, 0.05, 1e-25, 1e-25, 2, 0.5)
273/9:
def _single_FoM(qd_size_i,
                Vcb_i,
                Vvb_i,
                me_i,
                mh_i,
                Pl_i,
                Pt_i,
                Eg_i,
                offset_i,
                energy=np.linspace(2, 3, 200),
                lat_size=0.8,
                sim_size=25):
    """ Calculate the FoM for a single combination of parameters """
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    # Assuming the energy variation
    logging.info(
        f"Random calculation:{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}"
    )
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i),
                                (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    # The 1e2 serves to convert the wavelength from m to cm
    FoM = -sci.simpson(data, (scc.h * scc.c) / (data * scc.e) * 1e2)
    return FoM
273/10: _single_FoM(2, 1, 1, 0.05, 0.05, 1e-25, 1e-25, 2, 0.5)
273/11: _single_FoM(3, 1, 1, 0.05, 0.05, 1e-25, 1e-25, 2, 0.5)
273/12: _single_FoM(3, 0.5, 0.5, 0.05, 0.05, 1e-25, 1e-25, 2, 0.5)
273/13:
def _single_FoM(qd_size_i,
                Vcb_i,
                Vvb_i,
                me_i,
                mh_i,
                Pl_i,
                Pt_i,
                Eg_i,
                offset_i,
                energy=np.linspace(2, 3, 200),
                lat_size=0.8,
                sim_size=25):
    """ Calculate the FoM for a single combination of parameters """
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    # Assuming the energy variation
    logging.info(
        f"Random calculation:{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}"
    )
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i),
                                (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    print(data)
    # The 1e2 serves to convert the wavelength from m to cm
    FoM = -sci.simpson(data, (scc.h * scc.c) / (data * scc.e) * 1e2)
    return FoM
273/14: _single_FoM(3, 0.5, 0.5, 0.05, 0.05, 1e-25, 1e-25, 2, 0.5)
273/15:
def _single_FoM(qd_size_i,
                Vcb_i,
                Vvb_i,
                me_i,
                mh_i,
                Pl_i,
                Pt_i,
                Eg_i,
                offset_i,
                energy=np.linspace(2, 3, 200),
                lat_size=0.8,
                sim_size=25):
    """ Calculate the FoM for a single combination of parameters """
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    # Assuming the energy variation
    logging.info(
        f"Random calculation:{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}"
    )
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i),
                                (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    print(data)
    # The 1e2 serves to convert the wavelength from m to cm
    FoM = -sci.simpson(data["Total"], (scc.h * scc.c) / (data["Total"] * scc.e) * 1e2)
    return FoM
273/16: _single_FoM(3, 0.5, 0.5, 0.05, 0.05, 1e-25, 1e-25, 2, 0.5)
273/17:
def _single_FoM(qd_size_i,
                Vcb_i,
                Vvb_i,
                me_i,
                mh_i,
                Pl_i,
                Pt_i,
                Eg_i,
                offset_i,
                energy=np.linspace(2, 3, 50),
                lat_size=0.8,
                sim_size=25):
    """ Calculate the FoM for a single combination of parameters """
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    # Assuming the energy variation
    logging.info(
        f"Random calculation:{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}"
    )
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i),
                                (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    print(data)
    # The 1e2 serves to convert the wavelength from m to cm
    FoM = -sci.simpson(data["Total"], (scc.h * scc.c) / (data["Total"] * scc.e) * 1e2)
    return FoM
273/18: _single_FoM(3, 0.5, 0.5, 0.05, 0.05, 1e-25, 1e-25, 2, 0.5)
273/19:
def _single_FoM(qd_size_i,
                Vcb_i,
                Vvb_i,
                me_i,
                mh_i,
                Pl_i,
                Pt_i,
                Eg_i,
                offset_i,
                energy=np.linspace(2, 3, 50),
                lat_size=0.8,
                sim_size=25):
    """ Calculate the FoM for a single combination of parameters """
    sim_properties = (sim_size, lat_size, Eg_i, (Pl_i, Pt_i))
    # Assuming the energy variation
    logging.info(
        f"Random calculation:{qd_size_i=:.2f}  {me_i=:.2f}  {mh_i=:.2f}  {Pl_i=:.2g}  {Pt_i=:.2g}  {Eg_i=:.2f}  {offset_i=:.2f}  {Vcb_i=:.2f}  {Vvb_i=:.2f}"
    )
    data = ab.interband_absorption(energy, (qd_size_i, Vcb_i, me_i, me_i),
                                (qd_size_i, Vvb_i, mh_i, mh_i), sim_properties)
    print(data)
    # The 1e2 serves to convert the wavelength from m to cm
    FoM = -sci.simpson(data["Total"], (scc.h * scc.c) / (data["Energy"] * scc.e) * 1e2)
    return FoM
273/20: _single_FoM(3, 0.5, 0.5, 0.05, 0.05, 1e-25, 1e-25, 2, 0.5)
273/21:
from band_model.pso.pso import particle_swarm
from band_model.utils.absorption import opt_function
from multiprocessing import Pool
import multiprocessing
from functools import partial
273/22:
n_rnd = 5
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, Vcb, Vvb, me, mh, Pl, Pt, Eg, offset)
273/23:
n_rnd = 5
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, me, mh, Pl, Pt, Eg, offset)
273/24: a = np.array([1, 2, 3, 4, np.nan])
273/25: np.argmax(a)
273/26: a = np.array([6, 2, 3, 4, np.nan])
273/27: np.argmax(a)
273/28: np.argmin(a)
273/29: np.nanargmin(a)
273/30:
param_dict = {
    "qd_size": [2, 3],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 3],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(2, 4, 300),
    "lat_size": 0.8.
    "sim_size": 25
}
particle_swarm(opt_function, param_dict, **const_args)
273/31:
param_dict = {
    "qd_size": [2, 3],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 3],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(2, 4, 300),
    "lat_size": 0.8,
    "sim_size": 25
}
particle_swarm(opt_function, param_dict, **const_args)
273/32:
param_dict = {
    "qd_size": [2, 3],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 3],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(2, 4, 300),
    "lat_size": 0.8,
    "sim_size": 25
}
res = particle_swarm(opt_function, param_dict, n_particles=6, n_iter=2, **const_args)
print(res)
273/33:
# Check if opt function is working properly
n_rnd = 5
# Setup random values for all variables
me = np.random.uniform(0.05, 0.15, size=(n_rnd))
mh = np.random.uniform(0.05, 0.15, size=(n_rnd))
qd_size = np.random.uniform(1, 2, size=(n_rnd))
Pl = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Pt = np.random.uniform(1e-25, 1e-24, size=(n_rnd))
Eg = np.random.uniform(1, 3, size=(n_rnd))
offset = np.random.uniform(0.2, 0.8, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB
opt_function(qd_size, me, mh, Pl, Pt, Eg, offset)
273/34:
param_dict = {
    "qd_size": [2, 5],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 4],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 25
}
res = particle_swarm(opt_function, param_dict, n_particles=25, n_iter=25, export=True, **const_args)
print(res)
274/1:
%load_ext autoreload
%autoreload 1
%matplotlib inline
274/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
274/3:
from band_model.pso.pso import particle_swarm
from band_model.utils.absorption import opt_function
from multiprocessing import Pool
import multiprocessing
from functools import partial
274/4:
param_dict = {
    "qd_size": [2, 5],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 4],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 25
}
res = particle_swarm(opt_function, param_dict, n_particles=25, n_iter=25, export=True, **const_args)
print(res)
274/5:
param_dict = {
    "qd_size": [1, 4],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 4],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=25, n_iter=25, export=True, **const_args)
print(res)
274/6:
param_dict = {
    "qd_size": [1, 4],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 4],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=5, n_iter=2, export=True, **const_args)
print(res)
274/7:
param_dict = {
    "qd_size": [1, 2],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 2],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=5, n_iter=2, export=True, **const_args)
print(res)
274/8:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
274/9:
param_dict = {
    "qd_size": [1, 2],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 2],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=5, n_iter=2, export=True, **const_args)
print(res)
275/1:
%load_ext autoreload
%autoreload 1
%matplotlib inline
275/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
275/3:
param_dict = {
    "qd_size": [1, 2],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 2],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=5, n_iter=2, export=True, **const_args)
print(res)
275/4:
%aimport band_model.pso.pso
from band_model.pso.pso import particle_swarm
from band_model.utils.absorption import opt_function
from multiprocessing import Pool
import multiprocessing
from functools import partial
275/5:
param_dict = {
    "qd_size": [1, 2],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 2],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=5, n_iter=2, export=True, **const_args)
print(res)
275/6:
param_dict = {
    "qd_size": [1, 2],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 2],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=5, n_iter=2, export=True, **const_args)
print(res)
275/7:
param_dict = {
    "qd_size": [1, 2],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 2],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=5, n_iter=2, export=True, **const_args)
print(res)
276/1:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
276/2:
%load_ext autoreload
%autoreload 1
%matplotlib inline
276/3:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.DEBUG)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
276/4:
%aimport band_model.pso.pso
from band_model.pso.pso import particle_swarm
from band_model.utils.absorption import opt_function
from multiprocessing import Pool
import multiprocessing
from functools import partial
276/5:
param_dict = {
    "qd_size": [1, 2],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 2],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=5, n_iter=2, export=True, **const_args)
print(res)
276/6:
param_dict = {
    "qd_size": [1, 2],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 2],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=5, n_iter=2, export=True, **const_args)
print(res)
276/7:
param_dict = {
    "qd_size": [1, 2],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 2],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=5, n_iter=2, export=True, **const_args)
print(res)
276/8:
param_dict = {
    "qd_size": [1, 2],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 2],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=5, n_iter=2, export=True, **const_args)
print(res)
276/9:
param_dict = {
    "qd_size": [1, 2],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 2],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=5, n_iter=2, export=True, **const_args)
print(res)
277/1:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
277/2:
%load_ext autoreload
%autoreload 1
%matplotlib inline
277/3:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
277/4:
%aimport band_model.pso.pso
from band_model.pso.pso import particle_swarm
from band_model.utils.absorption import opt_function
from multiprocessing import Pool
import multiprocessing
from functools import partial
277/5:
param_dict = {
    "qd_size": [1, 4],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 4],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=25, n_iter=50, export=True, **const_args)
278/1:
%load_ext autoreload
%autoreload 1
%matplotlib inline
278/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
278/3:
%aimport band_model.pso.pso
from band_model.pso.pso import particle_swarm
from band_model.utils.absorption import opt_function
from multiprocessing import Pool
import multiprocessing
from functools import partial
278/4:
param_dict = {
    "qd_size": [1, 4],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 4],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=25, n_iter=50, export=True, **const_args)
278/5:
param_dict = {
    "qd_size": [1, 3.5],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 3],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict, n_particles=25, n_iter=50, export=True, **const_args)
278/6:
param_dict = {
    "qd_size": [1, 3],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-24, 1e-24],
    "Eg": [1, 2.5],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict,
                     n_particles=15, n_iter=20,
                     export=True, swarm_properties=(0.3, 1.5, 1.5),
                     **const_args)
279/1: import numpy as np
279/2: import pandas as pd
279/3: import matplotlib.pyplot as plt
279/4: pd.read_csv("results_0")
279/5: pd.read_csv("results_0", names=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"])
279/6: pd.read_csv("results_0", names=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"], sep=" ")
279/7: columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
279/8:
for i in range(5):
    print(i)
279/9: data = []
279/10:
for i in range(6):
    data.append(pd.read_csv(f"results_{i}", sep=" ", names=columns))
279/11: data
279/12: pd.concatenate(data, keys=list(range(6)))
279/13: pd.concat(data, keys=list(range(6)))
279/14: results = pd.concat(data, keys=list(range(6)))
279/15: results
279/16: results.loc[0]
279/17:
for i in range(6):
    plt.plot(i, results.loc[i])
279/18:
for i in range(6):
    plt.plot([i], results.loc[i])
279/19: results.loc[i].size
279/20: results.loc[i]
279/21: results.loc[i].ndim
279/22: len(results.loc[i])
279/23: results.loc[i].shape
279/24:
for i in range(6):
    plt.plot(np.ones(results.loc[i].shape[0], results.loc[i]))
279/25: results.loc[0].shape
279/26: results.loc[0].shape[0]
279/27:
for i in range(6):
    plt.plot(np.ones(results.loc[i].shape[0]), results.loc[i])
279/28: plt.show()
279/29:
for i in range(6):
    plt.plot(np.ones(results.loc[i].shape[0])+i, results.loc[i])
279/30: plt.show()
279/31:
for i in range(6):
    plt.scatter(np.ones(results.loc[i].shape[0])+i, results.loc[i])
279/32: results.loc[i]
279/33: results.loc[i, "QSize"]
279/34:
for i in range(6):
    plt.scatter(np.ones(results.loc[i].shape[0])+i, results.loc[i, "QSize"])
279/35: plt.show()
279/36: plt.savefig("teste.png")
279/37:
for i in range(6):
    plt.scatter(np.ones(results.loc[i].shape[0])+i, results.loc[i, "QSize"])
279/38: plt.savefig("teste.png")
280/1: import numpy as np
280/2: import pandas as pd
280/3: import matplotlib.pyplot as plt
280/4:
for i in range(7):
    print(i)
280/5: columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
280/6: import_data = []
280/7:
for i in range(7):
    import_data.append(pd.read_csv(f"results_{i}", sep=" ", names=columns))
280/8: import_data
280/9: data = pd.concat(import_data, keys=list(range(7)))
280/10: data
280/11:
for i in range(7):
    plt.scatter(np.zeros(data.loc[i, "QSize"]), data.loc[i ,"QSize"])
280/12:
for i in range(7):
    plt.scatter(np.zeros(data.loc[i, "QSize"])+i, data.loc[i ,"QSize"])
280/13:
for i in range(7):
    plt.scatter(np.zeros(data.loc[i, "QSize"].size)+i, data.loc[i ,"QSize"])
280/14: plt.show()
281/1: import numpy as np
281/2: import matplotlib.pyplot as plt
281/3: plt.plot(np.random.randn(100), np.random.randn(100))
281/4: plt.show()
281/5: plt.scatter(np.random.randn(100), np.random.randn(100))
281/6: plt.xlabel("Random 1")
281/7: plt.ylabel("Random 2")
281/8: plt.show()
282/1: ls
282/2: cd PSO_Results
282/3: ls
284/1: pd
284/2: import pandas as pd
284/3: import_data = []
284/4: columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
284/5:
for i in range(17):
    import_data.append(pd.read_csv(f"results_{i}", sep=" ", names=columns))
284/6:
for i in range(16):
    import_data.append(pd.read_csv(f"results_{i}", sep=" ", names=columns))
284/7: data = pd.concat(import_data, keys=list(range(16)))
284/8: data
284/9:
for i in range(16):
    plt.scatter(np.zeros(data.loc[i, "QSize"].size)+i, data.loc[i ,"QSize"])
284/10:
for i in range(16):
    plt.scatter(np.zeros(data.loc[i, "QSize"].size)+i, data.loc[i ,"QSize"], color='red')
284/11: plt.xlabel("Iteration")
284/12: plt.ylabel("QSize")
284/13: plt.bar(data["QSize"])
284/14: data["QSize"].plot.hist(bins=10)
284/15: plt.show()
284/16: data["QSize"].plot.hist(bins=10)
284/17: data["QSize"].plot.hist(bins=20)
284/18: data["QSize"].plot.hist(bins=50)
284/19: import seaborn as sns
284/20: sns.distplot(data["QSize"], bins=50)
286/1: import pandas as pd
286/2:
for i in range(16):
    import_data.append(pd.read_csv(f"results_{i}", sep=" ", names=columns))
286/3: import_data = []
286/4:
for i in range(16):
    import_data.append(pd.read_csv(f"results_{i}", sep=" ", names=columns))
286/5: columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
286/6:
for i in range(16):
    import_data.append(pd.read_csv(f"results_{i}", sep=" ", names=columns))
286/7: data = pd.concat(import_data, keys=list(range(16)))
286/8: data
286/9: columns[:6]
286/10: columns[:7]
286/11: plt.subplots?
286/12: fig, ax = plt.subplots(1, 7)
286/13: fig, ax = plt.subplots(1, 7, figsize=(15,5))
286/14:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        ax[index].scatter(np.zeros(15)+it, data.loc[it, variable])
286/15: fig, ax = plt.subplots(1, 7, figsize=(20,3))
286/16: fig, ax = plt.subplots(1, 7, figsize=(20,8))
286/17: fig, ax = plt.subplots(1, 7, figsize=(15,4))
286/18:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        ax[index].scatter(np.zeros(15)+it, data.loc[it, variable])
286/19: plt.subpltos_adjust(wspace=2)
286/20: plt.subplots_adjust(wspace=2)
286/21: plt.subplots_adjust(wspace=0.5)
286/22:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        ax[index].scatter(np.zeros(15)+it, data.loc[it, variable])
        ax[index].set_title(variable)
286/23: plt.subplots_adjust(wspace=0.5, left=None)
286/24: plt.subplots_adjust(wspace=0.5, left=None, right=None)
286/25: plt.subplots_adjust(wspace=0.5, left=0.1, right=None)
286/26: plt.subplots_adjust(wspace=0.5, left=0.1, right=0.1)
286/27: plt.subplots_adjust(wspace=0.5, left=0.05, right=0.1)
286/28: plt.subplots_adjust(wspace=0.5, left=0.05, right=1)
286/29: plt.subplots_adjust(wspace=0.5, left=0.05, right=0.9)
286/30: plt.subplots_adjust?
286/31: plt.set_ylabel("Variable")
286/32: ax[0].set_ylabel("Variable")
286/33: ax[0].set_xlabel("Iteration")
286/34: plt.subplot_tool?
286/35: plt.subplot_tool()
286/36: plt.subplots_adjust(wspace=0.2, left=0.05, right=0.9)
286/37:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        ax[index].scatter(np.zeros(15)+it, data.loc[it, variable])
        ax[index].set_title(variable)
286/38: plt.subplots_adjust(wspace=0.2, left=0.05, right=0.9)
286/39: fig, ax = plt.subplots(1, 7, figsize=(15,4))
286/40:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        ax[index].scatter(np.zeros(15)+it, data.loc[it, variable])
        ax[index].set_title(variable)
286/41: plt.subplots_adjust(wspace=0.2, left=0.05, right=0.9)
286/42:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        ax[index].scatter(np.zeros(15)+it, data.loc[it, variable])
        ax[index].set_title(variable)
        ax[index].set_xtics(rotate=90)
286/43:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        ax[index].scatter(np.zeros(15)+it, data.loc[it, variable])
        ax[index].set_title(variable)
        ax[index].set_xticks(rotate=90)
286/44: plt.xtics?
286/45: plt.xticks?
286/46:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        ax[index].scatter(np.zeros(15)+it, data.loc[it, variable])
        ax[index].set_title(variable)
        ax[index].tick_params(axis="x", rotate=90)
286/47:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        ax[index].scatter(np.zeros(15)+it, data.loc[it, variable])
        ax[index].set_title(variable)
        ax[index].tick_params(axis="x", rotation=90)
286/48:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        ax[index].scatter(np.zeros(15)+it, data.loc[it, variable])
        ax[index].set_title(variable)
        ax[index].tick_params(axis="y", rotation=90)
286/49:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        ax[index].scatter(np.zeros(15)+it, data.loc[it, variable])
        ax[index].set_title(variable)
        ax[index].tick_params(axis="x", rotation=0)
286/50: ax[0].set_xlabel("Iteration")
286/51: ax[0].set_ylabel("Variable")
286/52:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        ax[index].scatter(np.zeros(15)+it, data.loc[it, variable], color="blue")
        ax[index].set_title(variable)
        ax[index].tick_params(axis="x", rotation=0)
286/53: plt.savefig("askdjfhas.svg")
286/54: plt.rcParams['svg.fonttype'] = 'none'
286/55: plt.savefig("askdjfhas.svg")
285/1:
param_dict = {
    "qd_size": [1, 3.5],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-25, 1e-24],
    "Eg": [1, 2.5],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict,
                     n_particles=15, n_iter=20,
                     export=True, swarm_properties=(0.3, 1.5, 1.5),
                     **const_args)
285/2:
%load_ext autoreload
%autoreload 1
%matplotlib inline
285/3:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
285/4:
%load_ext autoreload
%autoreload 1
%matplotlib inline
285/5:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
285/6:
%aimport band_model.pso.pso
from band_model.pso.pso import particle_swarm
from band_model.utils.absorption import opt_function
from multiprocessing import Pool
import multiprocessing
from functools import partial
285/7:
param_dict = {
    "qd_size": [1, 3.5],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-25, 1e-24],
    "Eg": [1, 2.5],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.8,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict,
                     n_particles=15, n_iter=30,
                     export=True, swarm_properties=(0.3, 1.5, 1.5),
                     **const_args)
286/56: fig, ax = plt.subplots(1, 7, figsize(15,5))
286/57: fig, ax = plt.subplots(1, 7, figsize=(15,5))
286/58:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        sns.distplot(data[variable], bins=100, orient="h", ax=ax[index])
        ax[index].set_title(variable)
        ax[index].tick_params(axis="x", rotation=0)
286/59: import seaborn as sns
286/60:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        sns.distplot(data[variable], bins=100, orient="h", ax=ax[index])
        ax[index].set_title(variable)
        ax[index].tick_params(axis="x", rotation=0)
286/61:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        sns.distplot(data[variable], bins=100, vertical=True, ax=ax[index])
        ax[index].set_title(variable)
        ax[index].tick_params(axis="x", rotation=0)
286/62:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        sns.histplot(data=data,y="QSize", kde=True, ax=ax[index])
        ax[index].set_title(variable)
        ax[index].tick_params(axis="x", rotation=0)
286/63: fig, ax = plt.subplots(1, 7, figsize=(15,5))
286/64: plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
286/65:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        sns.histplot(data=data,y="QSize", kde=True, bins=50, ax=ax[index])
286/66:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y="QSize", kde=True, bins=50, ax=ax[index])
        chart.set_yticks_labels(rotation=90)
286/67:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y="Variable", kde=True, bins=50, ax=ax[index])
        chart.set_ytickslabels(rotation=90)
286/68:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y=variable, kde=True, bins=50, ax=ax[index])
        chart.set_ytickslabels(rotation=90)
286/69:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y=variable, kde=True, bins=50, ax=ax[index])
        chart.set_yticks(rotation=90)
286/70:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y=variable, kde=True, bins=50, ax=ax[index])
        chart.set_yticks(chart.set_ytics, rotation=90)
286/71:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y=variable, kde=True, bins=50, ax=ax[index])
        chart.set_yticks(chart.set_yticks, rotation=90)
286/72:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y=variable, kde=True, bins=50, ax=ax[index])
        ax[index].set_yticks(rotation=90)
286/73:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y=variable, kde=True, bins=50, ax=ax[index])
        ax[index].tick_params(rotation=90)
286/74:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y=variable, kde=True, bins=50, ax=ax[index])
        ax[index].tick_params(axis="y", rotation=90)
286/75: plt.show()
286/76: fig, ax = plt.subplots(1, 7, figsize=(15,5))
286/77: plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
286/78:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y=variable, kde=True, bins=50, ax=ax[index])
        ax[index].tick_params(axis="y", rotation=90)
286/79: plt.clear()
286/80: ax[index].clear()
286/81: [ax_i.clear() for ax_i in ax]
286/82: plt.subplots_adjust(wspace=0.2, left=0.05, right=0.95)
286/83:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y=variable, kde=True, bins=50, ax=ax[index])
        ax[index].tick_params(axis="y", rotation=90)
        ax[index].set_ylabel()
        ax[index].set_title(variable.title)
286/84:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y=variable, kde=True, bins=50, ax=ax[index])
        ax[index].tick_params(axis="y", rotation=90)
        ax[index].set_ylabel("")
        ax[index].set_title(variable.title)
286/85: [ax_i.clear() for ax_i in ax]
286/86:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y=variable, kde=True, bins=50, ax=ax[index])
        ax[index].tick_params(axis="y", rotation=90)
        ax[index].set_ylabel("")
        ax[index].set_title(variable)
286/87: colors = ["red", "green", "blue", "purple", "yellow", "brown", "darkgreen"]
286/88: [ax_i.clear() for ax_i in ax]
286/89:
for index, variable in enumerate(columns[:7]):
    for it in range(16):
        chart = sns.histplot(data=data,y=variable,color=colors[index], bins=25, ax=ax[index])
        ax[index].tick_params(axis="y", rotation=90)
        ax[index].set_ylabel("")
        ax[index].set_title(variable)
286/90: data
285/8: import seaborn as sns
285/9:
n_iter = 31
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/sults/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, list(range(n_iter)))

# Create the subplots for the data
fig, ax = plt.subplots(1, 7, figsize=(15,5))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
285/10:
n_iter = 31
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, list(range(n_iter)))

# Create the subplots for the data
fig, ax = plt.subplots(1, 7, figsize=(15,5))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
285/11:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, list(range(n_iter)))

# Create the subplots for the data
fig, ax = plt.subplots(1, 7, figsize=(15,5))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
285/12: import_data
285/13:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Create the subplots for the data
fig, ax = plt.subplots(1, 7, figsize=(15,5))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
285/14:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Create the subplots for the data
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
285/15:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Create the subplots for the data
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_xlabel("Variable")
285/16:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Create the subplots for the data
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
285/17:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Create the subplots for the data
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("PSO_1.svg")
285/18:
import seaborn as sns
plt.rcParams['svg.fonttype'] = 'none'
285/19:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Create the subplots for the data
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("PSO_1.svg")
287/1:
%load_ext autoreload
%autoreload 1
%matplotlib inline
288/1:
%load_ext autoreload
%autoreload 1
%matplotlib inline
288/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
288/3:
%aimport band_model.pso.pso
from band_model.pso.pso import particle_swarm
from band_model.utils.absorption import opt_function
from multiprocessing import Pool
import multiprocessing
from functools import partial
288/4: import seaborn as sns
288/5:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Create the subplots for the data
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("PSO_1.svg")
288/6:
import seaborn as sns
plt.rcparams["font.fontsize"] = 20
288/7:
import seaborn as sns
plt.rcparam["font.fontsize"] = 20
288/8:
import seaborn as sns
plt.rcParam["font.fontsize"] = 20
288/9:
import seaborn as sns
plt.rcParams["font.fontsize"] = 20
288/10:
import seaborn as sns
plt.rcParams["font.size"] = 20
288/11:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Create the subplots for the data
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("PSO_1.svg")
288/12:
import seaborn as sns
plt.rcParams["font.size"] = 18
288/13:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Create the subplots for the data
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("PSO_1.svg")
288/14:
import seaborn as sns
plt.rcParams["font.size"] = 16
288/15:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Create the subplots for the data
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("PSO_1.svg")
288/16:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Plot the histograms
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc(it, variable))
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
288/17: data.loc(1, "QSize")
288/18: data.loc[1, "QSize"]
288/19:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Plot the histograms
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
288/20:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Plot the histograms
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
288/21: res
288/22:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Plot the histograms
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot the FoM for the various iterations
fig, ax = plt.subplots(1, 1, figsize=(8,8))
for it in range(n_iter):
    ax.scatter(np.zeros(15) + it, data.loc[it, "FoM"], color=colors[index])
288/23:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Plot the histograms
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot the FoM for the various iterations
fig, ax = plt.subplots(1, 1, figsize=(8,8))
for it in range(n_iter):
    ax.scatter(np.zeros(15) + it, data.loc[it, "FoM"], color=colors[index])
    
# Plot for the velocities
for index, variable in enumerate(columns[7:]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[7:]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
288/24: columns[7:]
288/25:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Plot the histograms
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot the FoM for the various iterations
fig, ax = plt.subplots(1, 1, figsize=(8,8))
for it in range(n_iter):
    ax.scatter(np.zeros(15) + it, data.loc[it, "FoM"], color=colors[index])
    
# Plot for the velocities
for index, variable in enumerate(columns[8:]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[8:]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
288/26:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Plot the histograms
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot the FoM for the various iterations
fig, ax = plt.subplots(1, 1, figsize=(8,8))
for it in range(n_iter):
    ax.scatter(np.zeros(15) + it, data.loc[it, "FoM"], color=colors[index])
    
# Plot for the velocities
fig, ax = plt.subplots(1, 7, figsize=(20,8))
for index, variable in enumerate(columns[8:]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[8:]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
288/27: data
288/28: data.loc[-1]
288/29: data.loc[30]
288/30: data.loc[29]
288/31: 2.5*0.62
288/32: 2.1*0.62
288/33:
pso_abs = ab.interband_absorption(np.linspace(0.5, 4, 200), (1, 1.3, 0.086, 0.086),
                                (1, 1.19, 0.12, 0.12), (15, 0.8, 2.5, (0.65e-25, 0.85e-25))
288/34:
pso_abs = ab.interband_absorption(np.linspace(0.5, 4, 200), (1, 1.3, 0.086, 0.086),
                                (1, 1.19, 0.12, 0.12), (15, 0.8, 2.5, (0.65e-25, 0.85e-25)))
288/35: pso_abs
288/36: plt.plot(pso_abs["Energy"], pso_abs["Total"])
288/37:
pso_abs = ab.interband_absorption(np.linspace(0.5, 4, 200), (1, 1.3, 0.086, 0.086),
                                (1, 1.19, 0.12, 0.12), (15, 0.8, 2.5, (0.65e-25, 0.85e-25)))
qd1 = qbd.qd_results(1, 1.3, 0.086, 0.086)
qd1.e_levels
qd2 = qbd.qd_results(1, 1.19, 0.12, 0.12)
qd2.e_levels
288/38:
pso_abs = ab.interband_absorption(np.linspace(0.5, 4, 200), (1, 1.3, 0.086, 0.086),
                                (1, 1.19, 0.12, 0.12), (15, 0.8, 2.5, (0.65e-25, 0.85e-25)))
qd1 = qbd.qd_results(1, 1.3, 0.086, 0.086, "CB1")
qd1.e_levels
qd2 = qbd.qd_results(1, 1.19, 0.12, 0.12, "VB1")
qd2.e_levels
288/39:
pso_abs = ab.interband_absorption(np.linspace(0.5, 4, 200), (1, 1.3, 0.086, 0.086),
                                (1, 1.19, 0.12, 0.12), (15, 0.8, 2.5, (0.65e-25, 0.85e-25)))
qd1 = qbd.qd_results(1, 1.3, 0.086, 0.086, "CB1")
print(qd1.e_levels)
qd2 = qbd.qd_results(1, 1.19, 0.12, 0.12, "VB1")
print(qd2.e_levels)
288/40:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Plot the histograms
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("Hist_1.svg")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("Iter_1.svg")

# Plot the FoM for the various iterations
fig, ax = plt.subplots(1, 1, figsize=(8,8))
for it in range(n_iter):
    ax.scatter(np.zeros(15) + it, data.loc[it, "FoM"], color=colors[index])
ax.set_ylabel("FoM")
ax.set_xlabel("Iteration")
plt.savefig("FoM.svg")
    
# Plot for the velocities
fig, ax = plt.subplots(1, 7, figsize=(20,8))
for index, variable in enumerate(columns[8:]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("vHist_1.svg")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[8:]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("vIter_1.svg")
288/41:
param_dict = {
    "qd_size": [1, 3.5],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-25, 1e-24],
    "Eg": [1, 2.5],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict,
                     n_particles=15, n_iter=30,
                     export=True, swarm_properties=(0.3, 1.5, 1.5),
                     **const_args)
288/42:
n_iter = 3
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results_2/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Plot the histograms
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("Hist_2.svg")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("Iter_2.svg")

# Plot the FoM for the various iterations
fig, ax = plt.subplots(1, 1, figsize=(8,8))
for it in range(n_iter):
    ax.scatter(np.zeros(15) + it, data.loc[it, "FoM"], color=colors[index])
ax.set_ylabel("FoM")
ax.set_xlabel("Iteration")
plt.savefig("FoM_2.svg")
    
# Plot for the velocities
fig, ax = plt.subplots(1, 7, figsize=(20,8))
for index, variable in enumerate(columns[8:]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("vHist_2.svg")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[8:]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("vIter_2.svg")
288/43:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results_2/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Plot the histograms
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("Hist_2.svg")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("Iter_2.svg")

# Plot the FoM for the various iterations
fig, ax = plt.subplots(1, 1, figsize=(8,8))
for it in range(n_iter):
    ax.scatter(np.zeros(15) + it, data.loc[it, "FoM"], color=colors[index])
ax.set_ylabel("FoM")
ax.set_xlabel("Iteration")
plt.savefig("FoM_2.svg")
    
# Plot for the velocities
fig, ax = plt.subplots(1, 7, figsize=(20,8))
for index, variable in enumerate(columns[8:]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("vHist_2.svg")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[8:]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("vIter_2.svg")
288/44: res
288/45: res[1]
288/46: res
288/47:
n_iter = 30
import_data = []
# Import data and put it on a pandas DF
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for i in range(n_iter):
    import_data.append(pd.read_csv(f"PSO_Results/results_{i}", sep=" ", names=columns))
data = pd.concat(import_data, keys=list(range(n_iter)))

# Plot the histograms
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("Hist_2.svg")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[:7]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("Iter_2.svg")

# Plot the FoM for the various iterations
fig, ax = plt.subplots(1, 1, figsize=(8,8))
for it in range(n_iter):
    ax.scatter(np.zeros(15) + it, data.loc[it, "FoM"], color=colors[index])
ax.set_ylabel("FoM")
ax.set_xlabel("Iteration")
plt.savefig("FoM_2.svg")
    
# Plot for the velocities
fig, ax = plt.subplots(1, 7, figsize=(20,8))
for index, variable in enumerate(columns[8:]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("vHist_2.svg")

# Plot values per iteration
fig, ax = plt.subplots(1, 7, figsize=(20,8))
plt.subplots_adjust(wspace=0.15, left=0.05, right=0.95)
# Plot Colors
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
# Plot the histograms
for index, variable in enumerate(columns[8:]):
    for it in range(n_iter):
        ax[index].scatter(np.zeros(15) + it, data.loc[it, variable], color=colors[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
ax[0].set_ylabel("Variable")
plt.savefig("vIter_2.svg")
288/48:
energy = np.linspace(0.5, 4, 200)
sim_properties = (15, 0.65, 2.10, (7.9e-25, 5.1e25))
ab.interband_absorption(energy, (2.96, 0.82, 0.12, 0.12),
                                (2.96, 0.89, 0.10, 0.10), sim_properties)
288/49:
energy = np.linspace(0.5, 4, 200)
sim_properties = (15, 0.65, 2.10, (7.9e-25, 5.1e25))
absoprtion = ab.interband_absorption(energy, (2.96, 0.82, 0.12, 0.12),
                                (2.96, 0.89, 0.10, 0.10), sim_properties)
288/50: absorption
288/51: absoprtion
288/52: plt.plot(absoprtion["Energy"], absoprtion["Total"])
288/53:
plt.figure(figsize=(6, 6)
plt.plot(absoprtion["Energy"], absoprtion["Total"])
288/54:
plt.figure(figsize=(6, 6))
plt.plot(absoprtion["Energy"], absoprtion["Total"])
288/55:
plt.figure(figsize=(10, 6))
plt.plot(absoprtion["Energy"], absoprtion["Total"])
288/56:
plt.figure(figsize=(10, 6))
plt.plot(absoprtion["Energy"], absoprtion["Total"])
plt.xlabel("Absorption per Density")
plt.ylabel("Energy (eV)")
288/57: qbd.qd_results(2.96, 0.82, 0.12, 0.12)
288/58: qbd.qd_results(2.96, 0.82, 0.12, 0.12, "CB1")
288/59: qbd.qd_results(2.96, 0.82, 0.12, 0.12, "CB1").e_levels
288/60: qbd.qd_results(2.96, 0.89, 0.10, 0.10, "VB1").e_levels
288/61:
plt.figure(figsize=(10, 6))
plt.plot(absoprtion["Energy"], absoprtion["Total"])
plt.ylabel("Absorption per Density")
plt.xlabel("Energy (eV)")
288/62: energy
288/63: energy/scc.h_bar
288/64: energy/scc.hbar
288/65: energy/(scc.hbar*scc.e)
288/66: energy*scc.e/(scc.hbar)
288/67: energy
288/68: np.broadcast(energy, 10)
288/69: np.broadcast_to(energy, (energy.n_dim, enegy.n_dim))
288/70: energy.ndim
288/71: energy.size
288/72: np.broadcast_to(energy, (energy.size, enegy.size))
288/73: np.broadcast_to(energy, (energy.size, energy.size))
288/74: np.broadcast_to(energy, (energy.size, energy.size)).shape
288/75: np.broadcast_to(energy, (energy.size, energy.size))
288/76:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
e_array - energy
288/77: np.add?
288/78:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
e_array - energy[:, np.newaxis]
288/79:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absoprtion["Total"]
abs_coef = np.broadcast_to(abs_coef, (abs_coef.size, abs_coef.size))
e_array - energy[:, np.newaxis]
288/80:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absoprtion["Total"]
numerator = np.broadcast_to(abs_coef, (abs_coef.size, abs_coef.size))
denominator = e_array - energy[:, np.newaxis]
mask = denominator[denominator != 0]
288/81: mask
288/82:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absoprtion["Total"]
numerator = np.broadcast_to(abs_coef, (abs_coef.size, abs_coef.size))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
288/83: mask
288/84:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absoprtion["Total"]
numerator = np.broadcast_to(abs_coef, (abs_coef.size, abs_coef.size))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
numerator[mask].reshape(-1)
denominator[mask].reshape(-1)
288/85: numerator
288/86: abs_coef.size
288/87: denomitor
288/88: denominator
288/89:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absoprtion["Total"]
numerator = np.broadcast_to(abs_coef, (abs_coef.size, abs_coef.size))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
denominator = numerator[mask].reshape(-1)
denominator = denominator[mask].reshape(-1)
288/90:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absoprtion["Total"]
numerator = np.broadcast_to(abs_coef, (abs_coef.size, abs_coef.size))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
numerator = numerator[mask].reshape(-1)
denominator = denominator[mask].reshape(-1)
288/91: numerator
288/92: numerator.shape
288/93: 400*400
288/94: e_array.shape
288/95: numerator
288/96: abs_coef
288/97: abs_coef.size
288/98: numerator
288/99: numerator.shape
288/100:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absoprtion["Total"]
numerator = np.broadcast_to(abs_coef.values, (abs_coef.size, abs_coef.size))
denominator = e_array - energy[:, np.newaxis]
# mask = denominator != 0
# numerator = numerator[mask].reshape(-1)
# denominator = denominator[mask].reshape(-1)
288/101: numerator.shape
288/102: denominator
288/103: numerator
288/104:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absoprtion["Total"]
numerator = np.broadcast_to(abs_coef.values, (abs_coef.size, abs_coef.size))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
numerator = numerator[mask].reshape(-1)
# denominator = denominator[mask].reshape(-1)
288/105: numerator
288/106: denominator != 0
288/107: numerator[denominator != 0]
288/108:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absoprtion["Total"]
numerator = np.broadcast_to(abs_coef.values, (abs_coef.size, abs_coef.size))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
#numerator = numerator[mask].reshape(-1)
# denominator = denominator[mask].reshape(-1)
288/109: numerator[denominator != 0]
288/110: numerator[denominator != 0].reshape(abs_coef.size-1, abs_coef.size-1)
288/111: numerator[denominator != 0].shape
288/112:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absoprtion["Total"]
numerator = np.broadcast_to(abs_coef.values, (abs_coef.size, abs_coef.size))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
#numerator = numerator[mask].reshape(-1)
# denominator = denominator[mask].reshape(-1)
288/113: numerator
288/114: numerator.shape
288/115: 200*200
288/116:
numerator.shape
mask.shape
288/117: numerator[mask]
288/118: numerator[mask].shape
289/1:
%load_ext autoreload
%autoreload 1
%matplotlib inline
289/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
289/3: np.triu?
289/4:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absoprtion["Total"]
numerator = np.broadcast_to(abs_coef.values, (abs_coef.size, abs_coef.size))
print(np.triu(numerator))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
#numerator = numerator[mask].reshape(-1)
# denominator = denominator[mask].reshape(-1)
289/5:
energy = np.linspace(0.5, 4, 200)
sim_properties = (15, 0.65, 2.10, (7.9e-25, 5.1e25))
absorption = ab.interband_absorption(energy, (2.96, 0.82, 0.12, 0.12), (2.96, 0.89, 0.10, 0.10), sim_properties)
289/6: absorption
289/7:
plt.figure(figsize=(10, 6))
plt.plot(absoprtion["Energy"], absoprtion["Total"])
plt.ylabel("Absorption per Density")
plt.xlabel("Energy (eV)")
289/8:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption["Total"])
plt.ylabel("Absorption per Density")
plt.xlabel("Energy (eV)")
289/9:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absoprtion["Total"]
numerator = np.broadcast_to(abs_coef.values, (abs_coef.size, abs_coef.size))
print(np.triu(numerator))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
#numerator = numerator[mask].reshape(-1)
# denominator = denominator[mask].reshape(-1)
289/10:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absorption["Total"]
numerator = np.broadcast_to(abs_coef.values, (abs_coef.size, abs_coef.size))
print(np.triu(numerator))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
#numerator = numerator[mask].reshape(-1)
# denominator = denominator[mask].reshape(-1)
289/11:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absorption["Total"]
numerator = np.broadcast_to(abs_coef.values, (abs_coef.size, abs_coef.size))
pprint(np.triu(numerator))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
#numerator = numerator[mask].reshape(-1)
# denominator = denominator[mask].reshape(-1)
289/12:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absorption["Total"]
numerator = np.broadcast_to(abs_coef.values, (abs_coef.size, abs_coef.size))
print(np.triu(numerator))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
#numerator = numerator[mask].reshape(-1)
# denominator = denominator[mask].reshape(-1)
289/13: import pprint
289/14:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absorption["Total"]
numerator = np.broadcast_to(abs_coef.values, (abs_coef.size, abs_coef.size))
pprint(np.triu(numerator))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
#numerator = numerator[mask].reshape(-1)
# denominator = denominator[mask].reshape(-1)
289/15:
e_array = np.broadcast_to(energy, (energy.size, energy.size))
abs_coef = absorption["Total"]
numerator = np.broadcast_to(abs_coef.values, (abs_coef.size, abs_coef.size))
pprint.pprint(np.triu(numerator))
denominator = e_array - energy[:, np.newaxis]
mask = denominator != 0
#numerator = numerator[mask].reshape(-1)
# denominator = denominator[mask].reshape(-1)
289/16:
a=[1, 2, 3, np.nan]
sci.simpson(a)
289/17:
a=[1, 2, 3, np.nan]
sci.simpson(1/a)
289/18:
a=[1, 2, 3, np.nan]
sci.simpson(1/np.array(a))
289/19:
n_data = np.zeros_like(energy_i)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    print(index, energy_i)
289/20:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    print(index, energy_i)
289/21:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    print(energy_i[:index], energy_i[index:])
289/22:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    print(energy_i[:index], energy_i[index+1:])
289/23:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef[:index], abs_coefficien[index+1:]
    sci.simpson(l_abs_cound/l_bound, energy[:index])
289/24:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
    sci.simpson(l_abs_cound/l_bound, energy[:index])
289/25:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
    sci.simpson(l_abs_bound/l_bound, energy[:index])
289/26:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
    print(l_bound, u_bound, energy[:index])
    sci.simpson(l_abs_bound/l_bound, energy[:index])
289/27:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
    print(l_bound, l_abs_bound, energy[:index])
    sci.simpson(l_abs_bound/l_bound, energy[:index])
289/28:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
    print(l_bound, l_abs_bound, energy.values[:index])
    sci.simpson(l_abs_bound/l_bound, energy[:index])
289/29:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef.values[:index], abs_coef.values[index+1:]
    print(l_bound, l_abs_bound, energy[:index])
    sci.simpson(l_abs_bound/l_bound, energy[:index])
289/30:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef.values[:index], abs_coef.values[index+1:]
    print(l_bound, l_abs_bound, energy[:index])
    sci.simpson(u_abs_bound/u_bound, energy[index+1:])
289/31:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef.values[:index], abs_coef.values[index+1:]
    # Integrate both bounds, considering the edge cases
    if index == 0:
        l_int = 0
    else:
        l_int = sci.simpson(l_abs_bound/l_bound, energy[index+1:])
    if index == len(energy):
        u_int = 0
    else:
        u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
    n_data[index] = 1+scc.c/scc.pi*(l_int+u_int)
289/32: energy
289/33: len(energy)
289/34:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef.values[:index], abs_coef.values[index+1:]
    # Integrate both bounds, considering the edge cases
    if index == 0:
        l_int = 0
    else:
        l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
    if index == len(energy):
        u_int = 0
    else:
        u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
    n_data[index] = 1+scc.c/scc.pi*(l_int+u_int)
289/35:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef.values[:index], abs_coef.values[index+1:]
    print(index)
    # Integrate both bounds, considering the edge cases
    if index == 0:
        l_int = 0
    else:
        l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
    if index == len(energy):
        u_int = 0
    else:
        u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
    n_data[index] = 1+scc.c/scc.pi*(l_int+u_int)
289/36:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef.values[:index], abs_coef.values[index+1:]
    print(index)
    # Integrate both bounds, considering the edge cases
    if index == 0:
        l_int = 0
    else:
        l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
    if index > len(energy) - 1:
        u_int = 0
    else:
        u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
    n_data[index] = 1+scc.c/scc.pi*(l_int+u_int)
289/37:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef.values[:index], abs_coef.values[index+1:]
    # Integrate both bounds, considering the edge cases
    if index == 0:
        l_int = 0
    else:
        l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
    print(energy[index+1])
    if index > len(energy) - 1:
        u_int = 0
    else:
        u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
    n_data[index] = 1+scc.c/scc.pi*(l_int+u_int)
289/38:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef.values[:index], abs_coef.values[index+1:]
    # Integrate both bounds, considering the edge cases
    if index == 0:
        l_int = 0
    else:
        l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
    print(energy[index+1]:)
    if index > len(energy) - 1:
        u_int = 0
    else:
        u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
    n_data[index] = 1+scc.c/scc.pi*(l_int+u_int)
289/39:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef.values[:index], abs_coef.values[index+1:]
    # Integrate both bounds, considering the edge cases
    if index == 0:
        l_int = 0
    else:
        l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
    print(energy[index+1:])
    if index > len(energy) - 1:
        u_int = 0
    else:
        u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
    n_data[index] = 1+scc.c/scc.pi*(l_int+u_int)
289/40:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef.values[:index], abs_coef.values[index+1:]
    # Integrate both bounds, considering the edge cases
    if index == 0:
        l_int = 0
    else:
        l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
    print(energy[index+1:])
    if index > len(energy) - 2:
        u_int = 0
    else:
        u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
    n_data[index] = 1+scc.c/scc.pi*(l_int+u_int)
289/41:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef.values[:index], abs_coef.values[index+1:]
    # Integrate both bounds, considering the edge cases
    if index == 0:
        l_int = 0
    else:
        l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
    if index > len(energy) - 2:
        u_int = 0
    else:
        u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
    n_data[index] = 1+scc.c/scc.pi*(l_int+u_int)
print(n_data)
289/42:
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef.values[:index], abs_coef.values[index+1:]
    # Integrate both bounds, considering the edge cases
    if index == 0:
        l_int = 0
    else:
        l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
    if index > len(energy) - 2:
        u_int = 0
    else:
        u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
    n_data[index] = 1+scc.c/scc.pi*(l_int+u_int)
print(n_data)
print(len(n_data))
289/43:
%%timeit
n_data = np.zeros_like(energy)
e_array = np.broadcast_to(energy, (energy.size, energy.size))
for index, energy_i in enumerate(e_array - energy[:, np.newaxis]):
    # Create the lower and upper integration bounds
    l_bound, u_bound = energy_i[:index], energy_i[index+1:]
    l_abs_bound, u_abs_bound = abs_coef.values[:index], abs_coef.values[index+1:]
    # Integrate both bounds, considering the edge cases
    if index == 0:
        l_int = 0
    else:
        l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
    if index > len(energy) - 2:
        u_int = 0
    else:
        u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
    n_data[index] = 1+scc.c/scc.pi*(l_int+u_int)
289/44: plt.plot(energy, n_data)
289/45: abs_coef
289/46:
def kramers_kronig(ang_freq, abs_coef):
    """ Apply the kramers kronig to the abs_coef to return the refractive in the given
    energy interval
    """
    n_data = np.zeros_like(ang_freq)
    ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
    for index, ang_freq_i in enumerate(ang_freq - ang_freq[:, np.newaxis]):
        # Create the lower and upper integration bounds
        l_bound, u_bound = ang_freq_i[:index], ang_freq_i[index+1:]
        l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
        # Integrate both bounds, considering the edge cases
        if index == 0:
            l_int = 0
        else:
            l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
        if index > len(energy) - 2:
            u_int = 0
        else:
            u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
        n_data[index] = 1+scc.c/scc.pi*(l_int+u_int)
    return n_data
289/47: energy
289/48:
energy
abs_coef
289/49:
energy = np.linspace(0.5, 4, 200)
sim_properties = (15, 0.65, 2.10, (7.9e-25, 5.1e25))
absorption = ab.interband_absorption(energy, (2.96, 0.82, 0.12, 0.12), (2.96, 0.89, 0.10, 0.10), sim_properties)
289/50: absorption
289/51: abs_coef
289/52: absorption
289/53:
def kramers_kronig(ang_freq, abs_coef):
    """ Apply the kramers kronig to the abs_coef to return the refractive in the given
    energy interval
    """
    n_data = np.zeros_like(ang_freq)
    ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
    for index, ang_freq_i in enumerate(ang_freq - ang_freq[:, np.newaxis]):
        # Create the lower and upper integration bounds
        l_bound, u_bound = ang_freq_i[:index], ang_freq_i[index+1:]
        l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
        # Integrate both bounds, considering the edge cases
        if index == 0:
            l_int = 0
        else:
            l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
        if index > len(energy) - 2:
            u_int = 0
        else:
            u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
        # The 100 converts c0 to cm/s
        n_data[index] = 1+((100*scc.c)/scc.pi)*(l_int+u_int)
    return n_data
289/54:
ang_freq = energy/scc.hbar
abs_coef = absorption["Total"].values*1e-2
289/55: abs_coef
289/56:
ang_freq = energy/scc.hbar
abs_coef = absorption["Total"].values*1e-2
n = kramers_kronig(ang_freq, abs_coef)
289/57: plt.plot(energy, n)
289/58: plt.plot(n)
289/59: n
289/60:
def kramers_kronig(ang_freq, abs_coef):
    """ Apply the kramers kronig to the abs_coef to return the refractive in the given
    energy interval
    """
    n_data = np.zeros_like(ang_freq)
    ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
    for index, ang_freq_i in enumerate(ang_freq - ang_freq[:, np.newaxis]):
        # Create the lower and upper integration bounds
        l_bound, u_bound = ang_freq_i[:index], ang_freq_i[index+1:]
        l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
        # Integrate both bounds, considering the edge cases
        if index == 0:
            l_int = 0
        else:
            l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
        if index > len(energy) - 2:
            u_int = 0
        else:
            u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
        # The 100 converts c0 to cm/s
        print(l_int, u_int)
        n_data[index] = 1+((100*scc.c)/scc.pi)*(l_int+u_int)
    return n_data
289/61:
ang_freq = energy/scc.hbar
abs_coef = absorption["Total"].values*1e-2
n = kramers_kronig(ang_freq, abs_coef)
289/62:
def kramers_kronig(ang_freq, abs_coef):
    """ Apply the kramers kronig to the abs_coef to return the refractive in the given
    energy interval
    """
    n_data = np.zeros_like(ang_freq)
    ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
    for index, ang_freq_i in enumerate(ang_freq**2 - ang_freq[:, np.newaxis]**2):
        # Create the lower and upper integration bounds
        l_bound, u_bound = ang_freq_i[:index], ang_freq_i[index+1:]
        l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
        # Integrate both bounds, considering the edge cases
        if index == 0:
            l_int = 0
        else:
            l_int = sci.simpson(l_abs_bound/l_bound, energy[:index])
        if index > len(energy) - 2:
            u_int = 0
        else:
            u_int = sci.simpson(u_abs_bound/u_bound, energy[index+1:])
        # The 100 converts c0 to cm/s
        print(l_int, u_int)
        n_data[index] = 1+((100*scc.c)/scc.pi)*(l_int+u_int)
    return n_data
289/63:
ang_freq = energy/scc.hbar
abs_coef = absorption["Total"].values*1e-2
n = kramers_kronig(ang_freq, abs_coef)
289/64: n
289/65:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*1e-2
n = kramers_kronig(ang_freq, abs_coef)
289/66: ang_freq
289/67:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*1e-2
n = kramers_kronig(ang_freq, abs_coef)

ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
print(ang_freq**2 - ang_freq[:, np.newaxis]**2)
289/68: a = np.zeros((4, 4))
289/69: a
289/70:
a = np.zeros((4, 4))
b = np.ones(4)
289/71: b
289/72: a-b[:, np.newaxis]
289/73:
a = np.zeros((4, 4))
b = np.random.randn(4)
289/74: a-b[:, np.newaxis]
289/75:
def kramers_kronig(ang_freq, abs_coef):
    """ Apply the kramers kronig to the abs_coef to return the refractive in the given
    energy interval
    """
    n_data = np.zeros_like(ang_freq)
    ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
    for index, denominator in enumerate(ang_freq**2 - ang_freq[:, np.newaxis]**2):
        # Create the lower and upper integration bounds
        l_bound, u_bound = denominator[:index], denominator[index+1:]
        l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
        # Integrate both bounds, considering the edge cases
        if index == 0:
            l_int = 0
        else:
            l_int = sci.simpson(l_abs_bound/l_bound, ang_freq[:index])
        if index > len(energy) - 2:
            u_int = 0
        else:
            u_int = sci.simpson(u_abs_bound/u_bound, ang_freq[index+1:])
        # The 100 converts c0 to cm/s
        print(l_int, u_int)
        n_data[index] = 1+((100*scc.c)/scc.pi)*(l_int+u_int)
    return n_data
289/76:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*1e-2
n = kramers_kronig(ang_freq, abs_coef)
289/77: n
289/78: plt.plot(n)
289/79:
def kramers_kronig(ang_freq, abs_coef):
    """ Apply the kramers kronig to the abs_coef to return the refractive in the given
    energy interval
    """
    n_data = np.ones_like(ang_freq)
    ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
    for index, denominator in enumerate(ang_freq**2 - ang_freq[:, np.newaxis]**2):
        # Create the lower and upper integration bounds
        l_bound, u_bound = denominator[:index], denominator[index+1:]
        l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
        # Integrate both bounds, considering the edge cases
        if index == 0:
            l_int = 0
        else:
            l_int = -sci.simpson(l_abs_bound/l_bound, ang_freq[:index])
        if index > len(energy) - 2:
            u_int = 0
        else:
            u_int = -sci.simpson(u_abs_bound/u_bound, ang_freq[index+1:])
        # The 100 converts c0 to cm/s
        print(l_int, u_int)
        n_data[index] += ((100*scc.c)/scc.pi)*(l_int+u_int)
    return n_data
289/80:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*1e-2
n = kramers_kronig(ang_freq, abs_coef)
289/81: plt.plot(n)
289/82:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values
n = kramers_kronig(ang_freq, abs_coef)
289/83: plt.plot(n)
289/84:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*1e-2
n = kramers_kronig(ang_freq, abs_coef)
289/85: plt.plot(n)
289/86:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import scipy.interpolate as scin

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
289/87: data = scin.interp1d(energy, absorption["Total"])
289/88:
energy = np.linspace(0.1, 3.9, 400)
absorpt = data(energy)
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*1e-2
n = kramers_kronig(ang_freq, abs_coef)
289/89: energy
289/90:
energy_int = np.linspace(0.1, 3.9, 400)
absorpt = data(energy_int)
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*1e-2
n = kramers_kronig(ang_freq, abs_coef)
289/91:
energy = np.linspace(0.5, 4, 600)
sim_properties = (15, 0.65, 2.10, (7.9e-25, 5.1e25))
absorption = ab.interband_absorption(energy, (2.96, 0.82, 0.12, 0.12), (2.96, 0.89, 0.10, 0.10), sim_properties)
289/92: absorption
289/93:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption["Total"])
plt.ylabel("Absorption per Density")
plt.xlabel("Energy (eV)")
289/94:
def kramers_kronig(ang_freq, abs_coef):
    """ Apply the kramers kronig to the abs_coef to return the refractive in the given
    energy interval
    """
    n_data = np.ones_like(ang_freq)
    ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
    for index, denominator in enumerate(ang_freq**2 - ang_freq[:, np.newaxis]**2):
        # Create the lower and upper integration bounds
        l_bound, u_bound = denominator[:index], denominator[index+1:]
        l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
        # Integrate both bounds, considering the edge cases
        if index == 0:
            l_int = 0
        else:
            l_int = -sci.simpson(l_abs_bound/l_bound, ang_freq[:index])
        if index > len(energy) - 2:
            u_int = 0
        else:
            u_int = -sci.simpson(u_abs_bound/u_bound, ang_freq[index+1:])
        # The 100 converts c0 to cm/s
        print(l_int, u_int)
        n_data[index] += ((100*scc.c)/scc.pi)*(l_int+u_int)
    return n_data
289/95:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*1e-2
n = kramers_kronig(ang_freq, abs_coef)
289/96: plt.plot(n)
289/97:
def kramers_kronig(ang_freq, abs_coef):
    """ Apply the kramers kronig to the abs_coef to return the refractive in the given
    energy interval
    """
    n_data = np.ones_like(ang_freq)
    ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
    print(ang_freq_array)
    for index, denominator in enumerate(ang_freq[:, np.newaxis]**2 - ang_freq**2):
        # Create the lower and upper integration bounds
        l_bound, u_bound = denominator[:index], denominator[index+1:]
        l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
        # Integrate both bounds, considering the edge cases
        if index == 0:
            l_int = 0
        else:
            l_int = -sci.simpson(l_abs_bound/l_bound, ang_freq[:index])
        if index > len(energy) - 2:
            u_int = 0
        else:
            u_int = -sci.simpson(u_abs_bound/u_bound, ang_freq[index+1:])
        # The 100 converts c0 to cm/s
        n_data[index] += ((100*scc.c)/scc.pi)*(l_int+u_int)
    return n_data
289/98:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*1e-2
n = kramers_kronig(ang_freq, abs_coef)
289/99:
def kramers_kronig(ang_freq, abs_coef):
    """ Apply the kramers kronig to the abs_coef to return the refractive in the given
    energy interval
    """
    n_data = np.ones_like(ang_freq)
    ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
    for index, denominator in enumerate(ang_freq[:, np.newaxis]**2 - ang_freq**2):
        # Create the lower and upper integration bounds
        l_bound, u_bound = denominator[:index], denominator[index+1:]
        l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
        # Integrate both bounds, considering the edge cases
        if index == 0:
            l_int = 0
        else:
            l_int = sci.simpson(l_abs_bound/l_bound, ang_freq[:index])
        if index > len(energy) - 2:
            u_int = 0
        else:
            u_int = sci.simpson(u_abs_bound/u_bound, ang_freq[index+1:])
        # The 100 converts c0 to cm/s
        n_data[index] += ((100*scc.c)/scc.pi)*(l_int+u_int)
    return n_data
289/100:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*1e-2
n = kramers_kronig(ang_freq, abs_coef)
289/101: plt.plot(n)
289/102: plt.plot(energy, n)
289/103:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*0.1# Multiply by 1e19 density
n = kramers_kronig(ang_freq, abs_coef)
289/104: plt.plot(energy, n)
289/105:
def kramers_kronig(ang_freq, abs_coef):
    """ Apply the kramers kronig to the abs_coef to return the refractive in the given
    energy interval
    """
    n_data = np.ones_like(ang_freq)
    ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
    for index, denominator in enumerate(ang_freq[:, np.newaxis]**2 - ang_freq**2):
        # Create the lower and upper integration bounds
        l_bound, u_bound = denominator[:index], denominator[index+1:]
        l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
        # Integrate both bounds, considering the edge cases
        if index == 0:
            l_int = 0
        else:
            l_int = -sci.simpson(l_abs_bound/l_bound, ang_freq[:index])
        if index > len(energy) - 2:
            u_int = 0
        else:
            u_int = -sci.simpson(u_abs_bound/u_bound, ang_freq[index+1:])
        # The 100 converts c0 to cm/s
        n_data[index] += ((100*scc.c)/scc.pi)*(l_int+u_int)
    return n_data
289/106:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*0.1# Multiply by 1e19 density
n = kramers_kronig(ang_freq, abs_coef)
289/107: plt.plot(energy, n)
289/108: plt.plot(energy, n, energy, absorption)
289/109: plt.plot(energy, n)
289/110: plt.plot(energy, absorption)
289/111: plt.plot(energy, absorption);
289/112: plt.plot(energy, absorption["Total"]);
289/113:
energy = np.linspace(0.5, 4, 600)
sim_properties = (15, 0.65, 2.10, (7.9e-25, 5.1e25))
absorption = ab.interband_absorption(energy, (2.96, 0.82, 0.12, 0.12), (2.96, 0.89, 0.10, 0.10), sim_properties, peak_dispersion=0.05)
289/114: absorption
289/115:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption["Total"])
plt.ylabel("Absorption per Density")
plt.xlabel("Energy (eV)")
289/116:
def kramers_kronig(ang_freq, abs_coef):
    """ Apply the kramers kronig to the abs_coef to return the refractive in the given
    energy interval
    """
    n_data = np.ones_like(ang_freq)
    ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
    for index, denominator in enumerate(ang_freq[:, np.newaxis]**2 - ang_freq**2):
        # Create the lower and upper integration bounds
        l_bound, u_bound = denominator[:index], denominator[index+1:]
        l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
        # Integrate both bounds, considering the edge cases
        if index == 0:
            l_int = 0
        else:
            l_int = -sci.simpson(l_abs_bound/l_bound, ang_freq[:index])
        if index > len(energy) - 2:
            u_int = 0
        else:
            u_int = -sci.simpson(u_abs_bound/u_bound, ang_freq[index+1:])
        # The 100 converts c0 to cm/s
        n_data[index] += ((100*scc.c)/scc.pi)*(l_int+u_int)
    return n_data
289/117:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*0.1# Multiply by 1e19 density
n = kramers_kronig(ang_freq, abs_coef)
289/118: plt.plot(energy, n)
289/119: plt.plot(energy, absorption["Total"]);
289/120: plt.plot(energy, absorption["Total"]*0.1);
289/121:
def kramers_kronig(ang_freq, abs_coef):
    """ Apply the kramers kronig to the abs_coef to return the refractive in the given
    energy interval
    """
    n_data = np.ones_like(ang_freq)
    ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
    for index, denominator in enumerate(ang_freq[:, np.newaxis]**2 - ang_freq**2):
        # Create the lower and upper integration bounds
        l_bound, u_bound = denominator[:index], denominator[index+1:]
        l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
        # Integrate both bounds, considering the edge cases
        if index == 0:
            l_int = 0
        else:
            l_int = sci.simpson(l_abs_bound/l_bound, ang_freq[:index])
        if index > len(energy) - 2:
            u_int = 0
        else:
            u_int = sci.simpson(u_abs_bound/u_bound, ang_freq[index+1:])
        # The 100 converts c0 to cm/s
        n_data[index] += ((100*scc.c)/scc.pi)*(l_int+u_int)
    return n_data
289/122:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*0.1# Multiply by 1e19 density
n = kramers_kronig(ang_freq, abs_coef)
289/123: plt.plot(energy, n)
289/124: plt.plot(ang_freq, n)
289/125:
def kramers_kronig(ang_freq, abs_coef):
    """ Apply the kramers kronig to the abs_coef to return the refractive in the given
    energy interval
    """
    n_data = np.ones_like(ang_freq)
    ang_freq_array = np.broadcast_to(ang_freq, (ang_freq.size, ang_freq.size))
    for index, denominator in enumerate(-ang_freq[:, np.newaxis]**2 + ang_freq**2):
        # Create the lower and upper integration bounds
        l_bound, u_bound = denominator[:index], denominator[index+1:]
        l_abs_bound, u_abs_bound = abs_coef[:index], abs_coef[index+1:]
        # Integrate both bounds, considering the edge cases
        if index == 0:
            l_int = 0
        else:
            l_int = sci.simpson(l_abs_bound/l_bound, ang_freq[:index])
        if index > len(energy) - 2:
            u_int = 0
        else:
            u_int = sci.simpson(u_abs_bound/u_bound, ang_freq[index+1:])
        # The 100 converts c0 to cm/s
        n_data[index] += ((100*scc.c)/scc.pi)*(l_int+u_int)
    return n_data
289/126:
ang_freq = energy*scc.e/scc.hbar
abs_coef = absorption["Total"].values*0.1# Multiply by 1e19 density
n = kramers_kronig(ang_freq, abs_coef)
289/127: plt.plot(ang_freq, n)
289/128: plt.plot((scc.h*scc.c)/(scc.hbar*ang_freq), n)
289/129:
plt.figure(figsize=(10, 6), font="Arial", fontsize=20)
plt.plot(absorption["Energy"], absorption["Total"])
plt.ylabel("Absorption per Density")
plt.xlabel("Energy (eV)")
289/130:
plt.figure(figsize=(10, 6), fontsize=20)
plt.plot(absorption["Energy"], absorption["Total"])
plt.ylabel("Absorption per Density")
plt.xlabel("Energy (eV)")
289/131:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption["Total"])
plt.ylabel("Absorption per Density", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
289/132:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption["Total"], fontsize=20)
plt.ylabel("Absorption per Density", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
289/133:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption["Total"])
plt.yticks(fontsize=16)
plt.ylabel("Absorption per Density", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
289/134:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption["Total"])
plt.yticks(fontsize=16)
plt.xticks(fontsize=16)
plt.ylabel("Absorption per Density", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
289/135:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption["Total"])
plt.yticks(fontsize=16)
plt.xticks(fontsize=16)
plt.ylabel("Absorption per Density (nm^3/cm)", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
289/136:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption["Total"])
plt.yticks(fontsize=16)
plt.xticks(fontsize=16)
plt.ylabel("Absorption per Density (nm$^3$/cm)", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
289/137:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption["Total"])
plt.yticks(fontsize=16)
plt.xticks(fontsize=16)
plt.ylabel("Absorption per Density (nm$^3$/cm)", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
plt.savefig("Optimized_absorption.svg")
289/138: qbd.qd_results(2.96, 0.82, 0.12, 0.12, "CB1").e_levels
289/139: qbd.qd_results(2.96, 0.89, 0.10, 0.10, "VB1").e_levels
289/140:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption)
plt.yticks(fontsize=16)
plt.xticks(fontsize=16)
plt.ylabel("Absorption per Density (nm$^3$/cm)", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
plt.savefig("Optimized_absorption.svg")
289/141:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption["Total"])
plt.plot(absorption["Energy"], absorption.iloc[:, 2:)
plt.yticks(fontsize=16)
plt.xticks(fontsize=16)
plt.ylabel("Absorption per Density (nm$^3$/cm)", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
plt.savefig("Optimized_absorption.svg")
289/142:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption["Total"])
plt.plot(absorption["Energy"], absorption.iloc[:, 2:])
plt.yticks(fontsize=16)
plt.xticks(fontsize=16)
plt.ylabel("Absorption per Density (nm$^3$/cm)", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
plt.savefig("Optimized_absorption.svg")
289/143: absorption.iloc[:, 2:]
289/144:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption["Total"], color="black")
plt.plot(absorption["Energy"], absorption.iloc[:, 2:])
plt.yticks(fontsize=16)
plt.xticks(fontsize=16)
plt.ylabel("Absorption per Density (nm$^3$/cm)", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
plt.savefig("Optimized_absorption.svg")
289/145:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption.iloc[:, 2:])
plt.plot(absorption["Energy"], absorption["Total"], color="black")
plt.yticks(fontsize=16)
plt.xticks(fontsize=16)
plt.ylabel("Absorption per Density (nm$^3$/cm)", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
plt.savefig("Optimized_absorption.svg")
289/146: -qbd.qd_results(2.96, 0.89, 0.10, 0.10, "VB1").e_levels
289/147: 0.89 +0.4 + (0.82 + qbd.qd_results(2.96, 0.82, 0.12, 0.12, "CB1").e_levels)
289/148: absorption.to_csv("asdfas.csv")
289/149:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption.iloc[:, 2:])
plt.plot(absorption["Energy"], absorption["Total"], color="black")
plt.legend()
plt.yticks(fontsize=16)
plt.xticks(fontsize=16)
plt.ylabel("Absorption per Density (nm$^3$/cm)", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
plt.savefig("Optimized_absorption.svg")
289/150:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption.iloc[:, 2:])
plt.plot(absorption["Energy"], absorption["Total"], color="black", label="Total")
plt.legend()
plt.yticks(fontsize=16)
plt.xticks(fontsize=16)
plt.ylabel("Absorption per Density (nm$^3$/cm)", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
plt.savefig("Optimized_absorption.svg")
289/151:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption.iloc[:, 2:], label=absorption.keys)
plt.plot(absorption["Energy"], absorption["Total"], color="black", label="Total")
plt.legend()
plt.yticks(fontsize=16)
plt.xticks(fontsize=16)
plt.ylabel("Absorption per Density (nm$^3$/cm)", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
plt.savefig("Optimized_absorption.svg")
289/152: absorption.keys
289/153: absorption.keys()
289/154: list(absorption.keys())
289/155: list(absorption.keys())[2:]
289/156:
plt.figure(figsize=(10, 6))
plt.plot(absorption["Energy"], absorption.iloc[:, 2:], label=list(absorption.keys())[2:])
plt.plot(absorption["Energy"], absorption["Total"], color="black", label="Total")
plt.legend()
plt.yticks(fontsize=16)
plt.xticks(fontsize=16)
plt.ylabel("Absorption per Density (nm$^3$/cm)", fontsize=20)
plt.xlabel("Energy (eV)", fontsize=20)
plt.savefig("Optimized_absorption.svg")
289/157: absorption
289/158: res
289/159: 2.1 + qbd.qd_results(2.96, 0.82, 0.12, 0.12, "CB1").e_levels
289/160:
tol = 0.05 # Toleranve for the Monte Carlo Simulation (5% variation)
n_rnd = 200
me = np.random.uniform((1-tol)*0.12, (1+tol)*0.12, size=(n_rnd))
mh = np.random.uniform((1-tol)*0.10, (1+tol)*0.10, size=(n_rnd))
qd_size = np.random.uniform((1-tol)*2.96, (1+tol)*2.96, size=(n_rnd))
Pl = np.random.uniform((1-tol)*7.9e-25,(1+tol)*7.9e-25, size=(n_rnd))
Pt = np.random.uniform((1-tol)*5.1e-25,(1+tol)*5.1e-25, size=(n_rnd))
Eg = np.random.uniform((1-tol)*2.1, (1+tol)*2.1, size=(n_rnd))
offset = np.random.uniform((1-tol)*0.48, (1+tol)*0.48, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

const_args = {
    "energy": np.linspace(0.5, 4, 600),
    "lat_size": 0.65,
    "sim_size": 15
}

# Run all the random iterations
opt_function(qd_size, me, mh, Pl, Pt, Eg, offset, **const_args)
289/161:
tol = 0.05 # Toleranve for the Monte Carlo Simulation (5% variation)
n_rnd = 200
me = np.random.uniform((1-tol)*0.12, (1+tol)*0.12, size=(n_rnd))
mh = np.random.uniform((1-tol)*0.10, (1+tol)*0.10, size=(n_rnd))
qd_size = np.random.uniform((1-tol)*2.96, (1+tol)*2.96, size=(n_rnd))
Pl = np.random.uniform((1-tol)*7.9e-25,(1+tol)*7.9e-25, size=(n_rnd))
Pt = np.random.uniform((1-tol)*5.1e-25,(1+tol)*5.1e-25, size=(n_rnd))
Eg = np.random.uniform((1-tol)*2.1, (1+tol)*2.1, size=(n_rnd))
offset = np.random.uniform((1-tol)*0.48, (1+tol)*0.48, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

const_args = {
    "energy": np.linspace(0.5, 4, 600),
    "lat_size": 0.65,
    "sim_size": 15
}

# Run all the random iterations
ab.opt_function(qd_size, me, mh, Pl, Pt, Eg, offset, **const_args)
289/162: mc_res = _
289/163: mc_res
289/164: mc_series = pd.Series(mc_res)
289/165:
mc_series = pd.Series(mc_res)
mc_series
289/166:
import seaborn as sns
plt.rcParams["font.size"] = 16
289/167:
mc_series = pd.Series(mc_res)
sns.distplot(mc_series, bins=100)
289/168:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(mc_res)
sns.distplot(mc_series, bins=100)
289/169:
%aimport band_model.pso.pso
from band_model.pso.pso import particle_swarm
from band_model.utils.absorption import opt_function
from multiprocessing import Pool
import multiprocessing
from functools import partial
289/170: ab._single_FoM(2.96, 0.82, 0.89, 0.12, 0.10, 7.9e-25, 5.1e-25, 2.1, 0.48)
289/171: res
289/172:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(mc_res)
sns.histplot(mc_series, bins=100)
289/173:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(mc_res)
sns.histplot(mc_series, bins=100)
plt.xlabel("FoM")
289/174:
tol = 0.1 # Toleranve for the Monte Carlo Simulation (5% variation)
n_rnd = 10000
me = np.random.uniform((1-tol)*0.12, (1+tol)*0.12, size=(n_rnd))
mh = np.random.uniform((1-tol)*0.10, (1+tol)*0.10, size=(n_rnd))
qd_size = np.random.uniform((1-tol)*2.96, (1+tol)*2.96, size=(n_rnd))
Pl = np.random.uniform((1-tol)*7.9e-25,(1+tol)*7.9e-25, size=(n_rnd))
Pt = np.random.uniform((1-tol)*5.1e-25,(1+tol)*5.1e-25, size=(n_rnd))
Eg = np.random.uniform((1-tol)*2.1, (1+tol)*2.1, size=(n_rnd))
offset = np.random.uniform((1-tol)*0.48, (1+tol)*0.48, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

const_args = {
    "energy": np.linspace(0.5, 4, 600),
    "lat_size": 0.65,
    "sim_size": 15
}

# Run all the random iterations
mc_res = ab.opt_function(qd_size, me, mh, Pl, Pt, Eg, offset, **const_args)
291/1:
%load_ext autoreload
%autoreload 1
%matplotlib inline
291/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import scipy.interpolate as scin

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
291/3:
tol = 0.1 # Toleranve for the Monte Carlo Simulation (5% variation)
n_rnd = 1000
me = np.random.uniform((1-tol)*0.12, (1+tol)*0.12, size=(n_rnd))
mh = np.random.uniform((1-tol)*0.10, (1+tol)*0.10, size=(n_rnd))
qd_size = np.random.uniform((1-tol)*2.96, (1+tol)*2.96, size=(n_rnd))
Pl = np.random.uniform((1-tol)*7.9e-25,(1+tol)*7.9e-25, size=(n_rnd))
Pt = np.random.uniform((1-tol)*5.1e-25,(1+tol)*5.1e-25, size=(n_rnd))
Eg = np.random.uniform((1-tol)*2.1, (1+tol)*2.1, size=(n_rnd))
offset = np.random.uniform((1-tol)*0.48, (1+tol)*0.48, size=(n_rnd)) # This is to determine the % of Eg divided for VB and CB

const_args = {
    "energy": np.linspace(0.5, 4, 600),
    "lat_size": 0.65,
    "sim_size": 15
}

# Run all the random iterations
mc_res = ab.opt_function(qd_size, me, mh, Pl, Pt, Eg, offset, **const_args)
292/1:
def my_func(x, y):
    return x+y
292/2: my_func(10, 9)
292/3:
def my_func(x, y):
    if x > 10:
        x = x - 10
    return x+y
292/4: my_func(10, 9)
292/5: my_func(11, 9)
291/4:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(mc_res)
sns.histplot(mc_series, bins=100)
plt.xlabel("FoM")
291/5: import seaborn as sns
291/6:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(mc_res)
sns.histplot(mc_series, bins=100)
plt.xlabel("FoM")
291/7:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(mc_res)
sns.distplot(mc_series, bins=100)
plt.xlabel("FoM")
291/8:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(mc_res)
sns.distplot(mc_series, bins=100)
plt.xlabel("FoM", fontsize=20)
291/9:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(mc_res)
sns.distplot(mc_series, bins=100)
plt.xlabel("FoM", fontsize=20)
plt.ylabel(fontsize=20)
291/10:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(mc_res)
sns.distplot(mc_series, bins=100)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
291/11:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(mc_res)
sns.distplot(mc_series, bins=100)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.ticks(fontsize=20)
291/12:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(mc_res)
sns.distplot(mc_series, bins=100)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=20)
291/13:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(mc_res)
sns.distplot(mc_series, bins=100)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
291/14: plt.savefig?
291/15:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(mc_res)
sns.distplot(mc_series, bins=100)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
plt.savefig("Optimized_Dist.svg", transparent=True)
291/16: pd.read_csv("results_29.csv")
291/17: pd.read_csv("results_29")
291/18: pd.read_csv("results_29", sep=" ")
291/19:
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
pd.read_csv("results_29", sep=" ", columns=columns)
291/20:
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
pd.read_csv("results_29", sep=" ", column=columns)
291/21:
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
pd.read_csv("results_29", sep=" ", names=columns)
291/22:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data = data.iloc[:,:7]
291/23:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data = data.iloc[:,:7]
data
291/24:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data = data.iloc[:,:7]
dict(data.to_records(index=False))
291/25:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data = data.iloc[:,:7]
data.to_records(index=False)
291/26:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data = data.iloc[:,:7]
data.to_dict(index=False)
291/27:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data = data.iloc[:,:7]
data.to_dict()
291/28: df.to_dict?
291/29: DataFrame.to_dict?
291/30: pd.DataFrame.to_dict?
291/31:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data = data.iloc[:,:7]
data.to_dict(orient="list")
291/32:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data = data.iloc[:,:7]
data.to_dict(orient="records")
291/33:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data = data.iloc[:,:7]
best_info = data.to_dict(orient="records")
291/34: best_info
291/35: ab.interband_absorption?
291/36:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
for data_i in data:
    print(data)
291/37:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
for data_i in data.rows:
    print(data)
291/38:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
for data_i in data.rows:
    print(data_i)
291/39:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
for data_i in data.row:
    print(data_i)
291/40:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
for data_i in data:
    print(data_i)
291/41:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
for data_i in data.iterrows():
    print(data_i)
291/42:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
for data_i in data.iterrows():
    Vcb = (data_i["Eg"] - 0.4)*data_i["offset"]
    Vvb = (data_i["Eg"] - 0.4)*(1-data_i["offset"])
    qd_cb = (data_i["QSize"], Vcb, data_i["me"], data_i["me"])
    qd_vb = (data_i["QSize"], Vvb, data_i["mh"], data_i["mh"])
    sim_properties = (15, 0.65, data_i["Eg"], (data_i["Pl"], data_i["Pt"]))
    print(qd_cb, qd_vb, sim_properties)
291/43:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
for data_i in data.iterrows():
    print(data_i)
    Vcb = (data_i["Eg"] - 0.4)*data_i["offset"]
    Vvb = (data_i["Eg"] - 0.4)*(1-data_i["offset"])
    qd_cb = (data_i["QSize"], Vcb, data_i["me"], data_i["me"])
    qd_vb = (data_i["QSize"], Vvb, data_i["mh"], data_i["mh"])
    sim_properties = (15, 0.65, data_i["Eg"], (data_i["Pl"], data_i["Pt"]))
    print(qd_cb, qd_vb, sim_properties)
291/44: pd.DataFrame.to_tuple?
291/45: pd.DataFrame.to_records?
291/46: pd.DataFrame.to_dict
291/47: pd.DataFrame.to_dict?
291/48:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data["QD"] = (data_i["QSize"], (data_i["Eg"] - 0.4)*data_i["offset"], data_i["me"], data_i["me"])
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
# for data_i in data.iterrows():
#     print(data_i)
#     Vcb = (data_i["Eg"] - 0.4)*data_i["offset"]
#     Vvb = (data_i["Eg"] - 0.4)*(1-data_i["offset"])
#     qd_cb = (data_i["QSize"], Vcb, data_i["me"], data_i["me"])
#     qd_vb = (data_i["QSize"], Vvb, data_i["mh"], data_i["mh"])
#     sim_properties = (15, 0.65, data_i["Eg"], (data_i["Pl"], data_i["Pt"]))
#     print(qd_cb, qd_vb, sim_properties)
291/49:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
das = (data_i["QSize"], (data_i["Eg"] - 0.4)*data_i["offset"], data_i["me"], data_i["me"])
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
# for data_i in data.iterrows():
#     print(data_i)
#     Vcb = (data_i["Eg"] - 0.4)*data_i["offset"]
#     Vvb = (data_i["Eg"] - 0.4)*(1-data_i["offset"])
#     qd_cb = (data_i["QSize"], Vcb, data_i["me"], data_i["me"])
#     qd_vb = (data_i["QSize"], Vvb, data_i["mh"], data_i["mh"])
#     sim_properties = (15, 0.65, data_i["Eg"], (data_i["Pl"], data_i["Pt"]))
#     print(qd_cb, qd_vb, sim_properties)
291/50:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
for data_i in data.iterrows():
    print(data_i)
    Vcb = (data_i["Eg"] - 0.4)*data_i["offset"]
    Vvb = (data_i["Eg"] - 0.4)*(1-data_i["offset"])
    qd_cb = (data_i["QSize"], Vcb, data_i["me"], data_i["me"])
    qd_vb = (data_i["QSize"], Vvb, data_i["mh"], data_i["mh"])
    sim_properties = (15, 0.65, data_i["Eg"], (data_i["Pl"], data_i["Pt"]))
    print(qd_cb, qd_vb, sim_properties)
291/51:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
for data_i in data.apply(tuple):
    print(data_i)
    Vcb = (data_i["Eg"] - 0.4)*data_i["offset"]
    Vvb = (data_i["Eg"] - 0.4)*(1-data_i["offset"])
    qd_cb = (data_i["QSize"], Vcb, data_i["me"], data_i["me"])
    qd_vb = (data_i["QSize"], Vvb, data_i["mh"], data_i["mh"])
    sim_properties = (15, 0.65, data_i["Eg"], (data_i["Pl"], data_i["Pt"]))
    print(qd_cb, qd_vb, sim_properties)
291/52:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
for data_i in data.apply(tuple, axis=1):
    print(data_i)
    Vcb = (data_i["Eg"] - 0.4)*data_i["offset"]
    Vvb = (data_i["Eg"] - 0.4)*(1-data_i["offset"])
    qd_cb = (data_i["QSize"], Vcb, data_i["me"], data_i["me"])
    qd_vb = (data_i["QSize"], Vvb, data_i["mh"], data_i["mh"])
    sim_properties = (15, 0.65, data_i["Eg"], (data_i["Pl"], data_i["Pt"]))
    print(qd_cb, qd_vb, sim_properties)
291/53:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
for data_i in data.apply(tuple, axis=1):
    Vcb = (data_i[5] - 0.4)*data_i[6]
    Vvb = (data_i[5] - 0.4)*(1-data_i[6])
    qd_cb = (data_i[0], Vcb, data_i[1], data_i[1])
    qd_vb = (data_i[0], Vvb, data_i[2], data_i[2])
    sim_properties = (15, 0.65, data_i[5], (data_i[3], data_i[4]))
    print(qd_cb, qd_vb, sim_properties)
291/54:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
results = []
for data_i in data.apply(tuple, axis=1):
    Vcb = (data_i[5] - 0.4)*data_i[6]
    Vvb = (data_i[5] - 0.4)*(1-data_i[6])
    qd_cb = (data_i[0], Vcb, data_i[1], data_i[1])
    qd_vb = (data_i[0], Vvb, data_i[2], data_i[2])
    sim_properties = (15, 0.65, data_i[5], (data_i[3], data_i[4]))
    results.append(ab.interband_absorption(qd_cb, qd_vb, sim_properties))
291/55:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
# data = data.iloc[:,:7]
# best_info = data.to_dict(orient="records") # Unfortunately did not work..
energy = np.linspace(0.5, 4, 600)
results = []
for data_i in data.apply(tuple, axis=1):
    Vcb = (data_i[5] - 0.4)*data_i[6]
    Vvb = (data_i[5] - 0.4)*(1-data_i[6])
    qd_cb = (data_i[0], Vcb, data_i[1], data_i[1])
    qd_vb = (data_i[0], Vvb, data_i[2], data_i[2])
    sim_properties = (15, 0.65, data_i[5], (data_i[3], data_i[4]))
    results.append(ab.interband_absorption(energy, qd_cb, qd_vb, sim_properties))
291/56:
fig, ax = plt.subplots(3, 5, figsize=(9,7))
list(ax)
291/57:
fig, ax = plt.subplots(3, 5, figsize=(15,10))
list(ax)
291/58: results
291/59:
for i in range(3):
    for j in range(5):
        print(i+j
291/60:
for i in range(3):
    for j in range(5):
        print(i+j)
291/61:
for i in range(3):
    for j in range(5):
        print(i*j)
291/62:
for i in range(3):
    for j in range(5):
        print((i+1)*j+j)
291/63:
for i in range(3):
    for j in range(5):
        print(i*j+j)
291/64:
for i in range(3):
    for j in range(5):
        print(i*j)
291/65:
for i in range(3):
    for j in range(5):
        print((i+1)*j)
291/66:
for i in range(3):
    for j in range(5):
        print(i*(j+i))
291/67:
for i in range(3):
    line_index = 0
    for j in range(5):
        print(line_index + j)
    line_index += 5
291/68:
line_index = 0
for i in range(3):
    for j in range(5):
        print(line_index + j)
    line_index += 5
291/69: np.arange(0, 15).reshape(3, 15)
291/70: np.arange(0, 16).reshape(3, 15)
291/71: np.arange(0, 16).reshape(3, 5)
291/72: np.arange(0, 15).reshape(3, 5)
291/73:
fig, ax = plt.subplots(3, 5, figsize=(15,10))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, j].plot(results[flat_index[i, j]]["Total"])
291/74:
fig, ax = plt.subplots(3, 5, figsize=(15,10))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        print(flat_index[i, j])
        ax[i, j].plot(results[flat_index[i, j]]["Total"])
291/75:
fig, ax = plt.subplots(3, 5, figsize=(15,10))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
291/76:
fig, ax = plt.subplots(3, 5, figsize=(20,15))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)")
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)")
291/77:
fig, ax = plt.subplots(3, 5, figsize=(20,15))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax.set_yticks(fontsize=14)
        ax.set_xticks(fontsize=14)
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=20)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=20)
291/78:
fig, ax = plt.subplots(3, 5, figsize=(20,15))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=20)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=20)
291/79:
fig, ax = plt.subplots(3, 5, figsize=(20,10))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=20)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=20)
291/80:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=20)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=20)
291/81:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={results[flat_index[i, k]]["FoM"]}")
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=20)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=20)
291/82: data
291/83:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data.iloc[flat_index[i, k], "FoM"]}")
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=20)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=20)
291/84:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data.iloc[flat_index[i, k], 'FoM']}")
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=20)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=20)
291/85: data.iloc[3,'FoM']
291/86: data.loc['FoM']
291/87: data["FoM"]
291/88: data["FoM"][10]
291/89:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]}")
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=20)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=20)
291/90:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}")
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=20)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=20)
291/91:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}", fontsize=20)
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=16)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=16)
291/92:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}", fontsize=18)
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=16)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=16)
291/93:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}", fontsize=18)
        ax.set_xtics(labelsize=15)
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=16)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=16)
291/94:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}", fontsize=18)
        ax.set_xticks(labelsize=15)
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=16)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=16)
291/95:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}", fontsize=18)
        ax[i, k].set_xticks(labelsize=15)
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=16)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=16)
291/96:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}", fontsize=18)
        ax[i, k].tick_params(labelsize=15)
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=16)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=16)
291/97:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}", fontsize=18)
        ax[i, k].tick_params(labelsize=14)
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=16)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=16)
291/98:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}", fontsize=18)
        ax[i, k].tick_params(labelsize=14)
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=16)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=16)
plt.savefig("Absorption_Coefs.svg", transparent=True)
291/99: data
291/100:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
plt.suplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
    ax[0].set_ylabel("Variable")
    plt.savefig("Hist_2.svg")
291/101:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
    ax[0].set_ylabel("Variable")
    plt.savefig("Hist_2.svg")
291/102:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
    ax[0].set_ylabel("Variable")
    plt.savefig("Hist_2.svg")
291/103:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90)
    ax[index].set_ylabel("")
    ax[index].set_title(variable)
    ax[0].set_ylabel("Variable")
    plt.savefig("Hist_2.svg")
291/104:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, fontsize=14)
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/105:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=14)
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/106:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12)
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/107:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10), wspace=3)
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12)
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/108:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10), subplot_kw={"wspace"=3})
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12)
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/109:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12)
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/110:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10), gridspec_kw={"wspace":2})
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12)
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/111:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10), gridspec_kw={"wspace":0.5})
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12)
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/112:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10), gridspec_kw={"wspace":0.5})
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/113:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/114:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].major_ticklabels.set_va("center")
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/115:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_major_ticklabels.set_va("center")
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/116:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].xaxis.ticks_center()
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/117:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/118:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_xlabel(fontsize=18)
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/119:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_xlabel("Count", fontsize=18)
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
#plt.savefig("Hist_2.svg")
291/120:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=50, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_xlabel("Count", fontsize=18)
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
plt.savefig("Best_Particles.svg", transparent=True)
291/121:
# Plot all the parameters just for the last iteration
columns=["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
for index, variable in enumerate(columns[:7]):
    chart = sns.histplot(data=data,y=variable,color=colors[index], kde=True, bins=150, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_xlabel("Count", fontsize=18)
    ax[index].set_title(variable, fontsize=18)
ax[0].set_ylabel("Variable", fontsize=16)
plt.savefig("Best_Particles.svg", transparent=True)
291/122: data.apply(tuple, axis=1)
291/123: data.apply(tuple, axis=1).reshape(-1)
291/124: data.apply(tuple, axis=1).values.reshape(-1)
291/125: data.apply(tuple, axis=1).values
291/126: data.apply(tuple, axis=1).values.reshape(3, 5)
291/127:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(ordered_data):
        print(i, j)
        
# results = []
# for data_i in enumerate(data.apply(tuple, axis=1)):
#     Vcb = (data_i[5] - 0.4)*data_i[6]
#     Vvb = (data_i[5] - 0.4)*(1-data_i[6])
#     qd_cb = qbd.qd_results(data_i[0], Vcb, data_i[1], data_i[1])
#     qd_vb = qbd.qd_results(data_i[0], Vvb, data_i[2], data_i[2])
291/128:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(ordered_data):
        Vcb = (data_i[5] - 0.4)*data_i[6]
        Vvb = (data_i[5] - 0.4)*(1-data_i[6])
        # qd_cb = qbd.qd_results(data_i[0], Vcb, data_i[1], data_i[1])
        # qd_vb = qbd.qd_results(data_i[0], Vvb, data_i[2], data_i[2])
        print(column)
291/129:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(ordered_data):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1])
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2])
        for e_cb in qd_cv.e_levels.values.flatten():
            print(e_cb)
291/130:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(ordered_data):
        print(column)
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1])
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2])
        for e_cb in qd_cv.e_levels.values.flatten():
            print(e_cb)
291/131:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(ordered_data):
        print(len(column))
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1])
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2])
        for e_cb in qd_cv.e_levels.values.flatten():
            print(e_cb)
291/132:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(ordered_data):
        print(len(column))
        # Vcb = (column[5] - 0.4)*column[6]
        # Vvb = (column[5] - 0.4)*(1-column[6])
        # qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1])
        # qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2])
        # for e_cb in qd_cv.e_levels.values.flatten():
        #     print(e_cb)
291/133:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(ordered_data):
        print(column)
        # Vcb = (column[5] - 0.4)*column[6]
        # Vvb = (column[5] - 0.4)*(1-column[6])
        # qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1])
        # qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2])
        # for e_cb in qd_cv.e_levels.values.flatten():
        #     print(e_cb)
291/134:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
print(ordered_data)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(ordered_data):
        print(column)
        # Vcb = (column[5] - 0.4)*column[6]
        # Vvb = (column[5] - 0.4)*(1-column[6])
        # qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1])
        # qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2])
        # for e_cb in qd_cv.e_levels.values.flatten():
        #     print(e_cb)
291/135:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(ordered_data):
        print(column)
        # Vcb = (column[5] - 0.4)*column[6]
        # Vvb = (column[5] - 0.4)*(1-column[6])
        # qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1])
        # qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2])
        # for e_cb in qd_cv.e_levels.values.flatten():
        #     print(e_cb)
291/136: data.apply(tuple, axis=1).values
291/137: data.apply(tuple, axis=1).values.reshape(3, 5)
291/138: data.apply(tuple, axis=1).values.shape
291/139: data.apply(tuple, axis=1).values.reshape(3, 5).shape
291/140:
for i in data.apply(tuple, axis=1).values.reshape(3, 5):
    print(i)
291/141:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        print(column)
        # Vcb = (column[5] - 0.4)*column[6]
        # Vvb = (column[5] - 0.4)*(1-column[6])
        # qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1])
        # qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2])
        # for e_cb in qd_cv.e_levels.values.flatten():
        #     print(e_cb)
291/142:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        print(column)
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1])
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2])
        for e_cb in qd_cv.e_levels.values.flatten():
            print(e_cb)
291/143:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        print(column)
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        for e_cb in qd_cv.e_levels.values.flatten():
            print(e_cb)
291/144:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        for e_cb in qd_cb.e_levels.values.flatten():
            print(e_cb)
291/145:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].plot(e_cb)
291/146:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(e_cb)
291/147:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(e_cb)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(e_vb)
291/148:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb)
291/149:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        ax[i, j].set_xticks(None)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb)
291/150:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        ax[i, j].set_xticks(xticks=None)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb)
291/151:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        ax[i, j].set_xticks(ticks=None)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb)
291/152:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        ax[i, j].set_xticks(ticks=[9)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb)
291/153:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        ax[i, j].set_xticks(ticks=[])
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb)
291/154:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb, xmin=-0.25, xmax=0.25)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=-0.25, xmax=0.25)
291/155:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb, xmin=-0.25, xmax=0.25)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=-0.25, xmax=0.25)
291/156:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/157:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axline(0, xmin=0, xmax=0.25, color="b")
        ax[i, j].axline(column[5], xmin=0, xmax=0.25, color="b")
        ax[i, j].axline(0, xmin=0.65, xmax=1, color="b")
        ax[i, j].axline(column[5], xmin=0.65, xmax=1, color="b")
        # Mid Line
        ax[i, j].axline(Vvb, xmin=0.25, xmax=0.65, color="b")
        ax[i, j].axline(Vvb+0.4, xmin=0.25, xmax=0.65, color="b")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/158:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="b")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="b")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="b")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="b")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="b")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="b")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/159:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/160:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical berriers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vcb, color="k")
        ax[i, j].axvline(0.65, ymin=0, ymax=Vcb, color="k")
        ax[i, j].axvline(0.25, ymin=Vcb+0.4, ymax=column[5], color="k")
        ax[i, j].axvline(0.65, ymin=Vcb+0.4, ymax=column[5], color="k")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/161:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical berriers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vcb, color="k")
        ax[i, j].axvline(0.65, ymin=0, ymax=Vcb, color="k")
        ax[i, j].axvline(0.25, ymin=Vvb+0.4, ymax=column[5], color="k")
        ax[i, j].axvline(0.65, ymin=Vvb+0.4, ymax=column[5], color="k")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/162:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical berriers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vcb, color="k")
        ax[i, j].axvline(0.65, ymin=0, ymax=Vcb, color="k")
        ax[i, j].axvline(0.25, ymin=Vvb+0.4, ymax=column[6], color="k")
        ax[i, j].axvline(0.65, ymin=Vvb+0.4, ymax=column[6], color="k")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[6] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/163:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical berriers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vcb, color="k")
        ax[i, j].axvline(0.65, ymin=0, ymax=Vcb, color="k")
        ax[i, j].axvline(0.25, ymin=Vvb+0.4, ymax=column[5], color="k")
        ax[i, j].axvline(0.65, ymin=Vvb+0.4, ymax=column[5], color="k")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/164:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical berriers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vvb, color="k")
        ax[i, j].axvline(0.65, ymin=0, ymax=Vvb, color="k")
        ax[i, j].axvline(0.25, ymin=Vvb+0.4, ymax=column[5], color="k")
        ax[i, j].axvline(0.65, ymin=Vvb+0.4, ymax=column[5], color="k")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/165:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical berriers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vvb, color="k")
        ax[i, j].axvline(0.65, ymin=0, ymax=Vvb, color="k")
        # ax[i, j].axvline(0.25, ymin=Vvb+0.4, ymax=column[5], color="k")
        # ax[i, j].axvline(0.65, ymin=Vvb+0.4, ymax=column[5], color="k")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/166:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical berriers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vvb, color="k")
        # ax[i, j].axvline(0.65, ymin=0, ymax=Vvb, color="k")
        # ax[i, j].axvline(0.25, ymin=Vvb+0.4, ymax=column[5], color="k")
        # ax[i, j].axvline(0.65, ymin=Vvb+0.4, ymax=column[5], color="k")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/167:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical berriers
        ax[i, j].axvline(0.25, ymin=0, ymax=0.5, color="k")
        # ax[i, j].axvline(0.65, ymin=0, ymax=Vvb, color="k")
        # ax[i, j].axvline(0.25, ymin=Vvb+0.4, ymax=column[5], color="k")
        # ax[i, j].axvline(0.65, ymin=Vvb+0.4, ymax=column[5], color="k")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/168:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Define plot limits
        ax[i, j].set_ylim(0, column[5])
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical berriers
        ax[i, j].axvline(0.25, ymin=0, ymax=0.5, color="k")
        # ax[i, j].axvline(0.65, ymin=0, ymax=Vvb, color="k")
        # ax[i, j].axvline(0.25, ymin=Vvb+0.4, ymax=column[5], color="k")
        # ax[i, j].axvline(0.65, ymin=Vvb+0.4, ymax=column[5], color="k")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/169:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Define plot limits
        ax[i, j].set_ylim(0, column[5])
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical berriers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vvb/column[5], color="k")
        # ax[i, j].axvline(0.65, ymin=0, ymax=Vvb, color="k")
        # ax[i, j].axvline(0.25, ymin=Vvb+0.4, ymax=column[5], color="k")
        # ax[i, j].axvline(0.65, ymin=Vvb+0.4, ymax=column[5], color="k")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/170:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Define plot limits
        ax[i, j].set_ylim(0, column[5])
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical bariers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.65, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.25, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        ax[i, j].axvline(0.65, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        #ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/171:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Define plot limits
        ax[i, j].set_ylim(0, column[5])
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical bariers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.65, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.25, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        ax[i, j].axvline(0.65, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/172:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Define plot limits
        ax[i, j].set_ylim(0, column[5])
        ax[i, j].axis('off')
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical bariers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.65, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.25, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        ax[i, j].axvline(0.65, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/173:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Define plot limits
        ax[i, j].set_ylim(0, column[5])
        ax[i, j].spines['right'].set_visible(False)
        ax[i, j].spines['top'].set_visible(False)
        ax[i, j].spines['bottom'].set_visible(False)
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical bariers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.65, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.25, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        ax[i, j].axvline(0.65, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
291/174:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Define plot limits
        ax[i, j].set_ylim(0, column[5])
        ax[i, j].spines['right'].set_visible(False)
        ax[i, j].spines['top'].set_visible(False)
        ax[i, j].spines['bottom'].set_visible(False)
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical bariers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.65, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.25, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        ax[i, j].axvline(0.65, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        ax[i, j].set_xticks(ticks=[])
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)

plt.savefig("Band_diagrams.svg", transparent=True)
291/175:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Define plot limits
        ax[i, j].set_ylim(0, column[5])
        ax[i, j].spines['right'].set_visible(False)
        ax[i, j].spines['top'].set_visible(False)
        ax[i, j].spines['bottom'].set_visible(False)
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical bariers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.65, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.25, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        ax[i, j].axvline(0.65, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        ax[i, j].set_xticks(ticks=[])
        ac[i, j].tick_params(axis="y", labelsize=16)
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)

plt.savefig("Band_diagrams.svg", transparent=True)
291/176:
# Plot the energy profile for all the best particles
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
ordered_data = data.apply(tuple, axis=1).values.reshape(3, 5)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
x = np.linspace(0, 1, 50)
for i, line in enumerate(ordered_data):
    for j, column in enumerate(line):
        Vcb = (column[5] - 0.4)*column[6]
        Vvb = (column[5] - 0.4)*(1-column[6])
        qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
        qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
        # Define plot limits
        ax[i, j].set_ylim(0, column[5])
        ax[i, j].spines['right'].set_visible(False)
        ax[i, j].spines['top'].set_visible(False)
        ax[i, j].spines['bottom'].set_visible(False)
        # Create the band diagram from Eg, Vcb, Vvb
        # Left/Righ sides of the bands
        ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
        ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
        ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
        # Mid Line
        ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
        ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
        # Add vertical bariers
        ax[i, j].axvline(0.25, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.65, ymin=0, ymax=Vvb/column[5], color="k")
        ax[i, j].axvline(0.25, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        ax[i, j].axvline(0.65, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
        ax[i, j].set_xticks(ticks=[])
        ax[i, j].tick_params(axis="y", labelsize=16)
        # Plot the energy spectrum (from -0.25 to 0.25)
        for e_cb in qd_cb.e_levels.values.flatten():
            ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
        for e_vb in qd_vb.e_levels.values.flatten():
            ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)

plt.savefig("Band_diagrams.svg", transparent=True)
291/177:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[0]["Energy"], results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}", fontsize=18)
        ax[i, k].tick_params(labelsize=14)
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=16)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=16)
plt.savefig("Absorption_Coefs.svg", transparent=True)
291/178:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data
291/179:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM")
291/180:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", reverse=True)
291/181:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False)
291/182:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True)
291/183:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
291/184:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
data
291/185:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
data.loc[0]
291/186:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
data.loc[0][0]
291/187:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
data.loc[0]
291/188:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
data.loc[0]
qd_cb = qbd.qd_results(data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"],
                       data.loc[0]["me"], data.loc[0]["me"])
qd_vb = qbd.qd_results(data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*(1-data.loc[0]["offset"]),
                       data.loc[0]["mh"], data.loc[0]["mh"])
291/189:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
data.loc[0]
qd_cb = qbd.qd_results(data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"],
                       data.loc[0]["me"], data.loc[0]["me"], band="CB1")
qd_vb = qbd.qd_results(data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*(1-data.loc[0]["offset"]),
                       data.loc[0]["mh"], data.loc[0]["mh"], band="VB1")
291/190: qd_cb
291/191: qd_cb.e_levels
291/192: qd_vb.e_levels
291/193:
sim_setup = (15, 0.65, data.loc[0]["Eg"], (data.loc[0]["Pl"], data.loc[0]["Pt"]))
best_abs = ab.interband_absorption((data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"],
                       data.loc[0]["me"], data.loc[0]["me"]),
                        (data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*(1-data.loc[0]["offset"]),
                       data.loc[0]["mh"], data.loc[0]["mh"]), sim_setup)
291/194:
sim_setup = (15, 0.65, data.loc[0]["Eg"], (data.loc[0]["Pl"], data.loc[0]["Pt"]))
best_abs = ab.interband_absorption(np.linspace(0, 5, 600),
    (data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"], data.loc[0]["me"], data.loc[0]["me"]),
    (data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*(1-data.loc[0]["offset"], data.loc[0]["mh"], data.loc[0]["mh"]),
    , sim_setup)
291/195:
sim_setup = (15, 0.65, data.loc[0]["Eg"], (data.loc[0]["Pl"], data.loc[0]["Pt"]))
best_abs = ab.interband_absorption(np.linspace(0, 5, 600),
    (data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"], data.loc[0]["me"], data.loc[0]["me"]),
    (data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*(1-data.loc[0]["offset"]), data.loc[0]["mh"], data.loc[0]["mh"]),
    , sim_setup)
291/196:
sim_setup = (15, 0.65, data.loc[0]["Eg"], (data.loc[0]["Pl"], data.loc[0]["Pt"]))
best_abs = ab.interband_absorption(np.linspace(0, 5, 600),
    (data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"], data.loc[0]["me"], data.loc[0]["me"]),
    (data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*(1-data.loc[0]["offset"]), data.loc[0]["mh"], data.loc[0]["mh"]),
    sim_setup)
291/197: best_abs
291/198: best_abs["Total":]
291/199: best_abs[1:]
291/200: best_abs.iloc[:, 1:]
291/201:
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"])
291/202:
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"])
plt.yscale("log")
291/203:
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"])
plt.yscale("log")
plt.ylim((1e-6, 1e8))
291/204:
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"])
plt.yscale("log")
plt.ylim((1, 1e8))
291/205:
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"])
291/206:
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"])
plt.xlim((0.5, 2.5))
291/207:
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"])
plt.xlim((0.5, 2.5))
291/208:
sim_setup = (15, 0.65, data.loc[0]["Eg"], (data.loc[0]["Pl"], data.loc[0]["Pt"]))
qd1_prop = (data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"], data.loc[0]["me"], data.loc[0]["me"])
qd2_prop = (data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*(1-data.loc[0]["offset"]), data.loc[0]["mh"], data.loc[0]["mh"])

trn = ab.all_avg_trn_elements(qd1_prop, qd2_prop, sim_setup)
best_abs = ab.interband_absorption(np.linspace(0, 5, 600),qd1_prop, qd2_prop, sim_setup)
291/209:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"])
plt.xlim((0.5, 2.5))
291/210: trn
291/211: ab.avg_trn_elements(qd1_prop, qd2_prop, sim_setup, trn=15)
291/212:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k')
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.ticks_params(labelsize=16)
plt.xlim((0.5, 2.5))
291/213:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k')
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
291/214:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k')
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18, linewidth=2)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
291/215:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
291/216:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/217:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for name, value in zip(columns, data.loc[0]):
    print(name, value)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
# plt.savefig("real_best_abs.svg", transparent=True)
291/218:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    print(name, value)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
# plt.savefig("real_best_abs.svg", transparent=True)
291/219:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"{name}={value}", (0, 0)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
# plt.savefig("real_best_abs.svg", transparent=True)
291/220:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"{name}={value}", (0, 0))
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
# plt.savefig("real_best_abs.svg", transparent=True)
291/221:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"{name}={value}", (0, 0), fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
# plt.savefig("real_best_abs.svg", transparent=True)
291/222:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"{name}={value}", (3, 1e6), fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
# plt.savefig("real_best_abs.svg", transparent=True)
291/223:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"{name}={value}", (0.5, 0.5), xy_coords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
# plt.savefig("real_best_abs.svg", transparent=True)
291/224:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"{name}={value}", (0.5, 0.5), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
# plt.savefig("real_best_abs.svg", transparent=True)
291/225:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"{name}={value}", (0, 0.5), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
# plt.savefig("real_best_abs.svg", transparent=True)
291/226:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"{name}={value}", (0.1, 1-index/7), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
# plt.savefig("real_best_abs.svg", transparent=True)
291/227:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"{name}={value}", (0.1, 0.8-index/7), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
# plt.savefig("real_best_abs.svg", transparent=True)
291/228:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"{name}={value}", (0.05, 0.9-index/7), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
# plt.savefig("real_best_abs.svg", transparent=True)
291/229:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"{name}={value}", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
# plt.savefig("real_best_abs.svg", transparent=True)
291/230:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"\textbf{{name}}={value}", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/231:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"\\textbf{{name}}={value}", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/232:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\textbf{{name}}={value}$", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/233:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\textbf{{name}}={value}$", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/234:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\textbf{{name}}={value}$", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/235:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"\textbf{{name}}={value}", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/236:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"\\textbf{{name}}={value}", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/237:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"\\bf{{name}}={value}", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/238:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{{name}}={value}$", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/239:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{{name}}$={value}", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/240:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\bf{{name}}$={value}", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/241:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate("$\\bf{%s}$=%f".format(name, value), (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/242:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value}", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/243:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value}$\pm${value*0.05}", (0.05, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/244:
# See the best plot
plt.figure(figsize=(10, 8))
plt.plot(best_abs["Energy"], best_abs.iloc[:, 2:])
plt.plot(best_abs["Energy"], best_abs["Total"], color='k', linewidth=2)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.ylabel("Absorption Coefficient (nm$^3$/cm)", fontsize=18)
plt.xlabel("Energy (eV)", fontsize=18)
plt.tick_params(labelsize=16)
plt.xlim((0.5, 2.5))
plt.savefig("real_best_abs.svg", transparent=True)
291/245:
%load_ext autoreload
%autoreload 1
%matplotlib inline
%aimport band_model.pso.pso
291/246:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from band_model.pso.pso import particle_swarm

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import scipy.interpolate as scin

import matplotlib.pyplot as plt
import matplotlib.cm as cmb

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
291/247:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from band_model.pso.pso import particle_swarm

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import scipy.interpolate as scin

import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import seaborn as sns

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
291/248:
# Test different dispersions around the maximum value
best_abs.iloc[:, 2:]
291/249:
# Test different dispersions around the maximum value
data.iloc[:, 2:]
291/250:
# Test different dispersions around the maximum value
data.loc[0]
291/251:
# Test different dispersions around the maximum value
data.loc[0, :6]
291/252:
# Test different dispersions around the maximum value
data.loc[0][:6]
291/253:
# Test different dispersions around the maximum value
data.loc[0][:6].values
291/254:
# Test different dispersions around the maximum value
data.loc[0][:6]
291/255:
# Test different dispersions around the maximum value
data.loc[0][:6].to_dict("records")
291/256: pd.DataFrame.to_dict?
291/257:
# Test different dispersions around the maximum value
data.loc[0][:6].to_dict(orient="records")
291/258:
# Test different dispersions around the maximum value
data.loc[0][:6].to_dict(orient="dict")
291/259: pd.Series.to_dict?
291/260:
# Test different dispersions around the maximum value
data.loc[0][:6].to_dict()
291/261:
# Test different dispersions around the maximum value
data.loc[0][:7].to_dict()
291/262:
# Test different dispersions around the maximum value
best_res = data.loc[0][:7].to_dict()
best_res.update({"tol": 0.005. "n_rnd": 10, "kwargs": {
                "energy": np.linspace(0.5, 4, 400),
                "lat_size": 0.65,
                "sim_size": 15
}})
rnd_05 = ab.mc_random(**best_res)
291/263:
# Test different dispersions around the maximum value
best_res = data.loc[0][:7].to_dict()
best_res.update({"tol": 0.005, "n_rnd": 10, "kwargs": {
                "energy": np.linspace(0.5, 4, 400),
                "lat_size": 0.65,
                "sim_size": 15
}})
rnd_05 = ab.mc_random(**best_res)
291/264: best_res
291/265:
# Test different dispersions around the maximum value
best_res = data.loc[0][:7].to_dict()
# Change only QSize to qd_size
best_res["qd_size"] = best_res["QSize"]
best_res.pop("QSize")
best_res.update({"tol": 0.005, "n_rnd": 10, "kwargs": {
                "energy": np.linspace(0.5, 4, 400),
                "lat_size": 0.65,
                "sim_size": 15
}})
print(best_res)
rnd_05 = ab.mc_random(**best_res)
291/266:
# Test different dispersions around the maximum value
best_res = data.loc[0][:7].to_dict()
# Change only QSize to qd_size
best_res["qd_size"] = best_res["QSize"]
best_res.pop("QSize")
best_res.update({"tol": 0.005, "n_rnd": 10})
print(best_res)
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
rnd_05 = ab.mc_random(**best_res, **const_args)
291/267:
# Test different dispersions around the maximum value
# The ideia is to try and determine how much the maximum realy
# depends on each value...
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
best_res = data.loc[0][:7].to_dict()
# Change only QSize to qd_size
best_res["qd_size"] = best_res["QSize"]
best_res.pop("QSize")

# Call severall versions of the random variation around the maximum
print("Random 0.1%")
best_res.update({"tol": 0.001, "n_rnd": 500})
rnd_01 = ab.mc_random(**best_res, **const_args)
print("Random 0.5%")
best_res.update({"tol": 0.005, "n_rnd": 500})
rnd_05 = ab.mc_random(**best_res, **const_args)
print("Random 1%")
best_res.update({"tol": 0.01, "n_rnd": 500})
rnd_1 = ab.mc_random(**best_res, **const_args)
print("Random 5%")
best_res.update({"tol": 0.05, "n_rnd": 500})
rnd_5 = ab.mc_random(**best_res, **const_args)
291/268:
# Test different dispersions around the maximum value
# The ideia is to try and determine how much the maximum realy
# depends on each value...
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
best_res = data.loc[0][:7].to_dict()
# Change only QSize to qd_size
best_res["qd_size"] = best_res["QSize"]
best_res.pop("QSize")

# Call severall versions of the random variation around the maximum
print("Random 0.1%")
best_res.update({"tol": 0.001, "n_rnd": 500})
rnd_01 = ab.mc_random(**best_res, **const_args)
print("Random 0.5%")
best_res.update({"tol": 0.005, "n_rnd": 500})
rnd_05 = ab.mc_random(**best_res, **const_args)
print("Random 1%")
best_res.update({"tol": 0.01, "n_rnd": 500})
rnd_1 = ab.mc_random(**best_res, **const_args)
print("Random 5%")
best_res.update({"tol": 0.05, "n_rnd": 500})
rnd_5 = ab.mc_random(**best_res, **const_args)
293/1:
%load_ext autoreload
%autoreload 1
%matplotlib inline
%aimport band_model.pso.pso
293/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from band_model.pso.pso import particle_swarm

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import scipy.interpolate as scin

import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import seaborn as sns

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
293/3:
# Test different dispersions around the maximum value
# The ideia is to try and determine how much the maximum realy
# depends on each value...
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
best_res = data.loc[0][:7].to_dict()
# Change only QSize to qd_size
best_res["qd_size"] = best_res["QSize"]
best_res.pop("QSize")

# Call severall versions of the random variation around the maximum
print("Random 0.1%")
best_res.update({"tol": 0.001, "n_rnd": 100})
rnd_01 = ab.mc_random(**best_res, **const_args)
print("Random 0.5%")
best_res.update({"tol": 0.005, "n_rnd": 100})
rnd_05 = ab.mc_random(**best_res, **const_args)
print("Random 1%")
best_res.update({"tol": 0.01, "n_rnd": 100})
rnd_1 = ab.mc_random(**best_res, **const_args)
print("Random 5%")
best_res.update({"tol": 0.05, "n_rnd": 100})
rnd_5 = ab.mc_random(**best_res, **const_args)
293/4:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
# Test different dispersions around the maximum value
# The ideia is to try and determine how much the maximum realy
# depends on each value...
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
best_res = data.loc[0][:7].to_dict()
# Change only QSize to qd_size
best_res["qd_size"] = best_res["QSize"]
best_res.pop("QSize")

# Call severall versions of the random variation around the maximum
print("Random 0.1%")
best_res.update({"tol": 0.001, "n_rnd": 100})
rnd_01 = ab.mc_random(**best_res, **const_args)
print("Random 0.5%")
best_res.update({"tol": 0.005, "n_rnd": 100})
rnd_05 = ab.mc_random(**best_res, **const_args)
print("Random 1%")
best_res.update({"tol": 0.01, "n_rnd": 100})
rnd_1 = ab.mc_random(**best_res, **const_args)
print("Random 5%")
best_res.update({"tol": 0.05, "n_rnd": 100})
rnd_5 = ab.mc_random(**best_res, **const_args)
293/5:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
# Test different dispersions around the maximum value
# The ideia is to try and determine how much the maximum realy
# depends on each value...
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
best_res = data.loc[0][:7].to_dict()
# Change only QSize to qd_size
best_res["qd_size"] = best_res["QSize"]
best_res.pop("QSize")

# Call severall versions of the random variation around the maximum
print("Random 0.1%")
best_res.update({"tol": 0.001, "n_rnd": 100})
rnd_01 = ab.mc_random(**best_res, **const_args)
print("Random 0.5%")
best_res.update({"tol": 0.005, "n_rnd": 100})
rnd_05 = ab.mc_random(**best_res, **const_args)
print("Random 1%")
best_res.update({"tol": 0.01, "n_rnd": 100})
rnd_1 = ab.mc_random(**best_res, **const_args)
print("Random 5%")
best_res.update({"tol": 0.05, "n_rnd": 100})
rnd_5 = ab.mc_random(**best_res, **const_args)
293/6:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(mc_series, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
# plt.savefig("Optimized_Dist.svg", transparent=True)
293/7:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_01, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
# plt.savefig("Optimized_Dist.svg", transparent=True)
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_05, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
# plt.savefig("Optimized_Dist.svg", transparent=True)
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_1, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
# plt.savefig("Optimized_Dist.svg", transparent=True)
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_5, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
# plt.savefig("Optimized_Dist.svg", transparent=True)
293/8:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
# Test different dispersions around the maximum value
# The ideia is to try and determine how much the maximum realy
# depends on each value...
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
best_res = data.loc[0][:7].to_dict()
# Change only QSize to qd_size
best_res["qd_size"] = best_res["QSize"]
best_res.pop("QSize")

# Call severall versions of the random variation around the maximum
print("Random 0.1%")
best_res.update({"tol": 0.001, "n_rnd": 1000})
rnd_01 = ab.mc_random(**best_res, **const_args)
print("Random 0.5%")
best_res.update({"tol": 0.005, "n_rnd": 1000})
rnd_05 = ab.mc_random(**best_res, **const_args)
print("Random 1%")
best_res.update({"tol": 0.01, "n_rnd": 1000})
rnd_1 = ab.mc_random(**best_res, **const_args)
print("Random 5%")
best_res.update({"tol": 0.05, "n_rnd": 1000})
rnd_5 = ab.mc_random(**best_res, **const_args)
293/9:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_01, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
# plt.savefig("Optimized_Dist.svg", transparent=True)
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_05, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
# plt.savefig("Optimized_Dist.svg", transparent=True)
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_1, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
# plt.savefig("Optimized_Dist.svg", transparent=True)
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_5, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
# plt.savefig("Optimized_Dist.svg", transparent=True)
293/10:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_01, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
# plt.savefig("Optimized_Dist.svg", transparent=True)
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_05, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
# plt.savefig("Optimized_Dist.svg", transparent=True)
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_1, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
# plt.savefig("Optimized_Dist.svg", transparent=True)
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_5, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
# plt.savefig("Optimized_Dist.svg", transparent=True)
293/11:
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_01, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
plt.savefig("FoM_Dist_001.svg", transparent=True)
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_05, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
plt.savefig("FoM_Dist_005.svg", transparent=True)
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_1, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
plt.savefig("FoM_Dist_01.svg", transparent=True)
plt.figure(figsize=(10, 7))
mc_series = pd.Series(rnd_01)
sns.distplot(rnd_5, bins=50)
plt.xlabel("FoM", fontsize=20)
plt.ylabel("Density", fontsize=20)
plt.xticks(fontsize=18);
plt.yticks(fontsize=18);
plt.savefig("FoM_Dist_05.svg", transparent=True)
293/12: rnd_05
293/13:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
# Test different dispersions around the maximum value
# The ideia is to try and determine how much the maximum realy
# depends on each value...
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
best_res = data.loc[0][:7].to_dict()
best_res
293/14: list(zip([1, 2, 3], 1))
293/15: list(zip([1, 2, 3], [1]<))
293/16: list(zip([1, 2, 3], [1]))
293/17:
columns = ["qd_size", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
# Test different dispersions around the maximum value
# The ideia is to try and determine how much the maximum realy
# depends on each value...
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
# best_res = data.loc[0][:7].to_dict()
# best_res
# me = np.random.uniform((1-tol)*0.12, (1+tol)*0.12, size=(n_rnd))
# mh = np.random.uniform((1-tol)*0.10, (1+tol)*0.10, size=(n_rnd))
# qd_size = np.random.uniform((1-tol)*2.96, (1+tol)*2.96, size=(n_rnd))
# Pl = np.random.uniform((1-tol)*7.9e-25,(1+tol)*7.9e-25, size=(n_rnd))
# Pt = np.random.uniform((1-tol)*5.1e-25,(1+tol)*5.1e-25, size=(n_rnd))
# Eg = np.random.uniform((1-tol)*2.1, (1+tol)*2.1, size=(n_rnd))
# offset = np.random.uniform((1-tol)*0.48, (1+tol)*0.48, size=(n_rnd))
293/18: daa
293/19: data
293/20:
columns = ["qd_size", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
# Test different dispersions around the maximum value
# The ideia is to try and determine how much the maximum realy
# depends on each value...
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
best_res = data.loc[0][:7].to_dict()
best_res
# me = np.random.uniform((1-tol)*0.12, (1+tol)*0.12, size=(n_rnd))
# mh = np.random.uniform((1-tol)*0.10, (1+tol)*0.10, size=(n_rnd))
# qd_size = np.random.uniform((1-tol)*2.96, (1+tol)*2.96, size=(n_rnd))
# Pl = np.random.uniform((1-tol)*7.9e-25,(1+tol)*7.9e-25, size=(n_rnd))
# Pt = np.random.uniform((1-tol)*5.1e-25,(1+tol)*5.1e-25, size=(n_rnd))
# Eg = np.random.uniform((1-tol)*2.1, (1+tol)*2.1, size=(n_rnd))
# offset = np.random.uniform((1-tol)*0.48, (1+tol)*0.48, size=(n_rnd))
293/21:
columns = ["qd_size", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
# Test different dispersions around the maximum value
# The ideia is to try and determine how much the maximum realy
# depends on each value...
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
best_res = data.loc[0][:7].to_dict()
best_res_array = {key: value*np.ones(n_rnd) for key, value in best_res.values()}
# me = np.random.uniform((1-tol)*0.12, (1+tol)*0.12, size=(n_rnd))
# mh = np.random.uniform((1-tol)*0.10, (1+tol)*0.10, size=(n_rnd))
# qd_size = np.random.uniform((1-tol)*2.96, (1+tol)*2.96, size=(n_rnd))
# Pl = np.random.uniform((1-tol)*7.9e-25,(1+tol)*7.9e-25, size=(n_rnd))
# Pt = np.random.uniform((1-tol)*5.1e-25,(1+tol)*5.1e-25, size=(n_rnd))
# Eg = np.random.uniform((1-tol)*2.1, (1+tol)*2.1, size=(n_rnd))
# offset = np.random.uniform((1-tol)*0.48, (1+tol)*0.48, size=(n_rnd))
293/22:
columns = ["qd_size", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
# Test different dispersions around the maximum value
# The ideia is to try and determine how much the maximum realy
# depends on each value...
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
best_res = data.loc[0][:7].to_dict()
best_res_array = {key: value*np.ones(n_rnd) for key, value in best_res.items()}
# me = np.random.uniform((1-tol)*0.12, (1+tol)*0.12, size=(n_rnd))
# mh = np.random.uniform((1-tol)*0.10, (1+tol)*0.10, size=(n_rnd))
# qd_size = np.random.uniform((1-tol)*2.96, (1+tol)*2.96, size=(n_rnd))
# Pl = np.random.uniform((1-tol)*7.9e-25,(1+tol)*7.9e-25, size=(n_rnd))
# Pt = np.random.uniform((1-tol)*5.1e-25,(1+tol)*5.1e-25, size=(n_rnd))
# Eg = np.random.uniform((1-tol)*2.1, (1+tol)*2.1, size=(n_rnd))
# offset = np.random.uniform((1-tol)*0.48, (1+tol)*0.48, size=(n_rnd))
293/23:
columns = ["qd_size", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
# Test different dispersions around the maximum value
# The ideia is to try and determine how much the maximum realy
# depends on each value...
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
n_rnd = 1000
best_res = data.loc[0][:7].to_dict()
best_res_array = {key: value*np.ones(n_rnd) for key, value in best_res.items()}
# me = np.random.uniform((1-tol)*0.12, (1+tol)*0.12, size=(n_rnd))
# mh = np.random.uniform((1-tol)*0.10, (1+tol)*0.10, size=(n_rnd))
# qd_size = np.random.uniform((1-tol)*2.96, (1+tol)*2.96, size=(n_rnd))
# Pl = np.random.uniform((1-tol)*7.9e-25,(1+tol)*7.9e-25, size=(n_rnd))
# Pt = np.random.uniform((1-tol)*5.1e-25,(1+tol)*5.1e-25, size=(n_rnd))
# Eg = np.random.uniform((1-tol)*2.1, (1+tol)*2.1, size=(n_rnd))
# offset = np.random.uniform((1-tol)*0.48, (1+tol)*0.48, size=(n_rnd))
293/24: best_res_array
293/25:
columns = ["qd_size", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
# Make the random calculations
n_rnd = 10
tol = 0.05
best_res = data.loc[0][:7].to_dict()
best_res_array = {key: value*np.ones(n_rnd) for key, value in best_res.items()}
for key in best_res_array.items():
    sim_array = best_array.copy()
    sim_array[key] = np.random.uniform((1-tol)*best_res[key], (1+tol)*best_res[key], size=(n_rnd))
    sim_array.update(const_args)
    print(sim_array)
    # ab.opt_function(**sim_array)
293/26:
columns = ["qd_size", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
# Make the random calculations
n_rnd = 10
tol = 0.05
best_res = data.loc[0][:7].to_dict()
best_res_array = {key: value*np.ones(n_rnd) for key, value in best_res.items()}
for key in best_res_array.items():
    sim_array = best_res_array.copy()
    sim_array[key] = np.random.uniform((1-tol)*best_res[key], (1+tol)*best_res[key], size=(n_rnd))
    sim_array.update(const_args)
    print(sim_array)
    # ab.opt_function(**sim_array)
293/27:
columns = ["qd_size", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
# Make the random calculations
n_rnd = 10
tol = 0.05
best_res = data.loc[0][:7].to_dict()
best_res_array = {key: value*np.ones(n_rnd) for key, value in best_res.items()}
for key, value in best_res_array.items():
    sim_array = best_res_array.copy()
    sim_array[key] = np.random.uniform((1-tol)*best_res[key], (1+tol)*best_res[key], size=(n_rnd))
    sim_array.update(const_args)
    print(sim_array)
    # ab.opt_function(**sim_array)
293/28:
columns = ["qd_size", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
# Make the random calculations
n_rnd = 10
tol = 0.05
best_res = data.loc[0][:7].to_dict()
best_res_array = {key: value*np.ones(n_rnd) for key, value in best_res.items()}
for key in best_res_array.keys():
    sim_array = best_res_array.copy()
    sim_array[key] = np.random.uniform((1-tol)*best_res[key], (1+tol)*best_res[key], size=(n_rnd))
    sim_array.update(const_args)
    print(sim_array)
    # ab.opt_function(**sim_array)
293/29:
columns = ["qd_size", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
# Make the random calculations
n_rnd = 1000
tol = 0.05
best_res = data.loc[0][:7].to_dict()
best_res_array = {key: value*np.ones(n_rnd) for key, value in best_res.items()}
for key in best_res_array.keys():
    logging.info(f"Running... {key=}")
    sim_array = best_res_array.copy()
    sim_array[key] = np.random.uniform((1-tol)*best_res[key], (1+tol)*best_res[key], size=(n_rnd))
    sim_array.update(const_args)
    ab.opt_function(**sim_array)
293/30: rnd_5
293/31: np.savetxt("Random_calculations.csv", np.c_[rnd_01, rnd_05, rnd_1, rnd_5])
293/32: np.savetxt("Random_calculations.csv", np.c_[rnd_01, rnd_05, rnd_1, rnd_5], header="# Rnd_0.1 Rnd_0.5 Rnd_1 Rnd_5")
293/33:
columns = ["qd_size", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
# Make the random calculations
results = []
n_rnd = 1000
tol = 0.05
best_res = data.loc[0][:7].to_dict()
best_res_array = {key: value*np.ones(n_rnd) for key, value in best_res.items()}
for key in best_res_array.keys():
    logging.info(f"Running... {key=}")
    sim_array = best_res_array.copy()
    sim_array[key] = np.random.uniform((1-tol)*best_res[key], (1+tol)*best_res[key], size=(n_rnd))
    sim_array.update(const_args)
    results.append(ab.opt_function(**sim_array))
295/1:
#Interactive representation for the first 5 l's
@interact_manual(m1 = (0.0,1.0,0.1),
          m2 = (0.0,1.0,0.1),
          V0 = (0.0,1.0,0.1),
          a = (0.0,10.0,0.1))
def interact_eigen(m1=0.5,m2 = 0.5, V0 = 0.5,a = 1.0):
    #First calculate the values for plotting
    E = np.linspace(0,-V0,500)#Introducing negative E
    eigen = []
    for i in range(5):
        cond = f_spherical_bound_states(E,m1,m2,a,V0,i)
        eigen.append(cond)
    #Remove descontinuities
    eigen = np.stack(eigen)
    mask = (eigen > 20) | (eigen < -20)
    eigen[mask]=np.nan
    
    for i in range(5):
        plt.plot(E,eigen[i],label = "Condition for l = {}".format(i));
        plt.ylim((-10,10));
        plt.ylabel("f(E)");
        plt.xlabel("E");
        plt.legend();
295/2:
#Basic modules
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
#Plot configuration in the notebook
%matplotlib inline
from pylab import rcParams
rcParams['figure.figsize'] = 10,5

#Sci-py utilities
from scipy import special
from scipy import optimize
import scipy.constants as scc
from scipy.integrate import trapz, quad
#Clecsch-Gordan coefficients
from sympy.physics.quantum.cg import CG

#Module to inspect funcitons
import inspect

#Modules for interactivity in jupyter notebook
import ipywidgets as ipw
from ipywidgets import interact, interact_manual
from IPython.display import display
295/3:
#Interactive representation for the first 5 l's
@interact_manual(m1 = (0.0,1.0,0.1),
          m2 = (0.0,1.0,0.1),
          V0 = (0.0,1.0,0.1),
          a = (0.0,10.0,0.1))
def interact_eigen(m1=0.5,m2 = 0.5, V0 = 0.5,a = 1.0):
    #First calculate the values for plotting
    E = np.linspace(0,-V0,500)#Introducing negative E
    eigen = []
    for i in range(5):
        cond = f_spherical_bound_states(E,m1,m2,a,V0,i)
        eigen.append(cond)
    #Remove descontinuities
    eigen = np.stack(eigen)
    mask = (eigen > 20) | (eigen < -20)
    eigen[mask]=np.nan
    
    for i in range(5):
        plt.plot(E,eigen[i],label = "Condition for l = {}".format(i));
        plt.ylim((-10,10));
        plt.ylabel("f(E)");
        plt.xlabel("E");
        plt.legend();
295/4:
#Funcion to calculate the spherical hankel functions and its derivatives from the hankel funcitons
def spherical_hankel(n,x,kind,**kwargs):
    """Calculate spherical hankel funcions from the hankel functions
    Args:
        n (int): order of the spherical hankel function
        x (array): array with x data
        kind (int): kind of the hankel function (1 or 2) 
    **kwargs:
        derivative (bool): if true returns the derivative instead of the the value
    Return:
        sph_hankel (array): data for the spherical hankel function or its derivative
    """
    if kind == 1:#Calculate for first order hankel function
        if kwargs.get("derivative"):#If the derivative is asked 
            sph_hankel = np.sqrt((np.pi/(2*x)))*(special.hankel1(n-1/2,x)-((n+1)/x)*special.hankel1(n+1/2,x))
        else:
            sph_hankel = np.sqrt((np.pi/(2*x)))*special.hankel1(n+1/2,x)
    else:#Calculate second order hankel function
        if kwargs.get("derivative"):#If the derivative is asked 
            sph_hankel = np.sqrt((np.pi/(2*x)))*(special.hankel2(n-1/2,x)-((n+1)/x)*special.hankel2(n+1/2,x))
        else:
            sph_hankel = np.sqrt((np.pi/(2*x)))*special.hankel2(n+1/2,x)  
    return sph_hankel

#Solves the eigenvalue problem without any simplifations - NOT NECESSARY FOR FINAL FILE
def f_spherical_bound_states(E,m1,m2,a,V0,l):
    """Defines a function to solve the eigenstates in the spherical well by brute force
    Args:
        E (array): x range to calculate results (from 0 to -V0)
        m1,m2 (float): Effective masses inside and outside the well [m = m*.m_e]
        a (float): Radius of the well [nm]
        V0 (float): Potential barrier of the well [eV]
        l (int): order of the bessel function
    Returns:
        f_E: eigenvalue condition values
    """
    #Calculate normalization factors
    m1, m2, h_bar, V0, E = m1*9.1094, m2*9.1094, 1.05457, V0*1.6022, E*1.6022
    #Introducing the various bessel functions necessary
    #First kind bessel
    j_l = special.spherical_jn(l,np.sqrt((2*m1*(E+V0))/h_bar**2)*a)
    der_j_l = special.spherical_jn(l,np.sqrt((2*m1*(E+V0))/h_bar**2)*a,derivative = True)
    #First kind hankel
    h_l = spherical_hankel(l,np.sqrt((-2*m2*E/h_bar**2)*a*1j),1)
    der_h_l = spherical_hankel(l,np.sqrt((-2*m2*E/h_bar**2)*a*1j),1,derivative = True)
    f_E_1 = (der_j_l/j_l)
    f_E_2 = (np.sqrt(-(m2/m1)*(E/(E+V0)))*(der_h_l/h_l))
    #total function
    f_E = np.add(f_E_1,-1j*f_E_2)
    return np.real(f_E)

#Simplified condition to solve the eigenvalue condition
def spherical_bound_states(E,m1,m2,a,V0,l):
    """Function that returns the values of the eigenvalue condition
    For l = 0 uses the analitical solution to the problem
    For l > 0 solves the simplified verson of the eigenvalue condition
    Args:
        E (array): x range to calculate results (values from 0 to -V0)
        m1,m2 (float): Effective masses inside and outside the well [m = m*.m_e]
        a (float): Radius of the well [nm]
        V0 (float): Potential barrier of the well [eV]
        l (int): order of the bessel function
    Returns:
        f_E: argument and function result
    """
    if l == 0:#In this case solve the problem using the analitical solution
        f_E = f_spherical_l0(E,m1,m2,a,V0)
    else:#Solve the problem using the simplified solution
        #Calculate normalization factors
        m1, m2, h_bar, V0, E = m1*9.1094, m2*9.1094, 1.05457, V0*1.6022, E*1.6022
        E_j = np.sqrt(2*m1*(E+V0))*(a/h_bar) # argument of the bessel function
        E_h = np.sqrt(-2*m2*E)*(a/h_bar)*1j #argument of the hankel function
        #np.sqrt(-(m1/m2)*((E+V0)/E))*
        j_term = special.spherical_jn(l-1,E_j)/special.spherical_jn(l,E_j)
        #np.sqrt(-(m2/m1)*(E/(E+V0)))*
        h_term = np.sqrt(-(m2/m1)*(E/(E+V0)))*np.real(1j*(spherical_hankel(l-1,E_h,1)/spherical_hankel(l,E_h,1)))
        #h_term = (spherical_hankel(l-1,E_h,1)*spherical_hankel(l-1,E_h,2))/(spherical_hankel(l,E_h,1)*spherical_hankel(l,E_h,2))
        f_E = np.add(j_term,-h_term)
    return f_E

"""Analitical solutions to the problem"""
#Analitical Solution for l = 0
def f_spherical_l0(E,m1,m2,a,V0):
    """Return the results for the eigenvalue condition for l = 0
    Args:
        E (array): x range to calculate results (from 0 to -V0)
        m1,m2 (float): Effective masses inside and outside the well [m = m*.m_e]
        a (float): Radius of the well [nm]
        V0 (float): Potential barrier of the well [eV]
    Returns:
        f_E  (array): values for the eigenvalue condition
    """
    #Calculate normalization factors
    m1, m2, h_bar, V0, E = m1*9.1094, m2*9.1094, 1.05457, V0*1.6022, E*1.6022
    #E = np.linspace(0,-V0,500)
    arg_cot = np.sqrt(2*m1*(E+V0))*(a/h_bar)
    f_E = 1/np.tan(arg_cot)+np.sqrt(-(m2/m1)*(E/(E+V0)))
    return f_E

#Analitical solution for l = 1 - NOT NECESSARY FOR FINAL FILE
def f_spherical_l1(E,m1,m2,a,V0):
    """Return the results for the eigenvalue condition for l = 1
    Args:
        E (array): x range to calculate results
        m1,m2 (float): Effective masses inside and outside the well [m = m*.m_e]
        a (float): Radius of the well [nm]
        V0 (float): Potential barrier of the well [eV]
    Returns:
        f_E  (array): eigenvalue condition values
    """
    m1, m2, h_bar, V0, E = m1*9.1094, m2*9.1094, 1.05457, V0*1.6022, E*1.6022
    #E = np.linspace(0,-V0,500)
    kin = np.sqrt((2*m1*(E+V0))/(h_bar**2))
    kout = np.sqrt((-2*m2*E/(h_bar**2)))
    f_E = np.add(np.sin(kin*a)/((np.sin(kin*a)/(kin*a))-np.cos(kin*a)),np.sqrt(-(m2/m1)*(E/(E+V0)))*(1/(1+1/(kout*a))))
    return f_E

"""Calculation of zeros of the function"""
def zeros_f(func,x,**kwargs):
    """Calculate the zeros in the range defines by x
    Args:
        func (function): function to calculate the zeros
        x (array): array defining the range of values to calculate the zeros
    **kwargs:
        args = optinal argumentos for func
        tol = override the default tol of 0.1 (lower values lead to faster results but might be less accurate)
        fsolve = dictionary with overrides for fsolve
    Returns:
        zeros: array with the several zeros of the function
    """    
    #Check for tol override
    tol = 0.1
    if kwargs.get('tol'):
        tol = kwargs.get('tol')
    #Create a dictionary with additional arguments necessary for the function
    if kwargs.get('args'):
        #Associate variable name in the function with the value introduced in args
        f_variables = str(inspect.signature(spherical_bound_states))[1:-1].split(", ")[1:]
        f_args = dict()
        for (i,j) in zip(f_variables,range(len(f_variables))):
            f_args[i]=kwargs.get('args')[j]
        #Make a estimative for the location of the 0's  
        estimate_zeros = x[np.sqrt(np.abs(func(x,**f_args))) < tol]
    else:
        #Make a estimative for the location of the 0's  
        estimate_zeros = x[np.sqrt(np.abs(func(x))) < tol] 
    #Use fsolve combined with the previous 0 estimatives to determine the real 0s
    try:#To check if there are additional parameters to be used in fsolve
        zeros = optimize.fsolve(func, estimate_zeros,args = kwargs.get("args"),**kwargs.get('fsolve'))
    except:
        zeros = optimize.fsolve(func, estimate_zeros,args = kwargs.get("args"))
    #Remove duplicates
    zeros = np.unique(np.around(zeros,decimals=5))
    return zeros
295/5:
#Interactive representation for the first 5 l's
@interact_manual(m1 = (0.0,1.0,0.1),
          m2 = (0.0,1.0,0.1),
          V0 = (0.0,1.0,0.1),
          a = (0.0,10.0,0.1))
def interact_eigen(m1=0.5,m2 = 0.5, V0 = 0.5,a = 1.0):
    #First calculate the values for plotting
    E = np.linspace(0,-V0,500)#Introducing negative E
    eigen = []
    for i in range(5):
        cond = f_spherical_bound_states(E,m1,m2,a,V0,i)
        eigen.append(cond)
    #Remove descontinuities
    eigen = np.stack(eigen)
    mask = (eigen > 20) | (eigen < -20)
    eigen[mask]=np.nan
    
    for i in range(5):
        plt.plot(E,eigen[i],label = "Condition for l = {}".format(i));
        plt.ylim((-10,10));
        plt.ylabel("f(E)");
        plt.xlabel("E");
        plt.legend();
295/6:
j = ipw.IntSlider(min = 1,max = 20, step = 1)
j
295/7:
h = ipw.IntSlider(min = 1,max = 20, step = 1)
h
295/8:
#Test related with the positioning of the fraction
x = np.linspace(0,-1,500)
num_h = [spherical_hankel(i,1j*np.sqrt(-x)*h.value,1) for i in range(5)]
denom_h = [spherical_hankel(i+1,1j*np.sqrt(-x)*h.value,1) for i in range(5)]

frac_1 = [1j*np.sqrt(-x/(x+1))*np.divide(num_h[i],denom_h[i]) for i in range(5)]

for i in range(5):
    plt.plot(x,np.real(frac_1[i]),label = "$h_{}/h_{}$".format(i+1,i))
    
plt.legend();
plt.ylim(1,-10);
295/9:
#Test related with the positioning of the fraction
x = np.linspace(0,-1,500)
num_h = [spherical_hankel(i,1j*np.sqrt(-x)*h.value,1) for i in range(5)]
denom_h = [spherical_hankel(i+1,1j*np.sqrt(-x)*h.value,1) for i in range(5)]

frac_1 = [1j*np.sqrt(-x/(x+1))*np.divide(num_h[i],denom_h[i]) for i in range(5)]

for i in range(5):
    plt.plot(x,np.real(frac_1[i]),label = "$h_{}/h_{}$".format(i+1,i))
    
plt.legend();
plt.ylim(1,-10);
295/10:
#Resultados para o caso analitico
@interact_manual(a = (0.1,10,0.1),m1 = (0.1,1,0.1),m2 = (0.1,1,0.1),V0 = (0.1,1,0.1))
def compare_analitical(m1=1,m2=1,a=1,V0 = 10):
    E_l1 = np.linspace(0,-V0,500)#Introducing negative E
    f_e_anal = f_spherical_l1(E,m1,m2,a,V0);
    f_e_num = spherical_bound_states(E,m1,m2,a,V0,1);

    plt.plot(E_l1,f_e_anal,E_l1,f_e_num);
    plt.legend(("Analitical solution","Numerical solution"));
    plt.ylim(-10,10);
293/34: results
293/35: len(results)
293/36:
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
for index, rnd_i in enumerate(results):
    chart = sns.histplot(data=rnd_i,color=colors[index], kde=True, bins=150, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_xlabel("Count", fontsize=18)
    ax[index].set_title(variable, fontsize=18)
293/37:
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
for index, rnd_i in enumerate(results):
    chart = sns.histplot(data=rnd_i,color=colors[index], kde=True, bins=150, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_xlabel("Count", fontsize=18)
    #ax[index].set_title(variable, fontsize=18)
293/38:
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
for index, rnd_i in enumerate(results):
    chart = sns.histplot(y=rnd_i,color=colors[index], kde=True, bins=150, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_xlabel("Count", fontsize=18)
    #ax[index].set_title(variable, fontsize=18)
293/39:
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for index, rnd_i in enumerate(results):
    chart = sns.histplot(y=rnd_i,color=colors[index], kde=True, bins=150, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_xlabel("Count", fontsize=18)
    ax[index].set_title(columns[index], fontsize=18)
293/40:
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for index, rnd_i in enumerate(results):
    chart = sns.histplot(y=rnd_i,color=colors[index], kde=True, bins=150, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_xlabel("Count", fontsize=18)
    ax[index].set_title(columns[index], fontsize=18)
npres = np.c_[res_i for res_i in results]
np.savetxt("Param_Dist_1000.csv", npres, sep=" ", header=" ".join(columns[:7]))
plt.savefig("Param_Dist_1000.svg", transparent=True)
293/41:
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for index, rnd_i in enumerate(results):
    chart = sns.histplot(y=rnd_i,color=colors[index], kde=True, bins=150, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_xlabel("Count", fontsize=18)
    ax[index].set_title(columns[index], fontsize=18)
npres = np.c_[[res_i for res_i in results]]
np.savetxt("Param_Dist_1000.csv", npres, sep=" ", header=" ".join(columns[:7]))
plt.savefig("Param_Dist_1000.svg", transparent=True)
293/42:
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for index, rnd_i in enumerate(results):
    chart = sns.histplot(y=rnd_i,color=colors[index], kde=True, bins=150, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_xlabel("Count", fontsize=18)
    ax[index].set_title(columns[index], fontsize=18)
npres = np.c_[[res_i for res_i in results]]
np.savetxt("Param_Dist_1000.csv", npres, header=" ".join(columns[:7]))
plt.savefig("Param_Dist_1000.svg", transparent=True)
293/43: npres
293/44:
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for index, rnd_i in enumerate(results):
    chart = sns.histplot(y=rnd_i,color=colors[index], kde=True, bins=150, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_xlabel("Count", fontsize=18)
    ax[index].set_title(columns[index], fontsize=18)
npres = np.c_[results]
np.savetxt("Param_Dist_1000.csv", npres, header=" ".join(columns[:7]))
plt.savefig("Param_Dist_1000.svg", transparent=True)
293/45: results
293/46: np.c_[results[0], results[1]]
293/47: np.c_[results]
293/48: np.c_[results].shape
293/49: np.c_[results[0], results[1]]
293/50: np.c_[results[0], results[1]].shape
293/51: np.column_stack(tuple(results))
293/52: np.column_stack(tuple(results)).shape
293/53:
fig, ax = plt.subplots(1, 7, figsize=(15, 10))
colors = ["red", "green", "blue", "purple", "yellow", "brown", "rosybrown"]
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
for index, rnd_i in enumerate(results):
    chart = sns.histplot(y=rnd_i,color=colors[index], kde=True, bins=150, ax=ax[index])
    ax[index].tick_params(axis="y", rotation=90, labelsize=12, pad=1)
    ax[index].set_ylabel("")
    ax[index].set_xlabel("Count", fontsize=18)
    ax[index].set_title(columns[index], fontsize=18)
npres = np.column_stack(tuple(results))
np.savetxt("Param_Dist_1000.csv", npres, header=" ".join(columns[:7]))
plt.savefig("Param_Dist_1000.svg", transparent=True)
293/54:
param_dict = {
    "qd_size": [1, 3.5],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-25, 1e-24],
    "Eg": [1, 2.5],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
res = particle_swarm(opt_function, param_dict,
                     n_particles=15, n_iter=30,
                     export=True, swarm_properties=(0.3, 1.5, 1.5),
                     **const_args)
293/55:
param_dict = {
    "qd_size": [1, 3.5],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-25, 1e-24],
    "Eg": [1, 2.5],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 15
}
res = particle_swarm(ab.opt_function, param_dict,
                     n_particles=15, n_iter=30,
                     export=True, swarm_properties=(0.3, 1.5, 1.5),
                     **const_args)
293/56: res
293/57:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("PSO_Results/results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
data.loc[0]
qd_cb = qbd.qd_results(data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"],
                       data.loc[0]["me"], data.loc[0]["me"], band="CB1")
qd_vb = qbd.qd_results(data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*(1-data.loc[0]["offset"]),
                       data.loc[0]["mh"], data.loc[0]["mh"], band="VB1")

sim_setup = (15, 0.65, data.loc[0]["Eg"], (data.loc[0]["Pl"], data.loc[0]["Pt"]))
qd1_prop = (data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"], data.loc[0]["me"], data.loc[0]["me"])
qd2_prop = (data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*(1-data.loc[0]["offset"]), data.loc[0]["mh"], data.loc[0]["mh"])

trn = ab.all_avg_trn_elements(qd1_prop, qd2_prop, sim_setup)
best_abs = ab.interband_absorption(np.linspace(0, 5, 600),qd1_prop, qd2_prop, sim_setup)
293/58: plt.plot(np.linspace(0, 5, 600), best_abs)
293/59: qd_vb.e_levels
293/60: qd_cb.e_levels
293/61: best_abs
293/62: plt.plot(np.linspace(0, 5, 600), best_abs.iloc[1:])
293/63: plt.plot(np.linspace(0, 5, 600), best_abs.iloc[0:])
293/64: plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 0:])
293/65: plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
293/66:
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
plt.savefig("PSO_Best_2.svg", transparent=True)
293/67: run
293/68: res
293/69:
ab._single_FoM(data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"], (data.loc[0]["Eg"] - 0.4)*(1-data.loc[0]["offset"]),
               data.loc[0]["me"], data.loc[1]["mh"], data.loc[1]["Pl"], data.loc[1]["Pt"], data.loc[1]["Eg"], data.loc[1]["offset"])
293/70:
ab._single_FoM(data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"], (data.loc[0]["Eg"] - 0.4)*(1-data.loc[0]["offset"]),
               data.loc[0]["me"], data.loc[1]["mh"], data.loc[1]["Pl"], data.loc[1]["Pt"], data.loc[1]["Eg"], data.loc[1]["offset"])
293/71:
# Guarantee normalization for the CB
sim_size = 15
qd_size = 0.65
qd_wavefunction = qbd.qd_results(data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"], data.loc[0]["me"], data.loc[0]["me"], "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
293/72:
# Guarantee normalization for the CB
sim_size = 15
lat_size = 0.65
qd_wavefunction = qbd.qd_results(data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"], data.loc[0]["me"], data.loc[0]["me"], "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
293/73:
# Guarantee normalization for the CB
sim_size = 15
lat_size = 0.65
l = 0
n = 0
m = 0
qd_wavefunction = qbd.qd_results(data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"], data.loc[0]["me"], data.loc[0]["me"], "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
293/74: data.loc[0]
293/75: data.loc[0].to_tuple()
293/76: data.loc[0].totuple()
293/77: data.loc[0].totuple
293/78: tuple(pd.itertuples(data.loc[0]))
293/79: tuple(data.loc[0].itertuples)
293/80: tuple(data.loc[0])
293/81: data.loc[0]
293/82:
# Guarantee normalization for the CB
sim_size = 15
lat_size = 0.65
l = 0
n = 0
m = 0
qsize, me, mh, Pl, Pt, Eg, offset, _* = tuple(data.loc[0])
P = (Pl, Pt)
qd_wavefunction = qbd.qd_results(qsize, (eg - 0.4)*offset, me, me, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
293/83:
# Guarantee normalization for the CB
sim_size = 15
lat_size = 0.65
l = 0
n = 0
m = 0
qsize, me, mh, Pl, Pt, Eg, offset, *_ = tuple(data.loc[0])
P = (Pl, Pt)
qd_wavefunction = qbd.qd_results(qsize, (eg - 0.4)*offset, me, me, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
293/84:
# Guarantee normalization for the CB
sim_size = 15
lat_size = 0.65
l = 0
n = 0
m = 0
qsize, me, mh, Pl, Pt, Eg, offset, *_ = tuple(data.loc[0])
P = (Pl, Pt)
qd_wavefunction = qbd.qd_results(qsize, (Eg - 0.4)*offset, me, me, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
293/85:
# Guarantee normalization for the CB
sim_size = 15
lat_size = 0.65
l = 0
n = 0
m = 0
qsize, me, mh, Pl, Pt, Eg, offset, *_ = tuple(data.loc[0])
P = (Pl, Pt)
qd_wavefunction = qbd.qd_results(qsize, (Eg - 0.4)*offset, me, me, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
293/86:
# Guarantee normalization for the CB
sim_size = 15
lat_size = 0.65
l = 0
n = 0
m = 0
center = int(sim_size/lat_size/2)
qsize, me, mh, Pl, Pt, Eg, offset, *_ = tuple(data.loc[0])
P = (Pl, Pt)
qd_wavefunction = qbd.qd_results(qsize, (Eg - 0.4)*offset, me, me, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cm.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cm.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cm.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cm.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
293/87:
# Guarantee normalization for the CB
sim_size = 15
lat_size = 0.65
l = 0
n = 0
m = 0
center = int(sim_size/lat_size/2)
qsize, me, mh, Pl, Pt, Eg, offset, *_ = tuple(data.loc[0])
P = (Pl, Pt)
qd_wavefunction = qbd.qd_results(qsize, (Eg - 0.4)*offset, me, me, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cmb.jet)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cmb.jet)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cmb.jet)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cmb.jet)
ax[1, 1].set_title("L6pb envolute")
plt.show()
293/88:
# Guarantee normalization for the CB
sim_size = 15
lat_size = 0.65
l = 0
n = 0
m = 0
center = int(sim_size/lat_size/2)
qsize, me, mh, Pl, Pt, Eg, offset, *_ = tuple(data.loc[0])
P = (Pl, Pt)
qd_wavefunction = qbd.qd_results(qsize, (Eg - 0.4)*offset, me, me, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cmb.jet, levels=50)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cmb.jet, levels=50)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cmb.jet, levels=50)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cmb.jet, levels=50)
ax[1, 1].set_title("L6pb envolute")
plt.show()
293/89:
# Guarantee normalization for the CB
sim_size = 15
lat_size = 0.65
l = 0
n = 0
m = 0
center = int(sim_size/lat_size/2)
qsize, me, mh, Pl, Pt, Eg, offset, *_ = tuple(data.loc[0])
P = (Pl, Pt)
qd_wavefunction = qbd.qd_results(qsize, (Eg - 0.4)*offset, me, me, "CB1")
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cmb.jet, levels=50)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cmb.jet, levels=50)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cmb.jet, levels=50)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cmb.jet, levels=50)
ax[1, 1].set_title("L6pb envolute")
plt.show()

x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"band_{band}_envolute_S_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
gridToVTK(f"band_{band}_envolute_Y_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_Y)**2})
gridToVTK(f"band_{band}_envolute_X_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_X)**2})
gridToVTK(f"band_{band}_envolute_Z_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_Z)**2})
293/90:
# Preview the envolutes for the strange case in quesion
sim_size = 15
lat_size = 0.65
l = 0
n = 0
m = 0
center = int(sim_size/lat_size/2)
qsize, me, mh, Pl, Pt, Eg, offset, *_ = tuple(data.loc[0])
P = (Pl, Pt)
band = "CB1"
# Calculate the envolutes for the CB
qd_wavefunction = qbd.qd_results(qsize, (Eg - 0.4)*offset, me, me, band)
XX_env_S, YY_env_S, ZZ_env_S, envolute_S, t_matrix_S = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mt", l, m, n, Eg, P)
XX_env_Y, YY_env_Y, ZZ_env_Y, envolute_Y, t_matrix_Y = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6mb", l, m, n, Eg, P)
XX_env_X, YY_env_X, ZZ_env_X, envolute_X, t_matrix_X = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pt", l, m, n, Eg, P)
XX_env_Z, YY_env_Z, ZZ_env_Z, envolute_Z, t_matrix_Z = qd_wavefunction.norm_envolute(sim_size, lat_size, "L6pb", l, m, n, Eg, P)

# Plot a slice of the data
fig, ax = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)
ax[0, 0].contourf(XX_env_S[:, :, center], ZZ_env_S[center].T, np.abs(envolute_S[:, center, :])**2, cmap=cmb.jet, levels=50)
ax[0, 0].set_title("L6mt envolute")
ax[1, 0].contourf(XX_env_Y[:, :, center], ZZ_env_Y[center].T, np.abs(envolute_Y[:, center, :])**2, cmap=cmb.jet, levels=50)
ax[1, 0].set_title("L6mb envolute")
ax[0, 1].contourf(XX_env_X[:, :, center], ZZ_env_X[center].T, np.abs(envolute_X[:, center, :])**2, cmap=cmb.jet, levels=50)
ax[0, 1].set_title("L6pt envolute")
ax[1, 1].contourf(XX_env_Z[:, :, center], ZZ_env_Z[center].T, np.abs(envolute_Z[:, center, :])**2, cmap=cmb.jet, levels=50)
ax[1, 1].set_title("L6pb envolute")
plt.show()

# Export to vtk file for visualization in paraview
x = np.arange(-sim_size, sim_size, lat_size)
gridToVTK(f"band_{band}_envolute_S_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_S)**2})
gridToVTK(f"band_{band}_envolute_Y_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_Y)**2})
gridToVTK(f"band_{band}_envolute_X_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_X)**2})
gridToVTK(f"band_{band}_envolute_Z_{l}_{m}_{n}", x, x, x, pointData = {'QD': np.abs(envolute_Z)**2})
293/91:
ab._single_FoM(data.loc[0]["QSize"], (data.loc[0]["Eg"] - 0.4)*data.loc[0]["offset"], (data.loc[0]["Eg"] - 0.4)*(1-data.loc[0]["offset"]),
               data.loc[0]["me"], data.loc[1]["mh"], data.loc[1]["Pl"], data.loc[1]["Pt"], data.loc[1]["Eg"], data.loc[1]["offset"], sim_size=25, lat_size=0.65)
293/92: trn
293/93: ab.avg_trn_elements(qd1_prop, qd2_prop, qd1_prop, sim_setup)
293/94: ab.avg_trn_elements(qd1_prop, qd2_prop, qd1_prop, sim_setup, trn=0)
293/95: ab.avg_trn_elements(qd1_prop, qd2_prop, sim_setup, trn=0)
293/96: ab.avg_trn_elements(qd2_prop, qd1_prop, sim_setup, trn=0)
293/97: ab.avg_trn_elements(qd2_prop, qd1_prop, sim_setup, trn=0)
293/98:
sim_setup = (25, 0.65, 2.2, 1e-24, 1e-24)
qd1_prop = (2.5, 0.9, 0.1, 0.1)
qd2_prop = (2.5, 0.9, 0.1, 0.1)
trn = ab.all_avg_trn_elements(qd1_prop, qd2_prop, sim_setup)
best_abs = ab.interband_absorption(np.linspace(0, 5, 600), qd1_prop, qd2_prop, sim_setup)
print(trn)
print(best_abs)
293/99:
sim_setup = (25, 0.65, 2.2, (1e-24, 1e-24))
qd1_prop = (2.5, 0.9, 0.1, 0.1)
qd2_prop = (2.5, 0.9, 0.1, 0.1)
trn = ab.all_avg_trn_elements(qd1_prop, qd2_prop, sim_setup)
best_abs = ab.interband_absorption(np.linspace(0, 5, 600), qd1_prop, qd2_prop, sim_setup)
print(trn)
print(best_abs)
293/100: plt.plot(best_abs["Energy"], best_abs.iloc[:, 1:])
293/101:
plt.plot(best_abs["Energy"], best_abs.iloc[:, 1:])
plt.xlim(0.5, 2.2)
293/102:
cb = qbd.qd_results(2.5, 0.9, 0.1, 0.1, "CB1")
print(cb.e_levels)
vb = qbd.qd_results(2.5, 0.9, 0.1, 0.1, "VB1")
print(vb.e_levels)
293/103:
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.savefig("PSO_Best_2.svg", transparent=True)
293/104:
plg.figure(figsize=(20, 20))
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.savefig("PSO_Best_2.svg", transparent=True)
293/105:
plt.figure(figsize=(20, 20))
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.savefig("PSO_Best_2.svg", transparent=True)
293/106:
plt.figure(figsize=(10,8))
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.savefig("PSO_Best_2.svg", transparent=True)
293/107:
plt.figure(figsize=(10,8))
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
plt.xlabel("Absorption Coefficient", fontsize=16)
plt.ylabel("Energy (eV)", fontsize=16)
plt.tick_params(fontsize=14)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
#plt.savefig("PSO_Best_2.svg", transparent=True)
293/108:
plt.figure(figsize=(10,8))
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
plt.xlabel("Absorption Coefficient", fontsize=16)
plt.ylabel("Energy (eV)", fontsize=16)
plt.tick_params(axis='both', fontsize=14)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
#plt.savefig("PSO_Best_2.svg", transparent=True)
293/109:
plt.figure(figsize=(10,8))
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
plt.xlabel("Absorption Coefficient", fontsize=16)
plt.ylabel("Energy (eV)", fontsize=16)
plt.tick_params(axis='both', labelsize=14)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
#plt.savefig("PSO_Best_2.svg", transparent=True)
293/110:
plt.figure(figsize=(10,8))
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
plt.xlabel("Absorption Coefficient", fontsize=18)
plt.ylabel("Energy (eV)", fontsize=18)
plt.tick_params(axis='both', labelsize=16)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
#plt.savefig("PSO_Best_2.svg", transparent=True)
293/111:
plt.figure(figsize=(10,8))
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
plt.xlabel("Absorption Coefficient", fontsize=18)
plt.ylabel("Energy (eV)", fontsize=18)
plt.tick_params(axis='both', labelsize=16)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value:.3g}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
#plt.savefig("PSO_Best_2.svg", transparent=True)
293/112:
plt.figure(figsize=(10,8))
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
plt.xlabel("Absorption Coefficient", fontsize=18)
plt.ylabel("Energy (eV)", fontsize=18)
plt.tick_params(axis='both', labelsize=16)
plt.xlim(0, 3)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value:.3g}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
#plt.savefig("PSO_Best_2.svg", transparent=True)
293/113:
plt.figure(figsize=(10,8))
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
plt.xlabel("Absorption Coefficient", fontsize=18)
plt.ylabel("Energy (eV)", fontsize=18)
plt.tick_params(axis='both', labelsize=16)
plt.xlim(0, 3)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value:.3g}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.savefig("PSO_Best_2.svg", transparent=True)
293/114:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("PSO_Results/results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
qsize, me, mh, Pl, Pt, Eg, offset, *_ = tuple(data.loc[0])
qd_cb = qbd.qd_results(qsize, (Eg - 0.4)*offset, me, me, band="CB1")
qd_vb = qbd.qd_results(qsize, (Eg - 0.4)*(1-offset), mh, mh, band="VB1")

sim_setup = (25, 0.65, Eg, (Pl, Pt))
qd1_prop = (qsize, (Eg - 0.4)*offset, me, me)
qd2_prop = (qsize, (Eg - 0.4)*(1-offset), mh, mh)
trn = ab.all_avg_trn_elements(qd1_prop, qd2_prop, sim_setup)
best_abs = ab.interband_absorption(np.linspace(0, 5, 600),qd1_prop, qd2_prop, sim_setup)
293/115:
ab._single_FoM(qsize, (Eg - 0.4)*offset, (Eg - 0.4)*(1-offset),
               me, mh, Pl, Pt, Eg, offset, sim_size=25, lat_size=0.65)
293/116: qd_vb.e_levels
293/117: qd_cb.e_levels
293/118:
plt.figure(figsize=(10,8))
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
plt.xlabel("Absorption Coefficient", fontsize=18)
plt.ylabel("Energy (eV)", fontsize=18)
plt.tick_params(axis='both', labelsize=16)
plt.xlim(0, 3)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value:.3g}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.savefig("PSO_Best_2.svg", transparent=True)
293/119:
param_dict = {
    "qd_size": [1.5, 3],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-25, 1e-24],
    "Eg": [1, 2.5],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 25
}
res = particle_swarm(ab.opt_function, param_dict,
                     n_particles=15, n_iter=30,
                     export=True, swarm_properties=(0.3, 1.5, 1.5),
                     **const_args)
293/120:
param_dict = {
    "qd_size": [1.5, 3],
    "me": [0.05, 0.15],
    "mh": [0.05, 0.15],
    "Pl": [1e-25, 1e-24],
    "Pt": [1e-25, 1e-24],
    "Eg": [1, 2.5],
    "offset": [0.2, 0.8]
}
const_args = {
    "energy": np.linspace(0.5, 4, 400),
    "lat_size": 0.65,
    "sim_size": 25
}
res = particle_swarm(ab.opt_function, param_dict,
                     n_particles=15, n_iter=30,
                     export=True, swarm_properties=(0.3, 1.5, 1.5),
                     **const_args)
293/121:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("PSO_Results/results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
qsize, me, mh, Pl, Pt, Eg, offset, *_ = tuple(data.loc[0])
qd_cb = qbd.qd_results(qsize, (Eg - 0.4)*offset, me, me, band="CB1")
qd_vb = qbd.qd_results(qsize, (Eg - 0.4)*(1-offset), mh, mh, band="VB1")

sim_setup = (25, 0.65, Eg, (Pl, Pt))
qd1_prop = (qsize, (Eg - 0.4)*offset, me, me)
qd2_prop = (qsize, (Eg - 0.4)*(1-offset), mh, mh)
trn = ab.all_avg_trn_elements(qd1_prop, qd2_prop, sim_setup)
best_abs = ab.interband_absorption(np.linspace(0, 5, 600),qd1_prop, qd2_prop, sim_setup)
293/122:
ab._single_FoM(qsize, (Eg - 0.4)*offset, (Eg - 0.4)*(1-offset),
               me, mh, Pl, Pt, Eg, offset, sim_size=25, lat_size=0.65)
293/123: qd_vb.e_levels
293/124: qd_cb.e_levels
293/125:
plt.figure(figsize=(10,8))
plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
plt.xlabel("Absorption Coefficient", fontsize=18)
plt.ylabel("Energy (eV)", fontsize=18)
plt.tick_params(axis='both', labelsize=16)
plt.xlim(0, 3)
for index, (name, value) in enumerate(zip(columns, data.loc[0])):
    if index > 7:
        break
    plt.annotate(f"$\\bf{name}$={value:.3g}$\pm${value*0.05:.2f}", (0.02, 0.9-index/14), xycoords="axes fraction", fontsize=16)
plt.savefig("PSO_Best_2.svg", transparent=True)
293/126: res
296/1:
%load_ext autoreload
%autoreload 1
%matplotlib inline
%aimport band_model.pso.pso
296/2:
%aimport band_model.utils.absorption
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from band_model.pso.pso import particle_swarm

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import scipy.interpolate as scin

import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import seaborn as sns

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
296/3:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("PSO_Results/results_29", sep=" ", names=columns)
data.sort_values(by="FoM", ascending=False, ignore_index=True, inplace=True)
qsize, me, mh, Pl, Pt, Eg, offset, *_ = tuple(data.loc[0])
qd_cb = qbd.qd_results(qsize, (Eg - 0.4)*offset, me, me, band="CB1")
qd_vb = qbd.qd_results(qsize, (Eg - 0.4)*(1-offset), mh, mh, band="VB1")

sim_setup = (25, 0.65, Eg, (Pl, Pt))
qd1_prop = (qsize, (Eg - 0.4)*offset, me, me)
qd2_prop = (qsize, (Eg - 0.4)*(1-offset), mh, mh)
trn = ab.all_avg_trn_elements(qd1_prop, qd2_prop, sim_setup)
best_abs = ab.interband_absorption(np.linspace(0, 5, 600),qd1_prop, qd2_prop, sim_setup)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[0]["Energy"], results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}", fontsize=18)
        ax[i, k].tick_params(labelsize=14)
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=16)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=16)
#plt.savefig("Absorption_Coefs.svg", transparent=True)
296/4:
columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
data = pd.read_csv("PSO_Results/results_29", sep=" ", names=columns)
energy = np.linspace(0.4, 3, 600)
results = []
for data_i in data.apply(tuple, axis=1):
    Vcb = (data_i[5] - 0.4)*data_i[6]
    Vvb = (data_i[5] - 0.4)*(1-data_i[6])
    qd_cb = (data_i[0], Vcb, data_i[1], data_i[1])
    qd_vb = (data_i[0], Vvb, data_i[2], data_i[2])
    sim_properties = (15, 0.65, data_i[5], (data_i[3], data_i[4]))
    results.append(ab.interband_absorption(energy, qd_cb, qd_vb, sim_properties))

sim_setup = (25, 0.65, Eg, (Pl, Pt))
qd1_prop = (qsize, (Eg - 0.4)*offset, me, me)
qd2_prop = (qsize, (Eg - 0.4)*(1-offset), mh, mh)
trn = ab.all_avg_trn_elements(qd1_prop, qd2_prop, sim_setup)
best_abs = ab.interband_absorption(np.linspace(0, 5, 600),qd1_prop, qd2_prop, sim_setup)
fig, ax = plt.subplots(3, 5, figsize=(20,13))
flat_index = np.arange(0, 15).reshape(3, 5)
for i in range(3):
    for k in range(5):
        ax[i, k].plot(results[0]["Energy"], results[flat_index[i, k]]["Total"])
        ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}", fontsize=18)
        ax[i, k].tick_params(labelsize=14)
        if k == 0:
            ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=16)
        if i == 2:
            ax[i, k].set_xlabel("Energy (eV)", fontsize=16)
#plt.savefig("Absorption_Coefs.svg", transparent=True)
297/1: import numpy as np
297/2: np.arange(0, 15).reshape(-1)
296/5:
def pso_it_abs_preview(it_name, energy=np.linspace(0.4, 3, 600), save=False):
    """ Import data from a particular PSO optimization and plot the absorption for all particles """
    columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
    data = pd.read_csv(it_name, sep=" ", names=columns)
    results = []
    # Import the data all the info to a list of Dataframes with the severall absorptions
    for data_i in data.apply(tuple, axis=1):
        Vcb = (data_i[5] - 0.4)*data_i[6]
        Vvb = (data_i[5] - 0.4)*(1-data_i[6])
        qd_cb = (data_i[0], Vcb, data_i[1], data_i[1])
        qd_vb = (data_i[0], Vvb, data_i[2], data_i[2])
        sim_properties = (15, 0.65, data_i[5], (data_i[3], data_i[4]))
        results.append(ab.interband_absorption(energy, qd_cb, qd_vb, sim_properties))

    fig, ax = plt.subplots(3, 5, figsize=(20,13))
    flat_index = np.arange(0, 15).reshape(3, 5)
    for i in range(3):
        for k in range(5):
            ax[i, k].plot(results[0]["Energy"], results[flat_index[i, k]]["Total"])
            ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}", fontsize=18)
            ax[i, k].tick_params(labelsize=14)
            if k == 0:
                ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=16)
            if i == 2:
                ax[i, k].set_xlabel("Energy (eV)", fontsize=16)
    if save:
        plt.savefig("Absorption_Coefs.svg", transparent=True)
296/6: pso_it_abs_preview("PSO_Results/results_29")
298/1: import matplotlib.pyplot as plt
298/2: plt.subplots(1, 7)
298/3: fig, ax = plt.subplots(1, 7)
298/4: ax
298/5: ax.shape
298/6: fig, ax = plt.subplots(2, 7)
298/7: ax.shape
298/8: len(ax)
298/9: len(ax.shape)
298/10: sum(ax.shape)
298/11: np.arange(0, sum(ax.shape)).reshape(ax)
298/12: import numpy as np
298/13: import numpy as np
298/14: np.arange(0, sum(ax.shape)).reshape(ax)
298/15: np.arange(0, sum(ax.shape)-1).reshape(ax)
298/16: np.arange(0, sum(ax.shape)).reshape(ax.shape)
298/17: np.arange(0, sum(ax.shape)-1).reshape(ax.shape)
298/18: sum(ax.shape))
298/19: sum(ax.shape)
298/20: np.arange(0, 9)
298/21: prod(ax.shape)
298/22: np.prod(ax.shape)
298/23: np.arange(0, np.prod(ax.shape)).reshape(ax.shape)
296/7:
def pso_it_abs_preview(ax, it_name, energy=np.linspace(0.4, 3, 600), save=False):
    """ Import data from a particular PSO optimization and plot the absorption for all particles """
    columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
    data = pd.read_csv(it_name, sep=" ", names=columns)
    results = []
    # Import the data all the info to a list of Dataframes with the severall absorptions
    for data_i in data.apply(tuple, axis=1):
        Vcb = (data_i[5] - 0.4)*data_i[6]
        Vvb = (data_i[5] - 0.4)*(1-data_i[6])
        qd_cb = (data_i[0], Vcb, data_i[1], data_i[1])
        qd_vb = (data_i[0], Vvb, data_i[2], data_i[2])
        sim_properties = (15, 0.65, data_i[5], (data_i[3], data_i[4]))
        results.append(ab.interband_absorption(energy, qd_cb, qd_vb, sim_properties))
    # Create the array with the flat indexes
    flat_index = np.arange(0, np.prod(ax.shape)).reshape(ax.shape)
    for i in range(ax.shape[0]):
        for k in range(ax.shape[1]):
            ax[i, k].plot(results[0]["Energy"], results[flat_index[i, k]]["Total"])
            ax[i, k].set_title(f"FoM={data['FoM'][flat_index[i, k]]:.2f}", fontsize=18)
            ax[i, k].tick_params(labelsize=14)
            if k == 0:
                ax[i, k].set_ylabel("Absorption Coef (nm$^3$/cm)", fontsize=16)
            if i == 2:
                ax[i, k].set_xlabel("Energy (eV)", fontsize=16)
    if save:
        plt.savefig("Absorption_Coefs.svg", transparent=True)
296/8:
def pso_it_energy_profile(ax, it_name, save=False, savename="Band_diagrams.svg"):
    """
    Utility function to grab the data for all the particles in a iteration
    and then create a profile of the energy levels for each particle
    Args:
        ax: list with the axes (obtained from plt.subplots)
        it_name: name for the particular iteration
        save: wether to save the file
        savename: Name to save the file
    """
    # Columns for the optimization
    columns = ["QSize", "me", "mh", "Pl", "Pt", "Eg", "offset", "FoM", "vQSize", "vme", "vmh", "vPl", "vPt", "vEg", "voffset"]
    data = pd.read_csv(it_name, sep=" ", names=columns)
    ordered_data = data.apply(tuple, axis=1).values.reshape(ax.shape)
    # Normalized x to organize the standar information
    x = np.linspace(0, 1, 50)
    for i, line in enumerate(ordered_data):
        for j, column in enumerate(line):
            Vcb = (column[5] - 0.4)*column[6]
            Vvb = (column[5] - 0.4)*(1-column[6])
            qd_cb = qbd.qd_results(column[0], Vcb, column[1], column[1], band="CB1")
            qd_vb = qbd.qd_results(data_i[0], Vvb, column[2], column[2], band="VB1")
            # Define plot limits
            ax[i, j].set_ylim(0, column[5])
            ax[i, j].spines['right'].set_visible(False)
            ax[i, j].spines['top'].set_visible(False)
            ax[i, j].spines['bottom'].set_visible(False)
            # Create the band diagram from Eg, Vcb, Vvb
            # Left/Righ sides of the bands
            ax[i, j].axhline(0, xmin=0, xmax=0.25, color="k")
            ax[i, j].axhline(column[5], xmin=0, xmax=0.25, color="k")
            ax[i, j].axhline(0, xmin=0.65, xmax=1, color="k")
            ax[i, j].axhline(column[5], xmin=0.65, xmax=1, color="k")
            # Mid Line
            ax[i, j].axhline(Vvb, xmin=0.25, xmax=0.65, color="k")
            ax[i, j].axhline(Vvb+0.4, xmin=0.25, xmax=0.65, color="k")
            # Add vertical bariers
            ax[i, j].axvline(0.25, ymin=0, ymax=Vvb/column[5], color="k")
            ax[i, j].axvline(0.65, ymin=0, ymax=Vvb/column[5], color="k")
            ax[i, j].axvline(0.25, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
            ax[i, j].axvline(0.65, ymin=(Vvb+0.4)/column[5], ymax=1, color="k")
            ax[i, j].set_xticks(ticks=[])
            ax[i, j].tick_params(axis="y", labelsize=16)
            # Plot the energy spectrum (from -0.25 to 0.25)
            for e_cb in qd_cb.e_levels.values.flatten():
                ax[i, j].axhline(column[5] + e_cb, xmin=0.25, xmax=0.65)
            for e_vb in qd_vb.e_levels.values.flatten():
                ax[i, j].axhline(-e_vb, xmin=0.25, xmax=0.65)
    if save:
        plt.savefig(savename, transparent=True)
296/9:
%aimport band_model.utils.absorption
%aimport band_model.utils.utilities
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils import utilities as utils
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from band_model.pso.pso import particle_swarm

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import scipy.interpolate as scin

import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import seaborn as sns

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
296/10:
%aimport band_model.utils.absorption
%aimport band_model.utils.utilities
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils import utilities as utils
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from band_model.pso.pso import particle_swarm

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import scipy.interpolate as scin

import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import seaborn as sns

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
296/11:
%aimport band_model.utils.absorption
%aimport band_model.utils.utilities
from band_model import qd_base_data as qbd
from band_model.utils import absorption as ab
from band_model.utils import utilities as utils
from band_model.utils.absorption import envolute_matrix_element as eme
from band_model.utils.absorption import avg_trn_elements as ate
from band_model.pso.pso import particle_swarm

from scipy import special
import scipy.constants as scc
import scipy.integrate as sci
import scipy.interpolate as scin

import matplotlib.pyplot as plt
import matplotlib.cm as cmb
import seaborn as sns

import math
import numpy as np
import pandas as pd

import h5py
import importlib

from itertools import product
from pyevtk.hl import gridToVTK

import warnings
warnings.filterwarnings('ignore')

import time
import logging
logging.basicConfig(filename="output.log",
                    format='%(asctime)s - [%(levelname)s]:%(name)s[%(funcName)s]: %(message)s',
                    datefmt='%H:%M:%S',
                    level=logging.INFO)
logging.getLogger("matplotlib").setLevel(logging.INFO)
logging.getLogger("band_model").setLevel(logging.INFO)
296/12: utils.pso_it_energy_profile("PSO_Results/results_29")
296/13:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
utils.pso_it_energy_profile(ax, "PSO_Results/results_29")
296/14:
fig, ax = plt.subplots(3, 5, figsize=(20,13))
utils.pso_it_energy_profile(ax, "PSO_Results/results_29")
299/1: plt.plot(np.linspace(0, 5, 600), best_abs.iloc[:, 1:])
   1: %history -g -f Band_Model.ipynb
